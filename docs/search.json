[
  {
    "objectID": "tipsheet.html",
    "href": "tipsheet.html",
    "title": "431 Project B Tips",
    "section": "",
    "text": "I wanted to pass along these tips, most of which have came up in assessing the last few years of similar projects.\n\nThis should be a good set of things to review (along with the Project B Checklist) as you’re preparing your final materials for submission."
  },
  {
    "objectID": "tipsheet.html#what-is-this",
    "href": "tipsheet.html#what-is-this",
    "title": "431 Project B Tips",
    "section": "",
    "text": "I wanted to pass along these tips, most of which have came up in assessing the last few years of similar projects.\n\nThis should be a good set of things to review (along with the Project B Checklist) as you’re preparing your final materials for submission."
  },
  {
    "objectID": "tipsheet.html#yaml-and-setup-issues",
    "href": "tipsheet.html#yaml-and-setup-issues",
    "title": "431 Project B Tips",
    "section": "YAML and Setup issues",
    "text": "YAML and Setup issues\n\nNo hashtags preceding R results. I would like you to be sure that your R output is not preceded by hashtags. The easiest way to ensure this is to include the following code at the top of your code, where you load your R packages.\n\nknitr::opts_chunk$set(comment = NA)\n\nTheming gg-Plots. I would like you to use a ggplot theme like theme_bw() or theme_lucid() or another of your choosing globally, rather than including it in the code of every individual plot you build. So include something like\n\ntheme_set(theme_bw())\nimmediately after you load the tidyverse, and then don’t include theming of this sort in your individual plots, unless you are deliberately adding some specialized theming elements for a specific plot.\n\nClean List of R Packages. Your list of R packages should be clean for each study, which means:\n\n\ntidyverse is loaded last, and easystats is loaded just before it\nnone of the core tidyverse packages (core list is here) are loaded\nall packages you will load for this study are in one place\nno packages are loaded that you don’t use in your work."
  },
  {
    "objectID": "tipsheet.html#general-issues",
    "href": "tipsheet.html#general-issues",
    "title": "431 Project B Tips",
    "section": "General Issues",
    "text": "General Issues\n\nCheck your HTML for plot-text transition problems. One of the hardest things to get people to do is add empty lines in R Markdown after they create a plot or heading. Forgetting to do this can cause your plots to show up in the HTML with the start of the next paragraph shown to the right of the plot instead of below the plot. Make sure you avoid this mistake. Also, Hit ENTER after every pipe and + in your code so that you avoid scrollable windows for code in your HTML output.\nMissing Data Mechanism and Dealing with Missingness. You need to have an explicit statement about your assumed missing data mechanism, including either the term MCAR, MAR or MNAR, in both Study 1 and Study 2, and you have to be specific about what you’ve done. This should be part of your HTML file everywhere where you impute (as in Study 2 variables other than your outcome and key predictor) or filter to complete cases (as in Study 1 and with your Study 2 outcome and key predictor). None of your analyses (in Study 1 or Study 2) should involve missing values: either you should have imputed missing values or you should have filtered to complete cases.\nSpell check doesn’t check headings and subheadings. Using spell check in R Studio is trivial (just hit F7) and important, but be aware that you still need to read your HTML to be sure that you don’t have problems. A particular issue is that the spell check doesn’t check your headings and subheadings so you’ll want to pay especially close attention to those pieces. In particular, I’ve seen several people misspell the word “Transformations” in section 6 of Study 2.\nYour confidence level is 90%, not 95%. All of Project B uses a 90% confidence level, so the phrase “p &lt; 0.05” is 100% irrelevant to this work. I would also strongly suggest you search through your work and eliminate the terms “statistical significance” and even “significant” unless you have a remarkably good reason to include them.\nOrder multi-categorical factors properly. Please respect the ordering of multicategorical variables, especially in Analyses C and E for Study 1. Be sure that you adjust the levels of your factor so that they use the natural order of the variable. If you have a nominal multi-categorical variable, like race/ethnicity, in Study 2, then I suggest you order the levels of that factor variable from largest to smallest in terms of number of subjects, so that the baseline group will be the one that appears most frequently in your data.\nDon’t change numeric variables to factors. If you change a numeric variable to a factor, and then change it back into a numeric variable, that will create many, many problems. Don’t do that. Instead, create a new factor variable if you’re going to convert a numeric variable into categories."
  },
  {
    "objectID": "tipsheet.html#nhanes-issues",
    "href": "tipsheet.html#nhanes-issues",
    "title": "431 Project B Tips",
    "section": "NHANES issues",
    "text": "NHANES issues\n\nNHANES isn’t a random sample. Don’t suggest or state that it is. So the NHANES sampling procedure is a limitation in terms of you cannot really generalize to the US population with NHANES unless you use survey weighting.\nSpecify your approach if not standard. If you’re using NHANES data but not using adults ages 21-79, be sure that you’ve made that abundantly clear everywhere where it’s relevant, including at least in the Data Description section for Study 1 and Study 2. Also, be sure to very clearly specify whether you’re using 2017-2020 or 2021-2023 NHANES data."
  },
  {
    "objectID": "tipsheet.html#study-1-issues",
    "href": "tipsheet.html#study-1-issues",
    "title": "431 Project B Tips",
    "section": "Study 1 Issues",
    "text": "Study 1 Issues\n\nStudy 1 Analyses must stand on their own. Each of your four Study 1 Analyses should stand on its own, in the sense that you should specify the relevant group of subjects, the exposure and the outcome in words at the start of each of those analyses. Please label these as Analysis A, B, C, D or E, (leaving out one, of course) as I did in building the assignment.\nDescribe the direction and size of estimated effects. In Project B, you should have no statements about statistical significance or any synonym. Estimate effects whenever possible, including a confidence interval. This is easy for Study 2 and for Study 1 Analyses A, B, and D, I think, but more challenging for C and E. Be sure to carefully focus your description of your result on the direction and size of the effect you estimate, in the context of your problem.\n\n\nFor instance, a terrible sentence in Analysis B would be something like “We saw a significant difference between males and females on mean systolic blood pressure.”\nA better sentence would be something like “The mean systolic blood pressure for males was 3 mm Hg higher than that of females, with a 90% CI of (1, 5).” Notice that this better sentence includes the actual units of measurement, and not something generic like “points”.\n\n\nPaired vs. Independent Samples. In Analyses A and B for Study 1, be sure that you provide a logical argument near the top of your work for why the data you are studying use (in Analysis A, paired) (in Analysis B, independent) samples.\nSimplifying Conclusions in Analysis D. In Analysis D of Study 1, in writing up your conclusions after forming an appropriate 2x2 table, and specifying the probabilities of obtaining your outcome within each exposure group as estimated at the top of the table, it is completely sufficient to provide your interpretation of either:\n\n\nthe relative risk and the odds ratio and their confidence intervals, or\nthe relative risk and the difference in probabilities, with their confidence intervals.\n\n\nDescribe some percentages in Analysis E. In Analysis E for Study 1, you should focus your interpretation of the result from your table and chi-square test on a comparison of interesting percentages from your table, in addition to the p value and a visualization of the results."
  },
  {
    "objectID": "tipsheet.html#study-2-issues",
    "href": "tipsheet.html#study-2-issues",
    "title": "431 Project B Tips",
    "section": "Study 2 Issues",
    "text": "Study 2 Issues\n\nResidual Plots should be tall. When building residual plots, whether with check_model() or something else, make them tall, by incorporating r, fig.height = 8 into your chunk header for that code. For example, this is the default size:\n\n\nm1 &lt;- lm(mpg ~ disp + wt, data = mtcars)\ncheck_model(m1)\n\n\n\n\n\n\n\n\nand below is what you get if you add #| fig.height: 8 at the start of the code chunk.\n\nm1 &lt;- lm(mpg ~ disp + wt, data = mtcars)\ncheck_model(m1)\n\n\n\n\n\n\n\n\nThis helps us see things more effectively, especially with large sample sizes in the plots. So please do it.\n\nBox-Cox. In Study 2, in the Transformation of Outcome section, please show the Box-Cox analysis immediately after the starting graphical summary (as opposed to the strange approach I used in the template) and then either use it (which is fine) or specify why you’ve decided not to use it. Remember that a Box-Cox \\(\\lambda\\) near 0 suggests a logarithmic transformation, and that a Box-Cox \\(\\lambda\\) of 1 indicates no transformation.\nUsing Validated R-Square. In Study 2, you should use the validated R-square you develop in section 10.3.2 as part of your discussion in both Sections 10.4 and 11.1. (in addition to whatever else you decide to use) to help describe how successful your winning model is. You should also reflect in Section 11.1 (Chosen Model, within the Discussion section) on the relationship between the original training sample R-square you observed for your chosen model and the validated R-square you calculated for that model in section 10.3.2. Here, you want to assess how overconfident or underconfident your original R-square was, basically."
  },
  {
    "objectID": "tipsheet.html#and-finally",
    "href": "tipsheet.html#and-finally",
    "title": "431 Project B Tips",
    "section": "And finally…",
    "text": "And finally…\n\nThe Discussion section is important. The piece of your HTML that I guarantee I will be looking at to help me settle on your final grade is the Discussion section in Study 2. I expect to see meaningful paragraphs there in response to the required elements. So don’t neglect that material just because it comes last.\n\nDon’t forget to submit:\n\nyour Study 1 qmd and HTML, and your Study 2 qmd and HTML to Canvas no later than the deadline.\nyour data, if you’re not using NHANES, to Canvas no later than the deadline,\nyour Project B self-evaluation form after you submit your Canvas materials, and no later than the deadline.\nyour CWRU class evaluation by their deadline.\n\nThanks and good luck to you all!"
  },
  {
    "objectID": "study2b.html",
    "href": "study2b.html",
    "title": "Study 2 Report Specifications",
    "section": "",
    "text": "Produce a beautiful HTML report. It should include:"
  },
  {
    "objectID": "study2b.html#headings-you-should-use-in-the-study-2-report",
    "href": "study2b.html#headings-you-should-use-in-the-study-2-report",
    "title": "Study 2 Report Specifications",
    "section": "Headings you should use in the Study 2 report",
    "text": "Headings you should use in the Study 2 report\nAll of your work should be done in a fresh R project in a clean directory on your computer.\n\nSetup and Data Ingest\nCleaning the Data\n\nBe sure to review the material (including the Tips on Cleaning Data) provided in the Data Development section of this website, in particular regarding how to deal with missing data in Study 2.\nIf you have any missing data which you impute as part of Study 2, provide a description of that process as a subsection here, and demonstrate that imputation was needed, specify the missing data mechanism you are assuming (MAR or MCAR are the available choices) and then demonstrate that after imputation you have a complete data set.\n\nCodebook and Data Description\n\nFollow the headings and steps laid out in the Study 1 instructions for this section.\nYou should include subsections for your codebook, a listing of your analytic tibble, and a numeric description, as you did in Study 1.\nMake the word Outcome in bold the first word of the description for your outcome in your codebook.\nMake the words Key Predictor in bold the first two words of the description for your key predictor in your codebook.\n\nMy Research Question\n\nSpecify your research question, with whatever introduction and background you feel is required for Dr. Love to understand its importance. If you have a pre-analytic guess as to how this will work out in your setting, please feel encouraged to include that here. The actual question should end with a question mark, and be appropriate for the nature of the analyses to come.\n\nPartitioning the Data\n\nSplit the data into two samples (a model training sample containing 60-80% of the data, and a model test sample containing the remaining 20-40%.) Details on how to do this are available here.\nBe sure to demonstrate that each subject in the original data wound up in either your training or your test sample.\n\nTransforming the Outcome\n\nUsing your training sample, provide appropriate, well-labeled visualizations of your outcome, and investigate potential transformations of that outcome for the purpose of fitting regression models in a useful way.\nMake a clear decision about what transformation (if any) you want to use. Don’t use a transformation you cannot interpret.\nIf your outcome is symmetric but with outliers, power transformations will not be of much help.\nIf your outcome includes non-positive values, you may have to add the same value to each observation of the outcome before using power transformations. (For instance, if some of your values of your raw outcome are 0, you might add 1 to each observation before considering a transformation.)\n\nThe Big Model\n\nFit a linear regression model including all of your candidate predictors for your (possibly transformed) outcome within your training sample. Summarize its prediction equation, and the other materials available through a tidy summary of the coefficients.\nIf you want to divide this work into subsections, that’s up to you.\n\nThe Smaller Model\n\nFit a linear regression model using a subset of your predictors that is interesting, again using the training sample. Summarize its prediction equation, and the other materials available through a tidy summary of the coefficients.\nYour subset must include at least two predictors, including the key predictor, and a perfectly reasonable strategy for this project is simply to compare a “naive” model with the key predictor and one other predictor to the full model with all of the predictors you have identified.\nIf you prefer to use another subset of predictors from your big model as your smaller model, that’s fine, too. If you’d prefer to use an automated or semi-automated strategy for identifying your subset of predictors from the big model, that’s also fine, but you must have at least two predictors in your smaller model.\nIf you want to divide this work into subsections, that would be helpful.\n\nIn-Sample Comparison\n\nPresent four subsections here, as labeled below.\nIn Quality of Fit, summarize the quality of fit (focusing on \\(R^2\\), adjusted \\(R^2\\), AIC and BIC) within the training sample.\nIn Posterior Predictive Checks, comment on systematic discrepancies you observe for each model between the real and simulated data.\nIn Assessing Assumptions, create and assess residual plots (specifically you should be looking at the assumptions of linearity, constant variance and Normality) for each of the two models. Also discuss whether there are any highly influential points, and if so, identify them.\nIn Comparing the Models, comment on the relative strengths and weaknesses of the two models within your training sample. A graph of some key summaries would be appropriate, accompanied by comments on assumptions and posterior predictive checks. Which model do you prefer, based on this information?\n\nModel Validation\n\nThis should have four subsections, as labeled below.\nCalculating Prediction Errors Apply each of your models to the test sample to predict the outcome and do whatever back-transformation of predictions is necessary.\nVisualizing the Predictions Provide an appropriate visualization of the outcome predictions (after back-transformation) as compared to the actual outcome values, made by the two models in your test sample. Are they similar?\n\nSuch plots help you see the range of predicted values for each model on the X axis, and compare it to the range of observed values on the Y axis. Many models will be overly conservative, only predicting outcomes within a small range. For instance, if your big model’s range of predictions is much more in keeping with the observed range, that’s a reason to like the big model.\nSuch plots also help you see if one of the models matches the line for observed = predicted better than the other within your test sample.\n\nSummarizing the Errors Then summarize the following values, all on the scale of the original untransformed outcome, across the observations in your test sample, in an attractive table.\n\nsquare root of the mean squared prediction error (RMSPE)\nmean absolute prediction error (MAPE)\nmaximum absolute prediction error (MAE)\nsquared correlation of the actual and predicted values (validated \\(R^2\\))\n\nComparing the Models Use the results from the previous two subsections to comment on the relative strengths and weaknesses of the two models within your test sample. Which model do you prefer now?\n\nDiscussion\n\nThis should have four subsections, as labeled below.\nChosen Model\n\nSpecify which model you’ve chosen, based on your conclusions from sections 9 and 10.\n\nAnswering My Question\n\nUse the result of this model to answer your research question in a few sentences. Comment on whether your results matched up with your pre-analysis expectations, and also specify any limitations you see on this conclusion.\n\nNext Steps\n\nDiscuss an interesting next step you would like to pursue to learn more about this sort of research question or to go further with these data.\n\nReflection\n\nBriefly describe what you would have done differently in Study 2 had you known at the start of the project what you have learned by doing it.\n\n\nInclude the session information with session_info() from the xfun package as a separate section at the end of your report. If you make more use of AI than spell-check or RStudio’s help with filling in details of functions, the place to talk about that is here, at the start of the session information section."
  },
  {
    "objectID": "study1c.html",
    "href": "study1c.html",
    "title": "Study 1 Sample Report",
    "section": "",
    "text": "The Sample Study 1 Report is now available.\nThe Sample Study 1 Report provides a brief demonstration of an appropriate analysis for each of the required Study 1 analyses in Project B. Complete instructions for your Study 1 report are available here."
  },
  {
    "objectID": "study1c.html#the-study-1-sample-report",
    "href": "study1c.html#the-study-1-sample-report",
    "title": "Study 1 Sample Report",
    "section": "The Study 1 Sample Report",
    "text": "The Study 1 Sample Report\nThe Sample Study 1 Report demonstrates many of the elements you would need to complete, including:\n\ndata ingest and merging\ncleaning the data\ncodebook, analytic tibble and data summary\nAnalysis A: Compare two means/medians using paired samples\nAnalysis B: Compare two means/medians using independent samples\nAnalysis C: Compare 3-6 means/medians using independent samples\nAnalysis D: Create and analyze a \\(2 \\times 2\\) table\nAnalysis E: Create and analyze a \\(J \\times K\\) table, where \\(2 \\leq J \\leq 5\\) and \\(3 \\leq K \\leq 5\\)\nSession Information\n\nfor a sample of 53 observations (before I drop missing values) from a 2015 class survey of 431 students and TAs from that year. Since the sample size is much smaller than what you will be using, some issues are more problematic here than you might have to deal with in your work."
  },
  {
    "objectID": "study1c.html#study-1-sample-report-documents",
    "href": "study1c.html#study-1-sample-report-documents",
    "title": "Study 1 Sample Report",
    "section": "Study 1 Sample Report Documents",
    "text": "Study 1 Sample Report Documents\nThe Sample Study 1 Report can be viewed in HTML at this link.\nThere is a link at the top of the HTML document where you can download the complete Quarto code used to create the Sample Study 1 Report, which might be a helpful template for your Study 1 report.\nThe raw data files for the Sample Study 1 Report are described in the Quarto and HTML files above and are found on the 431-data website. They are named:\n\nprojectB-study1-demo-survey-2015a.xlsx (first 20 observations, all 21 columns)\nprojectB-study1-demo-survey-2015b.csv (remaining 33 observations, some of the 21 columns)\nprojectB-study1-demo-survey-2015c.csv (remaining 33 observations, rest of the 21 columns)\n\nThe final data set after merging for the Sample Study 1 Report includes 53 observations on 21 columns. The subjects are identified with a code called s_id in each of the raw data files."
  },
  {
    "objectID": "study1c.html#caveats",
    "href": "study1c.html#caveats",
    "title": "Study 1 Sample Report",
    "section": "Caveats",
    "text": "Caveats\n\nThe Sample Study 1 Report does not precisely follow the requirements from Study 1 for the Research Question and Conclusions sections, because that is a big part of your job.\nThe Sample Study 1 Report has a much smaller data set than you will have, so I don’t hold myself in the Sample Study 1 Report to the standards for cell sizes and numbers of observations that you will need to meet in your Study 1.\nIn the Sample Study 1 Report, I produce all 5 analyses (you will do only 4) and I also run several different possible analyses in most cases, when you will instead select one. For instance, in comparing paired samples, the demonstration shows code for confidence intervals based on the t distribution and the bootstrap, while your Project B Study 1 will include just one of these, should you choose to do that analysis.\nOutside of those caveats, these demonstrations are meant to be accurate and reflect the level of detail I’m looking for, although it is certainly possible to expand on these demonstrations in your work, if that seems helpful. I believe the Sample Study 1 Report to be largely accurate, but many eyes will find some issues, probably.\n\nIf people find corrections and would be good enough to email me about them I will attempt to reflect those edits in revisions. If I do something in the Sample Study 1 Report that appears to be in conflict with the instructions for Study 1, then (a) please let me know, and (b) treat the Study 1 instructions as your guidepost in completing your work."
  },
  {
    "objectID": "study1a.html",
    "href": "study1a.html",
    "title": "Required Study 1 Analyses",
    "section": "",
    "text": "In your four analyses (chosen from five possibilities), you will be doing:"
  },
  {
    "objectID": "study1a.html#data-management",
    "href": "study1a.html#data-management",
    "title": "Required Study 1 Analyses",
    "section": "Data Management",
    "text": "Data Management\n\nAll data merging and cleaning must be included in your Quarto report, starting from the raw data obtained either through the nhanesA package or via reading in your non-NHANES raw data, so that we can replicate your work.\nYou can use the data as they were collected (quantitative, binary or multi-categorical), but you can also create categorical variables from the quantitative variables provided, should that be of interest in one or more of your analyses.\n\nShould you decide a categorical variable from a quantitative one, be sure to describe that process carefully, and demonstrate that each level of your created categorical variable contains the minimum number of observations specified on the Data Development page."
  },
  {
    "objectID": "study1a.html#analyses-youll-do",
    "href": "study1a.html#analyses-youll-do",
    "title": "Required Study 1 Analyses",
    "section": "Analyses You’ll Do",
    "text": "Analyses You’ll Do\nYou will complete any four of the following five Analyses, and present these results in your Study 1 Report.\nFor each of these analyses, you will provide complete code (including whatever you did to clean the raw data for the variables you are studying), appropriate visualizations and detailed explanations of your analytic decisions, and conclusions. Use a 90% confidence level for all Study 1 work, please.\n\nAgain, if you are using NHANES data, you will need between 500 and 8,750 observations with a minimum of 500 observations containing complete data on all of the variables you will use in Study 1.\nIf you are using any other data source, you will need between 250 and 10,000 observations, and at least 250 with complete data on all variables you will use in Study 1.\nIn Study 1, you should explicitly state that you are assuming that the “missing completely at random (MCAR)” mechanism for missing data, and then filter until you have only complete cases.\n\nEach analysis should be self-contained (so that I don’t have to read Analysis A first to understand Analysis C, for example). Present each new analysis as a subsection with an appropriate heading in the table of contents.\n\nAnalysis A. Compare two means/medians using paired samples\nHere, you will need to identify two quantitative variables (outcomes) which are paired (so that they have a natural link between them, and use the same units of measurement.) You’ll analyze the results and build a confidence interval for the population mean difference with an appropriate t-based or bootstrap procedure. Again, we require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) contain at least 15 unique values.\n\n\nAnalysis B. Compare two means/medians using independent samples\nHere, you will need to identify one quantitative (outcome) and one categorical variable (binary - 2 levels.) You’ll analyze the results and build a confidence interval for the difference in means with an appropriate t-based or bootstrap procedure. Note that it’s generally easier to find independent samples comparisons than paired samples comparisons in most of the data I expect you’ll be using. This would require a quantitative outcome (with at least 15 unique values), and a binary categorical variable which divides the data into two subgroups, so that each subgroup has a minimum of 30 observations.\n\n\nAnalysis C. Compare 3-6 means/medians using independent samples\nHere, you will need to identify one quantitative (outcome) and one categorical variable (multi-categorical with 3-6 levels.) Here, you should be thinking about an analysis of variance with either a set of Holm (probably better if you have unequal sample sizes in your groups) or Tukey HSD (better if you have a fairly balanced design) pairwise comparisons. This would require a quantitative outcome (with at least 15 unique values), and a multi-categorical variable with 3-6 categories which divides the data into subgroups, so that each subgroup has a minimum of 30 observations.\n\n\nAnalysis D. Create and analyze a \\(2 \\times 2\\) table\nHere, you will need to identify two categorical (binary) variables. Each cell of the resulting 2 x 2 table should contain a minimum of 30 subjects. You should be focused on the relative risk, odds ratio (sample version) and risk difference comparisons for point estimates, and on interpreting the confidence interval for the risk difference comparison.\n\n\nAnalysis E. Create and analyze a \\(J \\times K\\) table, where \\(2 \\leq J \\leq 5\\) and \\(3 \\leq K \\leq 5\\)\nHere, you will need to identify two categorical variables, at least one of which should contain 3-5 levels, while the other contains 2-5 levels. Each cell in the cross-tabulation of the two variables within the table should have a minimum of 15 observations. Here, you should be providing an appropriate cross-tabulation, the results of a chi-square test, accompanied by a useful visualization and description of the nature of the observed association."
  },
  {
    "objectID": "sample-study2.html",
    "href": "sample-study2.html",
    "title": "431 Project B Sample Study 2 Report",
    "section": "",
    "text": "Reminders from Dr. Love\n\n\n\n\nRemember that each subsection should include at least one complete sentence explaining what you are doing, specifying the variables you are using and how you are using them, and then conclude with at least one complete sentence of discussion of the key conclusions you draw from the current step, and a discussion of any limitations you can describe that apply to the results.\nIf you want to download the Quarto code I used to create this document to use as a template for your own work, click on the Code button near the title of this Sample Study.\nIn general, DO NOT use my exact words (other than the section and subsection headings) included in this sample report in your project. Rewrite everything to make it relevant to your situation. Do not repeat my instructions back to me.\n\n\nOne partial exception is that I have demonstrated the interpretation of at least one point estimate and at least one confidence interval in this Sample Report, using language that I would be happy to see you use."
  },
  {
    "objectID": "sample-study2.html#initial-setup-and-package-loads-in-r",
    "href": "sample-study2.html#initial-setup-and-package-loads-in-r",
    "title": "431 Project B Sample Study 2 Report",
    "section": "1.1 Initial Setup and Package Loads in R",
    "text": "1.1 Initial Setup and Package Loads in R\n\nlibrary(broom)\nlibrary(car)\nlibrary(GGally)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(mosaic)  \nlibrary(mice)    \nlibrary(naniar)\nlibrary(patchwork)\nlibrary(xfun)\nlibrary(easystats)\nlibrary(tidyverse) \n\n## Global options\n\nopts_chunk$set(comment=NA)\n\ntheme_set(theme_lucid())\noptions(dplyr.summarise.inform = FALSE)"
  },
  {
    "objectID": "sample-study2.html#loading-the-raw-data-into-r",
    "href": "sample-study2.html#loading-the-raw-data-into-r",
    "title": "431 Project B Sample Study 2 Report",
    "section": "1.2 Loading the Raw Data into R",
    "text": "1.2 Loading the Raw Data into R\nHere, we load the data using read_csv and then convert all character variables to factors in R, and then change our identifying code: subj_id back to a character variable.\n\nhbp_study &lt;- read_csv(\"data/hbp_study.csv\", show_col_types = FALSE) |&gt;\n  mutate(across(where(is.character), as.factor)) |&gt;\n  mutate(subj_id = as.character(subj_id))"
  },
  {
    "objectID": "sample-study2.html#merging-the-data",
    "href": "sample-study2.html#merging-the-data",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.1 Merging the Data",
    "text": "2.1 Merging the Data\nIn my little demonstration here, I don’t have to do any merging. See the Study 1 Example for an example merging data."
  },
  {
    "objectID": "sample-study2.html#the-raw-data",
    "href": "sample-study2.html#the-raw-data",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.2 The Raw Data",
    "text": "2.2 The Raw Data\nThe hbp_study data set includes 12 variables and 999 adult subjects. For each subject, we have gathered\n\nbaseline information on their age, and their sex,\nwhether or not they have a diabetes diagnosis,\nthe socio-economic status of their neighborhood of residence (nses),\ntheir body-mass index (bmi1) and systolic blood pressure (sbp1),\ntheir insurance type, tobacco use history, and\nwhether or not they have a prescription for a statin, or for a diuretic.\nEighteen months later, we gathered a new systolic blood pressure (sbp2) for each subject.\n\n\nglimpse(hbp_study)\n\nRows: 999\nColumns: 12\n$ subj_id   &lt;chr&gt; \"A0001\", \"A0004\", \"A0005\", \"A0013\", \"A0015\", \"A0017\", \"A0018…\n$ age       &lt;dbl&gt; 58, 65, 61, 51, 61, 45, 40, 50, 43, 46, 56, 52, 58, 59, 54, …\n$ sex       &lt;fct&gt; F, F, F, M, F, F, F, F, M, F, F, F, M, F, M, F, F, F, M, M, …\n$ diabetes  &lt;fct&gt; No, No, Yes, No, No, No, Yes, Yes, No, No, No, No, No, No, Y…\n$ nses      &lt;fct&gt; Low, Very Low, Very Low, Very Low, Very Low, Low, Very Low, …\n$ bmi1      &lt;dbl&gt; 24.41, 50.50, 29.76, 41.83, 30.95, 33.01, 36.32, 30.76, 23.1…\n$ sbp1      &lt;dbl&gt; 147, 134, 170, 118, 132, 110, 127, 152, 125, 161, 140, 136, …\n$ insurance &lt;fct&gt; Medicaid, Medicaid, Medicaid, Medicaid, Medicaid, Medicaid, …\n$ tobacco   &lt;fct&gt; never, never, current, quit, never, current, never, never, c…\n$ statin    &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, …\n$ diuretic  &lt;dbl&gt; 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, …\n$ sbp2      &lt;dbl&gt; 138, 134, 140, 143, 162, 141, 101, 154, 111, 154, 154, 138, …\n\n\nNote: If you have more than 20 variables in your initial (raw) data set, prune it down to 20 as the first step before showing us the results of glimpse for your data.\nThis tibble describes twelve variables, including:\n\na character variable called subj_id not to be used in our model except for identification of subjects,\nour outcome (sbp2) and our key predictor (sbp1) that describe systolic blood pressure at two different times.\nseven categorical candidate predictors, specifically sex, diabetes, nses, insurance, tobacco, statin, and diuretic, each specified here in R as either a factor or a 1/0 numeric variable (statin and diuretic),\nthree quantitative candidate predictors, specifically age, bmi1 and sbp1."
  },
  {
    "objectID": "sample-study2.html#which-variables-should-be-included-in-the-tidy-data-set",
    "href": "sample-study2.html#which-variables-should-be-included-in-the-tidy-data-set",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.3 Which variables should be included in the tidy data set?",
    "text": "2.3 Which variables should be included in the tidy data set?\nIn fitting my models, I actually plan only to use five predictors: sbp1, age, bmi1, diabetes and tobacco to model my outcome: sbp2. Even though I’m not planning to use all of these predictors in my models, I’m going to build a tidy data set including all of them anyway, so I can demonstrate solutions to some problems you might have.\nWhen you build your tidy data set in the next section, restrict it to the variables (outcomes, predictors and subj_id) that you will actually use in your modeling.\nIn building our tidy version of these data, we must:\n\ndeal with the ordering of levels in the multi-categorical variables nses, insurance and tobacco,\nchange the name of nses to something more helpful - I’ll use nbhd_ses as the new name1."
  },
  {
    "objectID": "sample-study2.html#checking-our-outcome-and-key-predictor",
    "href": "sample-study2.html#checking-our-outcome-and-key-predictor",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.4 Checking our Outcome and Key Predictor",
    "text": "2.4 Checking our Outcome and Key Predictor\n\ndf_stats(~ sbp2 + sbp1, data = hbp_study)\n\n  response min  Q1 median  Q3 max     mean       sd   n missing\n1     sbp2  77 121    133 144 203 133.7427 17.93623 999       0\n2     sbp1  81 124    136 147 205 136.5185 18.34717 999       0\n\n\nWe have no missing values in our outcome or our key predictor, and each of the values look plausible, so we’ll move on."
  },
  {
    "objectID": "sample-study2.html#checking-the-quantitative-predictors",
    "href": "sample-study2.html#checking-the-quantitative-predictors",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.5 Checking the Quantitative Predictors",
    "text": "2.5 Checking the Quantitative Predictors\nBesides sbp1 we have two other quantitative predictor candidates, age and bmi1.\n\ndf_stats(~ age + bmi1, data = hbp_study)\n\n  response   min     Q1 median     Q3   max     mean       sd   n missing\n1      age 33.00 52.000 59.000 66.000 83.00 58.68669 10.47551 999       0\n2     bmi1 16.72 27.865 32.145 38.365 74.65 33.72258  8.36090 994       5\n\n\nWe know that all subjects in these data had to be between 33 and 83 years of age in order to be included, so we’re happy to see that they are. We have five missing values (appropriately specified with NA) and no implausible values in our BMI values (I would use 16-80 as a plausible range of BMI values for adults.) Things look OK for now, as we’ll deal with the missing values last."
  },
  {
    "objectID": "sample-study2.html#checking-the-categorical-variables",
    "href": "sample-study2.html#checking-the-categorical-variables",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.6 Checking the Categorical Variables",
    "text": "2.6 Checking the Categorical Variables\nFor categorical variables, it’s always worth it to check to see whether the existing orders of the factor levels match the inherent order of the information, as well as whether there are any levels which we might want to collapse due to insufficient data, and whether there are any missing values.\n\n2.6.1 nses: home neighborhood’s socio-economic status\n\nhbp_study |&gt; tabyl(nses)\n\n     nses   n     percent valid_percent\n     High 154 0.154154154     0.1553986\n      Low 336 0.336336336     0.3390515\n   Middle 281 0.281281281     0.2835520\n Very Low 220 0.220220220     0.2219980\n     &lt;NA&gt;   8 0.008008008            NA\n\n\n\nThe order of nses, instead of the alphabetical (“High”, “Low”, “Middle”, “Very Low”), should go from “Very Low” to “Low” to “Middle” to “High”, or perhaps its reverse.\nLet’s fix that using the fct_relevel function from the forcats package, which is part of the tidyverse. While we’re at it, we’ll rename the variable nbhd_ses which is more helpful to me.\nThen we’ll see how many subjects fall in each category.\n\n\nhbp_study &lt;- hbp_study |&gt;\n  rename(nbhd_ses = nses) |&gt;\n  mutate(nbhd_ses = fct_relevel(nbhd_ses, \"Very Low\", \"Low\", \n                            \"Middle\", \"High\"))\nhbp_study |&gt; tabyl(nbhd_ses)\n\n nbhd_ses   n     percent valid_percent\n Very Low 220 0.220220220     0.2219980\n      Low 336 0.336336336     0.3390515\n   Middle 281 0.281281281     0.2835520\n     High 154 0.154154154     0.1553986\n     &lt;NA&gt;   8 0.008008008            NA\n\n\nWe have 8 missing values of nbhd_ses. We’ll deal with that later.\n\n\n2.6.2 tobacco: tobacco use history\n\nhbp_study |&gt; tabyl(tobacco)\n\n tobacco   n    percent valid_percent\n current 295 0.29529530     0.3022541\n   never 319 0.31931932     0.3268443\n    quit 362 0.36236236     0.3709016\n    &lt;NA&gt;  23 0.02302302            NA\n\n\n\nFor tobacco, instead of (“current”, “never”, “quit”), we want a new order: (“never”, “quit”, “current”).\n\n\nhbp_study &lt;- hbp_study |&gt;\n  mutate(tobacco = fct_relevel(tobacco, \"never\", \"quit\", \n                            \"current\"))\nhbp_study |&gt; count(tobacco)\n\n# A tibble: 4 × 2\n  tobacco     n\n  &lt;fct&gt;   &lt;int&gt;\n1 never     319\n2 quit      362\n3 current   295\n4 &lt;NA&gt;       23\n\n\nWe have 23 missing values of tobacco. Again, we’ll deal with that later.\n\n\n2.6.3 insurance: primary insurance type\n\nhbp_study |&gt; tabyl(insurance)\n\n insurance   n    percent\n  Medicaid 398 0.39839840\n  Medicare 402 0.40240240\n   Private 160 0.16016016\n Uninsured  39 0.03903904\n\n\n\nFor insurance, we’ll change the order to (“Medicare”, “Private”, “Medicaid”, “Uninsured”)\n\n\nhbp_study &lt;- hbp_study |&gt;\n  mutate(insurance = fct_relevel(insurance, \"Medicare\", \n                                 \"Private\", \"Medicaid\", \n                                 \"Uninsured\"))\nhbp_study |&gt; tabyl(insurance)\n\n insurance   n    percent\n  Medicare 402 0.40240240\n   Private 160 0.16016016\n  Medicaid 398 0.39839840\n Uninsured  39 0.03903904\n\n\nNote that any levels left out of a fct_relevel statement get included in their current order, after whatever levels have been specified.\n\n\n2.6.4 What about the subjects?\nIt is important to make sure that we have a unique (distinct) code (here, subj_id) for each row in the raw data set.\n\nnrow(hbp_study)\n\n[1] 999\n\nn_distinct(hbp_study |&gt; select(subj_id))\n\n[1] 999\n\n\nOK, that’s fine."
  },
  {
    "objectID": "sample-study2.html#dealing-with-missingness",
    "href": "sample-study2.html#dealing-with-missingness",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.7 Dealing with Missingness",
    "text": "2.7 Dealing with Missingness\nIn Study 2, we will take the following steps once we have ensured that any missing values are appropriately specified using NA.\n\nIf there are any missing values in your outcome, drop those subjects.\nIf there are any missing values in your key predictor, drop those subjects.\nBuild your codebook using the original data you have (including missing values.)\nOnce you have built the codebook, perform single imputation with the mice package to obtain your analytic sample, which you will then partition into a training and testing sample, and then use for the remainder of the work (everything after the codebook.)"
  },
  {
    "objectID": "sample-study2.html#steps-1-and-2-missing-values-in-our-outcome-or-key-predictor",
    "href": "sample-study2.html#steps-1-and-2-missing-values-in-our-outcome-or-key-predictor",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.8 Steps 1 and 2: Missing values in our outcome or key predictor?",
    "text": "2.8 Steps 1 and 2: Missing values in our outcome or key predictor?\n\nmiss_var_summary(hbp_study)\n\n# A tibble: 12 × 3\n   variable  n_miss pct_miss\n   &lt;chr&gt;      &lt;int&gt;    &lt;num&gt;\n 1 tobacco       23    2.30 \n 2 nbhd_ses       8    0.801\n 3 bmi1           5    0.501\n 4 subj_id        0    0    \n 5 age            0    0    \n 6 sex            0    0    \n 7 diabetes       0    0    \n 8 sbp1           0    0    \n 9 insurance      0    0    \n10 statin         0    0    \n11 diuretic       0    0    \n12 sbp2           0    0    \n\nmiss_case_table(hbp_study)\n\n# A tibble: 2 × 3\n  n_miss_in_case n_cases pct_cases\n           &lt;int&gt;   &lt;int&gt;     &lt;dbl&gt;\n1              0     963     96.4 \n2              1      36      3.60\n\n\nWe are missing data for 36 of our 999 subjects, but we don’t have any missing values in either our outcome sbp2 or our key predictor sbp1, so we’ll move on to build our codebook."
  },
  {
    "objectID": "sample-study2.html#the-codebook",
    "href": "sample-study2.html#the-codebook",
    "title": "431 Project B Sample Study 2 Report",
    "section": "3.1 The Codebook",
    "text": "3.1 The Codebook\n\n\n\n\n\n\nNote\n\n\n\nBelow, I’ve demonstrated the task of building a set of variable descriptions for a larger set of predictors than I actually intend to use, just to illustrate.\nThe 12 variables in the hbp_study tibble are as follows.\n\n\n\n\n\n\n\n\nVariable\nType\nDescription / Levels\n\n\n\n\nsubj_id\nCharacter\nsubject code (A001-A999)\n\n\nsbp2\nQuantitative\noutcome variable, SBP after 18 months, in mm Hg\n\n\nsbp1\nQuantitative\nkey predictor baseline SBP (systolic blood pressure), in mm Hg\n\n\nage\nQuantitative\nage of subject at baseline, in years\n\n\nsex\nBinary\nMale or Female\n\n\ndiabetes\nBinary\nDoes subject have a diabetes diagnosis: No or Yes\n\n\nnbhd_ses\n4 level Cat.\nSocio-economic status of subject’s home neighborhood: Very Low, Low, Middle and High\n\n\nbmi1\nQuantitative\nsubject’s body-mass index at baseline\n\n\ninsurance\n4 level Cat.\nsubject’s insurance status at baseline: Medicare, Private, Medicaid, Uninsured\n\n\ntobacco\n3 level Cat.\nsubject’s tobacco use at baseline: never, quit (former), current\n\n\nstatin\nBinary\n1 = statin prescription at baseline, else 0\n\n\ndiuretic\nBinary\n1 = diuretic prescription at baseline, else 0\n\n\n\n\n\nIn fitting my models, I actually plan only to use five predictors: sbp1, age, bmi1, diabetes and tobacco to model my outcome: sbp2. So let’s create that data set as a tibble, and provide its set of variable descriptions.\n\nhbp_a1 &lt;- hbp_study |&gt;\n  select(subj_id, sbp2, sbp1, age, bmi1, diabetes, tobacco) \n\nThe 7 variables in the hbp_a1 tibble are as follows.\n\n\n\n\n\n\n\n\nVariable\nType\nDescription / Levels\n\n\n\n\nsubj_id\nCharacter\nsubject code (A001-A999)\n\n\nsbp2\nQuantitative\noutcome variable, SBP after 18 months, in mm Hg\n\n\nsbp1\nQuantitative\nkey predictor baseline SBP (systolic blood pressure), in mm Hg\n\n\nage\nQuantitative\nage of subject at baseline, in years\n\n\nbmi1\nQuantitative\nsubject’s body-mass index at baseline\n\n\ndiabetes\nBinary\nDoes subject have a diabetes diagnosis: No or Yes\n\n\ntobacco\n3 level Cat.\nsubject’s tobacco use at baseline: never, quit (former), current"
  },
  {
    "objectID": "sample-study2.html#print-the-tibble",
    "href": "sample-study2.html#print-the-tibble",
    "title": "431 Project B Sample Study 2 Report",
    "section": "3.2 Print the Tibble",
    "text": "3.2 Print the Tibble\nFirst, we’ll provide a printout of the tibble, which confirms that we have one.\n\nhbp_a1\n\n# A tibble: 999 × 7\n   subj_id  sbp2  sbp1   age  bmi1 diabetes tobacco\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n 1 A0001     138   147    58  24.4 No       never  \n 2 A0004     134   134    65  50.5 No       never  \n 3 A0005     140   170    61  29.8 Yes      current\n 4 A0013     143   118    51  41.8 No       quit   \n 5 A0015     162   132    61  31.0 No       never  \n 6 A0017     141   110    45  33.0 No       current\n 7 A0018     101   127    40  36.3 Yes      never  \n 8 A0019     154   152    50  30.8 Yes      never  \n 9 A0020     111   125    43  23.1 No       current\n10 A0025     154   161    46  NA   No       never  \n# ℹ 989 more rows\n\n\nOK. All set. Now we show the data_codebook() results."
  },
  {
    "objectID": "sample-study2.html#data_codebook-results",
    "href": "sample-study2.html#data_codebook-results",
    "title": "431 Project B Sample Study 2 Report",
    "section": "3.3 data_codebook() results",
    "text": "3.3 data_codebook() results\n\ndata_codebook(hbp_a1 |&gt; select(-subj_id))\n\nselect(hbp_a1, -subj_id) (999 rows and 6 variables, 6 shown)\n\nID | Name     | Type        |  Missings |         Values |           N\n---+----------+-------------+-----------+----------------+------------\n1  | sbp2     | numeric     |  0 (0.0%) |      [77, 203] |         999\n---+----------+-------------+-----------+----------------+------------\n2  | sbp1     | numeric     |  0 (0.0%) |      [81, 205] |         999\n---+----------+-------------+-----------+----------------+------------\n3  | age      | numeric     |  0 (0.0%) |       [33, 83] |         999\n---+----------+-------------+-----------+----------------+------------\n4  | bmi1     | numeric     |  5 (0.5%) | [16.72, 74.65] |         994\n---+----------+-------------+-----------+----------------+------------\n5  | diabetes | categorical |  0 (0.0%) |             No | 668 (66.9%)\n   |          |             |           |            Yes | 331 (33.1%)\n---+----------+-------------+-----------+----------------+------------\n6  | tobacco  | categorical | 23 (2.3%) |          never | 319 (32.7%)\n   |          |             |           |           quit | 362 (37.1%)\n   |          |             |           |        current | 295 (30.2%)\n----------------------------------------------------------------------\n\n\nWe should (and do) see no implausible values here, and our categorical variables are treated as factors with a rational ordering for the levels."
  },
  {
    "objectID": "sample-study2.html#our-single-imputation",
    "href": "sample-study2.html#our-single-imputation",
    "title": "431 Project B Sample Study 2 Report",
    "section": "3.4 Our Single Imputation",
    "text": "3.4 Our Single Imputation\nWe will now assuming MISSING AT RANDOM and singly impute the missing values in hbp_a1, creating a new analytic tibble called hbp_a2, which we will use for the rest of our work.\n\nset.seed(4311)\nhbp_imp &lt;- mice(hbp_a1, m = 1, printFlag = FALSE)\n\nWarning: Number of logged events: 1\n\nhbp_a2 &lt;- complete(hbp_imp)\nn_miss(hbp_a2)\n\n[1] 0"
  },
  {
    "objectID": "sample-study2.html#partition-the-data",
    "href": "sample-study2.html#partition-the-data",
    "title": "431 Project B Sample Study 2 Report",
    "section": "3.5 Partition the Data",
    "text": "3.5 Partition the Data\nFirst, we should check that our subject identifying codes are unique to each row of our analytic data.\n\nc(nrow(hbp_a2), n_distinct(hbp_a2$subj_id))\n\n[1] 999 999\n\n\nOK. Since those two values match, we should be ready to partition. We’ll put 70% of the data in the training sample (hbp_train) leaving the other 30% for the test sample (hbp_test).\n\nset.seed(4312)\nhbp_train &lt;- hbp_a2 |&gt; slice_sample(prop = 0.7, replace = FALSE)\nhbp_test &lt;- anti_join(hbp_a2, hbp_train, by = \"subj_id\")"
  },
  {
    "objectID": "sample-study2.html#visualizing-the-outcome-distribution",
    "href": "sample-study2.html#visualizing-the-outcome-distribution",
    "title": "431 Project B Sample Study 2 Report",
    "section": "5.1 Visualizing the Outcome Distribution",
    "text": "5.1 Visualizing the Outcome Distribution\nI see at least three potential graphs to use to describe the distribution of our outcome variable, sbp2. Again, remember we’re using only the training sample here.\n\nA boxplot, probably accompanied by a violin plot to show the shape of the distribution more honestly.\nA histogram, which could perhaps be presented as a density plot with a Normal distribution superimposed.\nA Normal Q-Q plot to directly assess Normality.\n\nI expect you to show at least two of these three, but I will display all three here. Should we see substantial skew in the outcome data, we will want to consider an appropriate transformation, and then display the results of that transformation, as well.\nWARNING: Please note that I am deliberately showing you plots that are less finished than I hope you will provide.\n\nThe coloring is dull or non-existent.\nThe theme is the default gray and white grid that lots of people dislike.\nThere are no meaningful titles or subtitles.\nThe axis labels select the default settings, and use incomprehensible variable names.\nThe coordinates aren’t flipped when that might be appropriate.\nI expect a much nicer presentation in your final work. Use the class slides and course text for good ideas.\n\n\nviz1 &lt;- ggplot(hbp_train, aes(x = \"\", y = sbp2)) +\n  geom_violin() +\n  geom_boxplot(width = 0.25)\n\nviz2 &lt;- ggplot(hbp_train, aes(x = sbp2)) +\n  geom_histogram(bins = 30, col = \"white\")\n\nviz3 &lt;- ggplot(hbp_train, aes(sample = sbp2)) +\n  geom_qq() + geom_qq_line()\n\nviz1 + viz2 + viz3 +\n  plot_annotation(title = \"Less-Than-Great Plots of My Outcome's Distribution\",\n                  subtitle = \"complete with a rotten title, default axis labels and bad captions\")\n\n\n\n\n\n\n\n\nLater, we’ll augment this initial look at the outcome data with a Box-Cox plot to suggest a potential transformation. Should you decide to make such a transformation, remember to return here to plot the results for your new and transformed outcome."
  },
  {
    "objectID": "sample-study2.html#numerical-summary-of-the-outcome",
    "href": "sample-study2.html#numerical-summary-of-the-outcome",
    "title": "431 Project B Sample Study 2 Report",
    "section": "5.2 Numerical Summary of the Outcome",
    "text": "5.2 Numerical Summary of the Outcome\nAssuming you plan no transformation of the outcome (and in our case, I am happy that the outcome data appear reasonably well-modeled by the Normal distribution) then you should just summarize the training data, with your favorite tool for that task. That might be:\n\nlovedist() from our Love-431.R script, or\nfavstats from the mosaic package, as shown below, or\nsomething else, I guess.\n\nBut show ONE of these choices, and not all of them. Make a decision and go with it!\n\nfavstats(~ sbp2, data = hbp_train)\n\n min  Q1 median  Q3 max     mean      sd   n missing\n  90 121    133 143 200 133.1645 17.6876 699       0"
  },
  {
    "objectID": "sample-study2.html#numerical-summaries-of-the-predictors",
    "href": "sample-study2.html#numerical-summaries-of-the-predictors",
    "title": "431 Project B Sample Study 2 Report",
    "section": "5.3 Numerical Summaries of the Predictors",
    "text": "5.3 Numerical Summaries of the Predictors\nWe also need an appropriate set of numerical summaries of each predictor variable, in the training data. The inspect function provides a way to get results like favstats, but for an entire data frame.\n\nhbp_train |&gt; select(-subj_id, -sbp2) |&gt; \n  inspect()\n\n\ncategorical variables:  \n      name  class levels   n missing\n1 diabetes factor      2 699       0\n2  tobacco factor      3 699       0\n                                   distribution\n1 No (66.1%), Yes (33.9%)                      \n2 quit (37.5%), never (33.5%) ...              \n\nquantitative variables:  \n  name   class   min      Q1 median      Q3    max      mean        sd   n\n1 sbp1 numeric 83.00 124.000 135.00 146.000 203.00 135.89843 17.777992 699\n2  age numeric 33.00  52.000  59.00  66.000  83.00  58.78541 10.442077 699\n3 bmi1 numeric 16.72  27.715  32.26  38.255  74.65  33.69518  8.448366 699\n  missing\n1       0\n2       0\n3       0\n\n\nNext, we will build and interpret a scatterplot matrix to describe the associations (both numerically and graphically) between the outcome and all predictors.\n\nWe’ll also use a Box-Cox plot to investigate whether a transformation of our outcome is suggested, and\ndescribe what a correlation matrix suggests about collinearity between candidate predictors."
  },
  {
    "objectID": "sample-study2.html#scatterplot-matrix",
    "href": "sample-study2.html#scatterplot-matrix",
    "title": "431 Project B Sample Study 2 Report",
    "section": "5.4 Scatterplot Matrix",
    "text": "5.4 Scatterplot Matrix\nHere, we will build a scatterplot matrix (or two) to show the relationship between our outcome and the predictors. I’ll demonstrate the use of ggpairs from the GGally package.\n\nIf you have more than five predictors (as we do in our case) you should build two scatterplot matrices, each ending with the outcome. Anything more than one outcome and five predictors becomes unreadable in Professor Love’s view.\nIf you have a multi-categorical predictor with more than four categories, that predictor will be very difficult to see and explore in the scatterplot matrix produced.\n\n\ntemp &lt;- hbp_train |&gt; \n  select(sbp1, age, bmi1, diabetes, tobacco, sbp2) \n\nggpairs(temp, title = \"Scatterplot Matrix\",\n        lower = list(combo = wrap(\"facethist\", bins = 20)))\n\n\n\n\n\n\n\n\nAt the end of this section, you should provide some discussion of the distribution of any key predictors, and their relationship to the outcome (all of that is provided in the bottom row if you place the outcome last, as you should, in selecting variables for the plot.)\nHINT: For categorical variables, your efforts in this regard to summarize the relationships you see may be challenging. Your comments would be aided by the judicious use of numerical summaries. For example, suppose you want to study the relationship between tobacco use and sbp2, then you probably want to run and discuss the following results, in addition to the scatterplot matrix above.\n\nfavstats(sbp2 ~ tobacco, data = hbp_train)\n\n  tobacco min     Q1 median    Q3 max     mean       sd   n missing\n1   never  95 126.00    135 144.0 186 135.5385 16.49661 234       0\n2    quit  95 119.25    130 141.0 182 131.0992 16.55542 262       0\n3 current  90 119.00    134 145.5 200 133.0936 20.02340 203       0"
  },
  {
    "objectID": "sample-study2.html#collinearity-checking",
    "href": "sample-study2.html#collinearity-checking",
    "title": "431 Project B Sample Study 2 Report",
    "section": "5.5 Collinearity Checking",
    "text": "5.5 Collinearity Checking\nNext, we’ll take a brief look at potential collinearity. Remember that we want to see strong correlations between our outcome and the predictors, but relatively modest correlations between the predictors.\nNone of the numeric candidate predictors show any substantial correlation with each other. The largest Pearson correlation (in absolute value) between predictors is (-0.239) for age and bmi1, and that’s not strong. If we did see signs of meaningful collinearity, we might rethink our selected set of predictors.\nI’ll recommend later that you run a generalized VIF (variance inflation factor) calculation2 after fitting your kitchen sink model just to see if anything pops up (in my case, it won’t.)"
  },
  {
    "objectID": "sample-study2.html#boxcox-function-to-assess-need-for-transformation-of-our-outcome",
    "href": "sample-study2.html#boxcox-function-to-assess-need-for-transformation-of-our-outcome",
    "title": "431 Project B Sample Study 2 Report",
    "section": "5.6 boxCox function to assess need for transformation of our outcome",
    "text": "5.6 boxCox function to assess need for transformation of our outcome\nTo use the boxCox approach here, we need to ensure that the distribution of our outcome, sbp2, includes strictly positive values. We can see from our numerical summary earlier that the minimum sbp2 in our hbp_train sample is 90, so we’re OK.\n\nNote that I am restricting myself here to the five predictors I actually intend to use in building models.\nAlthough we’re generally using a 90% confidence interval in this project, we won’t worry about that issue in the boxCox plot, and instead just look at the point estimate from powerTransform.\nThese commands (boxCox and powerTransform) come from the car package.\n\n\nmodel_temp &lt;- lm(sbp2 ~ sbp1 + age + bmi1 + diabetes + tobacco,\n                 data = hbp_train)\n\nboxCox(model_temp)\n\n\n\n\n\n\n\n\nThe estimated power transformation is about 0.5, which looks like a square root transformation of sbp2 is useful. Given that I’m using another measure of sbp, specifically, sbp1 to predict sbp2, perhaps I want to transform that, too?\n\np1 &lt;- ggplot(hbp_train, aes(x = sbp1, y = sqrt(sbp2))) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) + \n  geom_smooth(method = \"lm\", col = \"red\", formula = y ~ x, se = FALSE) +\n  labs(title = \"SQRT(sbp2) vs. SBP1\")\n\np2 &lt;- ggplot(hbp_train, aes(x = sqrt(sbp1), y = sqrt(sbp2))) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) + \n  geom_smooth(method = \"lm\", col = \"red\", formula = y ~ x, se = FALSE) + \n  labs(title = \"SQRT(sbp2) vs. SQRT(sbp1)\")\n\np1 + p2\n\n\n\n\n\n\n\n\nI don’t see an especially large difference between these two plots. It is up to you to decide whether a transformation suggested by boxCox should be applied to your data.\n\nFor the purposes of this project, you should stick to transformations of strictly positive outcomes, and to the square root (power = 0.5), square (power = 2), logarithm (power = 0) and inverse (power = -1) transformations. Don’t make the transformation without being able to interpret the result well.\nFeel encouraged to scale your transformations (by multiplying or dividing by a constant) so that most of the transformed values wind up between 0 and 100 or 0 and 1000, if you like.\nIf you do decide to include a transformation of your outcome in fitting models, be sure to back-transform any predictions you make at the end of the study so that we can understand the prediction error results.\nIf your outcome data are substantially multimodal, I wouldn’t treat the boxCox results as meaningful.\n\nI’m going to use the square root transformation for both my outcome and for the key predictor, but I don’t think it makes a big difference. I’m doing it mostly so that I can show you how to back-transform later."
  },
  {
    "objectID": "sample-study2.html#fittingsummarizing-the-kitchen-sink-model",
    "href": "sample-study2.html#fittingsummarizing-the-kitchen-sink-model",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.1 Fitting/Summarizing the Kitchen Sink model",
    "text": "6.1 Fitting/Summarizing the Kitchen Sink model\nOur “kitchen sink” or “big” model predicts the square root of sbp2 using the predictors (square root of sbp1), age, bmi1, diabetes and tobacco.\nFirst, we’ll use mutate to create our two new transformed variables.\n\nhbp_train &lt;- hbp_train |&gt; \n  mutate(sbp2_tr = sqrt(sbp2), sbp1_tr = sqrt(sbp1))\n\nNext, we’ll fit our “big” (kitchen sink) model.\n\nmodel_big &lt;- lm(sbp2_tr ~ sbp1_tr + age + bmi1 + diabetes + tobacco, \n                data = hbp_train)\n\n\nmodel_performance(model_big)\n\n# Indices of model performance\n\nAIC    |   AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------\n1525.4 | 1525.6 | 1561.8 | 0.128 |     0.121 | 0.712 | 0.716"
  },
  {
    "objectID": "sample-study2.html#effect-sizes-coefficient-estimates",
    "href": "sample-study2.html#effect-sizes-coefficient-estimates",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.2 Effect Sizes: Coefficient Estimates",
    "text": "6.2 Effect Sizes: Coefficient Estimates\nSpecify the size and magnitude of all coefficients, providing estimated effect sizes with 90% confidence intervals.\n\nmodel_parameters(model_big, ci = 0.90)\n\nParameter         | Coefficient |       SE |         90% CI | t(692) |      p\n-----------------------------------------------------------------------------\n(Intercept)       |        7.31 |     0.47 | [ 6.53,  8.08] |  15.51 | &lt; .001\nsbp1 tr           |        0.34 |     0.04 | [ 0.28,  0.40] |   9.39 | &lt; .001\nage               |    3.58e-03 | 2.82e-03 | [ 0.00,  0.01] |   1.27 | 0.205 \nbmi1              |    4.18e-03 | 3.49e-03 | [ 0.00,  0.01] |   1.20 | 0.231 \ndiabetes [Yes]    |   -9.27e-03 |     0.06 | [-0.10,  0.09] |  -0.16 | 0.873 \ntobacco [quit]    |       -0.15 |     0.07 | [-0.25, -0.04] |  -2.23 | 0.026 \ntobacco [current] |       -0.05 |     0.07 | [-0.16,  0.07] |  -0.63 | 0.530 \n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation."
  },
  {
    "objectID": "sample-study2.html#describing-the-equation",
    "href": "sample-study2.html#describing-the-equation",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.3 Describing the Equation",
    "text": "6.3 Describing the Equation\nThis model implies for the key predictor (sbp_1) that:\n\nPoint Estimate: If we had two subjects with the same values of age, BMI, diabetes and tobacco status, but A had a baseline square root of SBP of, for example, 12 (so an SBP at baseline of 144) and B had a baseline square root of SBP one unit lower, so for example, 11 (so an SBP at baseline of 121) our model_big predicts that the square root of subject A’s SBP at 18 months will be 0.34 points higher (90% CI: 0.28, 0.40) than that of subject B.\n90% Confidence Interval: Our model_big estimates the slope of the square root of sbp_1 to be 0.34 in the participants in our study. When we generalize beyond study participants to the population they were selected at random from, then our data are compatible (at the 90% confidence level) with population slopes between 0.28 and 0.40 for our transformed sbp_1.\n\nYou should also provide a description of the meaning (especially the direction) of the point estimates of the other coefficients in your model being sure to interpret the coefficients as having meaning holding all other predictors constant, but I’ll skip that here."
  },
  {
    "objectID": "sample-study2.html#backwards-stepwise-elimination",
    "href": "sample-study2.html#backwards-stepwise-elimination",
    "title": "431 Project B Sample Study 2 Report",
    "section": "7.1 Backwards Stepwise Elimination",
    "text": "7.1 Backwards Stepwise Elimination\n\nstep(model_big)\n\nStart:  AIC=-460.28\nsbp2_tr ~ sbp1_tr + age + bmi1 + diabetes + tobacco\n\n           Df Sum of Sq    RSS     AIC\n- diabetes  1     0.013 354.66 -462.26\n- bmi1      1     0.736 355.39 -460.83\n- age       1     0.826 355.48 -460.65\n&lt;none&gt;                  354.65 -460.28\n- tobacco   2     2.658 357.31 -459.06\n- sbp1_tr   1    45.165 399.82 -378.49\n\nStep:  AIC=-462.26\nsbp2_tr ~ sbp1_tr + age + bmi1 + tobacco\n\n          Df Sum of Sq    RSS     AIC\n- bmi1     1     0.722 355.39 -462.83\n- age      1     0.820 355.49 -462.64\n&lt;none&gt;                 354.66 -462.26\n- tobacco  2     2.677 357.34 -461.00\n- sbp1_tr  1    45.152 399.82 -380.49\n\nStep:  AIC=-462.83\nsbp2_tr ~ sbp1_tr + age + tobacco\n\n          Df Sum of Sq    RSS     AIC\n- age      1     0.457 355.84 -463.93\n&lt;none&gt;                 355.39 -462.83\n- tobacco  2     2.732 358.12 -461.48\n- sbp1_tr  1    46.258 401.65 -379.30\n\nStep:  AIC=-463.93\nsbp2_tr ~ sbp1_tr + tobacco\n\n          Df Sum of Sq    RSS     AIC\n&lt;none&gt;                 355.84 -463.93\n- tobacco  2     2.452 358.30 -463.13\n- sbp1_tr  1    46.423 402.27 -380.22\n\n\n\nCall:\nlm(formula = sbp2_tr ~ sbp1_tr + tobacco, data = hbp_train)\n\nCoefficients:\n   (Intercept)         sbp1_tr     tobaccoquit  tobaccocurrent  \n       7.62034         0.34114        -0.14135        -0.07367  \n\n\nThe backwards selection stepwise approach suggests a model with sqrt(sbp1) and tobacco, but not age, bmi1 or diabetes."
  },
  {
    "objectID": "sample-study2.html#fitting-the-small-model",
    "href": "sample-study2.html#fitting-the-small-model",
    "title": "431 Project B Sample Study 2 Report",
    "section": "7.2 Fitting the “small” model",
    "text": "7.2 Fitting the “small” model\n\nmodel_small &lt;- lm(sqrt(sbp2) ~ sqrt(sbp1) + tobacco, data = hbp_train)\n\nmodel_performance(model_small)\n\n# Indices of model performance\n\nAIC    |   AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------\n5903.8 | 5903.9 | 5926.6 | 0.126 |     0.122 | 0.713 | 0.716"
  },
  {
    "objectID": "sample-study2.html#effect-sizes-coefficient-estimates-1",
    "href": "sample-study2.html#effect-sizes-coefficient-estimates-1",
    "title": "431 Project B Sample Study 2 Report",
    "section": "7.3 Effect Sizes: Coefficient Estimates",
    "text": "7.3 Effect Sizes: Coefficient Estimates\n\nmodel_parameters(model_small, ci = 0.90)\n\nParameter         | Coefficient |   SE |         90% CI | t(695) |      p\n-------------------------------------------------------------------------\n(Intercept)       |        7.62 | 0.42 | [ 6.92,  8.32] |  18.03 | &lt; .001\nsbp1 [sqrt]       |        0.34 | 0.04 | [ 0.28,  0.40] |   9.52 | &lt; .001\ntobacco [quit]    |       -0.14 | 0.06 | [-0.25, -0.03] |  -2.19 | 0.029 \ntobacco [current] |       -0.07 | 0.07 | [-0.19,  0.04] |  -1.07 | 0.285 \n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation."
  },
  {
    "objectID": "sample-study2.html#interpreting-the-small-model-regression-equation",
    "href": "sample-study2.html#interpreting-the-small-model-regression-equation",
    "title": "431 Project B Sample Study 2 Report",
    "section": "7.4 Interpreting the Small Model Regression Equation",
    "text": "7.4 Interpreting the Small Model Regression Equation\nHere, we again need to specify the size and magnitude of all coefficients, providing estimated effect sizes with 90% confidence intervals.\nI’ll skip the necessary English sentences here in the demo that explain the meaning of the estimates in our model. You should provide a detailed explanation of the point estimates for all slopes, and of the confidence interval for the slope of your key predictor."
  },
  {
    "objectID": "sample-study2.html#compare-performance",
    "href": "sample-study2.html#compare-performance",
    "title": "431 Project B Sample Study 2 Report",
    "section": "8.1 Compare Performance",
    "text": "8.1 Compare Performance\n\nplot(compare_performance(model_big, model_small))\n\nWhen comparing models, please note that probably not all models were fit\n  from same data.\n\n\n\n\n\n\n\n\n\n\ncompare_performance(model_big, model_small, rank = TRUE)\n\nWhen comparing models, please note that probably not all models were fit\n  from same data.\n\n\n# Comparison of Model Performance Indices\n\nName        | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights\n---------------------------------------------------------------------\nmodel_big   |    lm | 0.128 |     0.121 | 0.712 | 0.716 |        1.00\nmodel_small |    lm | 0.126 |     0.122 | 0.713 | 0.716 |    0.00e+00\n\nName        | AICc weights | BIC weights | Performance-Score\n------------------------------------------------------------\nmodel_big   |         1.00 |        1.00 |            71.43%\nmodel_small |     0.00e+00 |    0.00e+00 |            28.57%\n\n\nThese results can be summarized as follows:\n\nmodel_big (naturally) has a stronger \\(R^2\\) result, but it also has a better result for RMSE, AIC and BIC.\nmodel_small has a stronger result for Adjusted \\(R^2\\) and Sigma."
  },
  {
    "objectID": "sample-study2.html#assessing-assumptions",
    "href": "sample-study2.html#assessing-assumptions",
    "title": "431 Project B Sample Study 2 Report",
    "section": "8.2 Assessing Assumptions",
    "text": "8.2 Assessing Assumptions\nHere, we should run a set of residual plots for each model, with check_model() and interpret your findings in each case, carefully. I’ll show my plots for model_big here.\n\n8.2.1 Checking model_big\n\ncheck_model(model_big)\n\n\n\n\n\n\n\n\nI see no serious problems with the assumptions of linearity, Normality and constant variance, nor do I see any highly influential points in our big model.\n\n\n8.2.2 Does collinearity have a meaningful impact?\nIf we fit models with multiple predictors, then we might want to augment the plot above by assessing variance inflation factors to see the potential impact of collinearity.\n\nvif(model_big)\n\n             GVIF Df GVIF^(1/(2*Df))\nsbp1_tr  1.014160  1        1.007055\nage      1.181857  1        1.087132\nbmi1     1.185957  1        1.089017\ndiabetes 1.027252  1        1.013534\ntobacco  1.165447  2        1.039018\n\n\nWe’d need to see a generalized variance inflation factor above 5 for collinearity to be a meaningful concern, so we should be fine in our big model. Our small model also has multiple predictors, but collinearity cannot be an issue, since it’s just a subset of our big model, which didn’t have a collinearity problem."
  },
  {
    "objectID": "sample-study2.html#comparing-the-models",
    "href": "sample-study2.html#comparing-the-models",
    "title": "431 Project B Sample Study 2 Report",
    "section": "8.3 Comparing the Models",
    "text": "8.3 Comparing the Models\nBased on the training sample, you should draw a conclusion. So far, I will support the larger model. It has (slightly) better performance on the fit quality measures, and each model shows no serious problems with regression assumptions."
  },
  {
    "objectID": "sample-study2.html#calculating-prediction-errors",
    "href": "sample-study2.html#calculating-prediction-errors",
    "title": "431 Project B Sample Study 2 Report",
    "section": "9.1 Calculating Prediction Errors",
    "text": "9.1 Calculating Prediction Errors\n\n9.1.1 Big Model: Back-Transformation and Calculating Fits/Residuals\nFirst, we need to create our transformed data in our test data.\n\nhbp_test &lt;- hbp_test |&gt; mutate(sbp1_tr = sqrt(sbp1), sbp2_tr = sqrt(sbp2))\n\nWe’ll use the augment function from the broom package to help us here, and create sbp2_fit to hold the fitted values on the original sbp2 scale after back-transformation (by squaring the predictions on the square root scale) and then sbp2_res to hold the residuals (prediction errors) we observe using the big model on the hbp_test data.\n\naug_big &lt;- augment(model_big, newdata = hbp_test) |&gt; \n  mutate(mod_name = \"big\",\n         sbp2_fit = .fitted^2,\n         sbp2_res = sbp2 - sbp2_fit) |&gt;\n  select(subj_id, mod_name, sbp2, sbp2_fit, sbp2_res, everything())\n\nhead(aug_big,3)\n\n# A tibble: 3 × 14\n  subj_id mod_name  sbp2 sbp2_fit sbp2_res  sbp1   age  bmi1 diabetes tobacco\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 A0001   big        138     137.    0.886   147    58  24.4 No       never  \n2 A0018   big        101     130.  -28.9     127    40  36.3 Yes      never  \n3 A0032   big        147     129.   18.1     130    58  32.8 No       quit   \n# ℹ 4 more variables: sbp1_tr &lt;dbl&gt;, sbp2_tr &lt;dbl&gt;, .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;\n\n\n\n\n9.1.2 Small Model: Back-Transformation and Calculating Fits/Residuals\nWe’ll do the same thing, but using the small model in the hbp_test data.\n\naug_small &lt;- augment(model_small, newdata = hbp_test) |&gt; \n  mutate(mod_name = \"small\",\n         sbp2_fit = .fitted^2,\n         sbp2_res = sbp2 - sbp2_fit) |&gt;\n  select(subj_id, mod_name, sbp2, sbp2_fit, sbp2_res, everything())\n\nhead(aug_small,3)\n\n# A tibble: 3 × 14\n  subj_id mod_name  sbp2 sbp2_fit sbp2_res  sbp1   age  bmi1 diabetes tobacco\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 A0001   small      138     138.   -0.215   147    58  24.4 No       never  \n2 A0018   small      101     131.  -30.4     127    40  36.3 Yes      never  \n3 A0032   small      147     129.   17.8     130    58  32.8 No       quit   \n# ℹ 4 more variables: sbp1_tr &lt;dbl&gt;, sbp2_tr &lt;dbl&gt;, .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;\n\n\n\n\n9.1.3 Combining the Results\n\ntest_comp &lt;- union(aug_big, aug_small) |&gt;\n  arrange(subj_id, mod_name)\n\ntest_comp |&gt; head()\n\n# A tibble: 6 × 14\n  subj_id mod_name  sbp2 sbp2_fit sbp2_res  sbp1   age  bmi1 diabetes tobacco\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 A0001   big        138     137.    0.886   147    58  24.4 No       never  \n2 A0001   small      138     138.   -0.215   147    58  24.4 No       never  \n3 A0002   big        138     133.    5.43    130    64  30.8 No       never  \n4 A0002   small      138     132.    5.52    130    64  30.8 No       never  \n5 A0003   big        131     128.    2.87    130    52  29.4 No       quit   \n6 A0003   small      131     129.    1.75    130    52  29.4 No       quit   \n# ℹ 4 more variables: sbp1_tr &lt;dbl&gt;, sbp2_tr &lt;dbl&gt;, .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;\n\n\nGiven this test_comp tibble, including predictions and residuals from the kitchen sink model on our test data, we can now:\n\nVisualize the prediction errors from each model.\nSummarize those errors across each model.\nIdentify the “worst fitting” subject for each model in the test sample.\n\nThe next few subsections actually do these things."
  },
  {
    "objectID": "sample-study2.html#visualizing-the-predictions",
    "href": "sample-study2.html#visualizing-the-predictions",
    "title": "431 Project B Sample Study 2 Report",
    "section": "9.2 Visualizing the Predictions",
    "text": "9.2 Visualizing the Predictions\n\nggplot(test_comp, aes(x = sbp2_fit, y = sbp2)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, lty = \"dashed\") + \n  geom_smooth(method = \"loess\", col = \"blue\", se = FALSE, formula = y ~ x) +\n  facet_wrap( ~ mod_name, labeller = \"label_both\") +\n  labs(x = \"Predicted sbp2\",\n       y = \"Observed sbp2\",\n       title = \"Observed vs. Predicted sbp2\",\n       subtitle = \"Comparing Big to Small Model in Test Sample\",\n       caption = \"Dashed line is where Observed = Predicted\")\n\n\n\n\n\n\n\n\nI’m not seeing a lot of difference between the models in terms of the adherence of the points to the dashed line. The models seem to be making fairly similar errors."
  },
  {
    "objectID": "sample-study2.html#summarizing-the-errors",
    "href": "sample-study2.html#summarizing-the-errors",
    "title": "431 Project B Sample Study 2 Report",
    "section": "9.3 Summarizing the Errors",
    "text": "9.3 Summarizing the Errors\nCalculate the mean absolute prediction error (MAPE), the root mean squared prediction error (RMSPE) and the maximum absolute error across the predictions made by each model.\n\ntest_comp |&gt;\n  group_by(mod_name) |&gt;\n  summarise(n = n(),\n            MAPE = mean(abs(sbp2_res)), \n            RMSPE = sqrt(mean(sbp2_res^2)),\n            max_error = max(abs(sbp2_res)),\n            R2_val = cor(sbp2, sbp2_fit)^2)\n\n# A tibble: 2 × 6\n  mod_name     n  MAPE RMSPE max_error R2_val\n  &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 big        300  13.7  17.3      48.8  0.127\n2 small      300  13.7  17.3      49.2  0.126\n\n\nThis is a table Dr. Love will definitely need to see during your presentation.\nIn this case, all four of these summaries are better for the bigger model.\nThese models suggest an average error in predicting systolic blood pressure (using MAPE) of more than 13 mm Hg. That’s not great on the scale of systolic blood pressure, I think. In addition, our validated \\(R^2\\) values here are only slightly worse (in either model) than what we saw in our training sample.\n\n9.3.1 Identify the largest errors\nIdentify the subject(s) where that maximum prediction error was made by each model, and the observed and model-fitted values of sbp2 for that subject in each case.\n\ntemp1 &lt;- aug_big |&gt;\n  filter(abs(sbp2_res) == max(abs(sbp2_res)))\n\ntemp2 &lt;- aug_small |&gt;\n  filter(abs(sbp2_res) == max(abs(sbp2_res)))\n\nbind_rows(temp1, temp2)\n\n# A tibble: 2 × 14\n  subj_id mod_name  sbp2 sbp2_fit sbp2_res  sbp1   age  bmi1 diabetes tobacco\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 A0703   big        178     129.     48.8   130    64  30.0 No       quit   \n2 A0265   small      180     131.     49.2   130    65  27.3 No       current\n# ℹ 4 more variables: sbp1_tr &lt;dbl&gt;, sbp2_tr &lt;dbl&gt;, .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;\n\n\n\nIn our case, a different subject (A0703 in the big model, and A0265 in the small model) was most poorly fit by each model."
  },
  {
    "objectID": "sample-study2.html#comparing-the-models-1",
    "href": "sample-study2.html#comparing-the-models-1",
    "title": "431 Project B Sample Study 2 Report",
    "section": "9.4 Comparing the Models",
    "text": "9.4 Comparing the Models\nI would select model_big here, on the basis of the similar performance in terms of the visualization of errors, and small improvements in all four of our main test sample summaries."
  },
  {
    "objectID": "sample-study2.html#chosen-model",
    "href": "sample-study2.html#chosen-model",
    "title": "431 Project B Sample Study 2 Report",
    "section": "10.1 Chosen Model",
    "text": "10.1 Chosen Model\nI chose the bigger model. You’ll want to briefly reiterate the reasons why in this subsection, using results related to training-sample summaries, training-sample assumptions and model checks, and test-sample performance assessments. If you have evidence towards both models, decide what’s more important to you, and pick a winner."
  },
  {
    "objectID": "sample-study2.html#answering-my-question",
    "href": "sample-study2.html#answering-my-question",
    "title": "431 Project B Sample Study 2 Report",
    "section": "10.2 Answering My Question",
    "text": "10.2 Answering My Question\nNow use the winning model to answer the research question, in a complete sentence of two."
  },
  {
    "objectID": "sample-study2.html#next-steps",
    "href": "sample-study2.html#next-steps",
    "title": "431 Project B Sample Study 2 Report",
    "section": "10.3 Next Steps",
    "text": "10.3 Next Steps\nDescribe an interesting next step, which might involve fitting a new model not available with your current cleaned data, or dealing with missing values differently, or obtaining new or better data, or something else. You should be able to describe why this might help."
  },
  {
    "objectID": "sample-study2.html#reflection",
    "href": "sample-study2.html#reflection",
    "title": "431 Project B Sample Study 2 Report",
    "section": "10.4 Reflection",
    "text": "10.4 Reflection\nTell us what you know now that would have changed your approach to Study 2 had you known it at the start."
  },
  {
    "objectID": "sample-study2.html#footnotes",
    "href": "sample-study2.html#footnotes",
    "title": "431 Project B Sample Study 2 Report",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAdmittedly, that’s not much better.↩︎\nAs we’ll see in that setting, none of the generalized variance inflation factors will approach the 5 or so that would cause us to be seriously concerned about collinearity.↩︎"
  },
  {
    "objectID": "register.html",
    "href": "register.html",
    "title": "Registration for Project B",
    "section": "",
    "text": "You will use this Google Form to register for Project B. The deadline (for Project B Registration) is specified on the Course Calendar (it is in mid-November.)\n\nThe form will open by 2025-11-03.\nYour response will be automatically emailed to your CWRU email once you submit the form. If you need to edit your submission, you can do so with the link included in that email.\nIf you are working with a partner, there will be an opportunity to indicate that on this form, and only one of you (you or your partner) should complete the whole thing, while the other person needs to only complete a few of the items, as you’ll see.\n\nOnce your form is complete, Dr. Love will review your submission and get back to you to tell you whether your proposed approach is approved or not. If not, you’ll have to edit your submission and resubmit the form."
  },
  {
    "objectID": "register.html#the-registration-form",
    "href": "register.html#the-registration-form",
    "title": "Registration for Project B",
    "section": "",
    "text": "You will use this Google Form to register for Project B. The deadline (for Project B Registration) is specified on the Course Calendar (it is in mid-November.)\n\nThe form will open by 2025-11-03.\nYour response will be automatically emailed to your CWRU email once you submit the form. If you need to edit your submission, you can do so with the link included in that email.\nIf you are working with a partner, there will be an opportunity to indicate that on this form, and only one of you (you or your partner) should complete the whole thing, while the other person needs to only complete a few of the items, as you’ll see.\n\nOnce your form is complete, Dr. Love will review your submission and get back to you to tell you whether your proposed approach is approved or not. If not, you’ll have to edit your submission and resubmit the form."
  },
  {
    "objectID": "register.html#what-do-you-need-to-do-before-filling-out-the-form",
    "href": "register.html#what-do-you-need-to-do-before-filling-out-the-form",
    "title": "Registration for Project B",
    "section": "What Do You Need To Do Before Filling Out the Form?",
    "text": "What Do You Need To Do Before Filling Out the Form?\nFive things.\n\nDetermine whether or not you will work with a partner, and coordinate with that person to get all necessary tasks completed.\nIdentify whether you will use NHANES data or something else.\nObtain the data and figure out which variables you will use in Study 1 and in Study 2, making sure to meet the specifications for each study specified in the data development instructions.\nWithin your Study 2 variables, identify the number of observations in your data set with complete data on your variables (including your study ID code, your outcome, your key predictor and your 3-8 additional predictors).\nIdentify which times on December 3-9 work for you (and your partner) among those that are available (see below.) You’ll need to select at least five of the 20 available periods in total, and this must include times on at least two different dates. The time slots are specified below.\n\n\nTime Periods for Presentations\nYour actual presentation time will be 20 minutes, but we have divided the schedule into longer blocks of 75 minutes below. During each block, we will schedule up to 3 presentations. On site means Dr. Love’s office at the School of Medicine at CWRU, and Zoom means via Zoom.\nNote that December 8 is a reading day, and the last day of class (for all classes) is December 5. Regardless of when you give your presentation, your final report is due at the deadline (December 10 at noon) in the Course Calendar.\nNote that you will need to select at least 5 of the available 20 time periods below, and that those selections cannot all be on the same date. You will also have the opportunity to identify your top choice for your presentation and your preference for Zoom vs. On Site in the form, but I will not guarantee that I will match those preferences.\n\nWednesday December 3 (Zoom only) - (Quiz 2 due same day)\n\n1:00 PM - 2:15 PM\n2:30 PM - 3:45 PM\n\n\n\nThursday December 4 (either On Site or Zoom) - Final day of 431 Class\n\n9:30 AM - 10:45 AM\n11:00 AM - 12:15 PM\n2:30 PM - 3:45 PM\n4:00 PM - 5:15 PM\n\n\n\nFriday December 5 (Zoom only) - Last day of class (generally)\n\n10:00 AM - 11:15 AM\n11:30 AM - 12:45 PM\n2:00 PM - 3:15 PM\n3:30 PM - 4:45 PM\n\n\n\nMonday December 8 (Zoom only) - Reading Day\n\n8:30 - 9:45 AM\n10:00 AM - 11:15 AM\n11:30 AM - 12:45 PM\n1:30 PM - 2:45 PM\n2:45 PM - 4:00 PM\n4:00 PM - 5:15 PM\n\n\n\nTuesday December 9 (either On Site or Zoom)\n\n11:00 AM - 12:15 PM\n12:30 PM - 1:45 PM\n2:00 PM - 3:15 PM\n3:30 PM - 4:45 PM\n\nAll Project B Portfolios are due at Noon Wednesday 2024-12-10."
  },
  {
    "objectID": "data3.html",
    "href": "data3.html",
    "title": "Using Something other than NHANES",
    "section": "",
    "text": "This page describes what to do if you want to use something other than NHANES data for Project B. If you want to use NHANES data, then you should visit this page instead.\nIn either case, be sure to read through and verify that your data meet the Data Requirements for Study 1 and Study 2 described on our Data Development page.\nTo encourage people to use data other than NHANES, there is a five-point bonus in the final project B grade available for all projects which use non-NHANES data."
  },
  {
    "objectID": "data3.html#if-youre-using-data-from-another-source",
    "href": "data3.html#if-youre-using-data-from-another-source",
    "title": "Using Something other than NHANES",
    "section": "If you’re using data from another source",
    "text": "If you’re using data from another source\nIf you don’t want to use NHANES data, you will need to obtain Dr. Love’s approval through the registration form. Here are the data specifications.\n\nThe data must be freely available to all, and there must be no risk associated with your using the data for this project of any kind. Your use of the data for this project must not be subject to IRB approval, or the approval of anyone other than you (so, for example, if you would also need the approval of a principal investigator to use the data, that won’t work for Project B.)\n\nThere can be no protected health information or protected information or privacy risk of any kind involved with the data.\n\nDr. Love will need to see your source for the data in its entirety. You will need to be able to provide a link to a web page from which you (and Dr. Love and anyone else) can download the raw data as part of your registration for the project in mid-November.\nThe data must be cross-sectional, rather than longitudinal.\n\nThe only exception to this rule would be data where a baseline set of predictors is measured, which might include the baseline measure of the outcome, and then the outcome (and only the outcome) is measured at a later time.\n\nThe data must not be hierarchical, so everything must be measured at the subject level.\n\nWe cannot have subjects nested in states, for instance, with some variables measured only at the state level included in your set of variables.\nThe data you select must in all ways be suitable for the analyses required in Project B.\n\nThe data must not be from County Health Rankings, nor can they appear in any teaching repository of data (including the ones at Cleveland Clinic), nor can they be data from our 431 materials, including Lab assignments, Course Notes or Class Slides.\nThe data must not be pre-compiled as part of an R package, but rather available in raw form and ingested into R by you.\nDr. Love has an extremely strong preference for data that describe individual people or animals, as opposed to other types of “subjects”. Who the subjects (rows) of your data are must be completely clear. No genomics data, either, in Project B - Dr. Love is insufficiently familiar with that sort of data.\nDr. Love can refuse to let you use a data set for any reason at all, and this includes the reason that he’s tired of the data set.\n\nPlease visit the Data Requirements for Study 1 and Study 2 on the Data Development page to ensure that your data will meet all necessary requirements."
  },
  {
    "objectID": "data1.html",
    "href": "data1.html",
    "title": "Data Development",
    "section": "",
    "text": "You must use the same data source for Study 1 and Study 2 in Project B. That data source must either be:\n\nNHANES data, as discussed here.\nsomething else, as discussed here.\n\nTo encourage people to use data other than NHANES, there is a five-point bonus in the final project B grade for all projects which use non-NHANES data.\n\n\n\nData Requirements for Study 1 and Study 2\n\nNumber of observations\n\nIf you are using NHANES data, you will need between 500 and 7,500 observations with a minimum of 500 observations containing complete data on all of the variables you will use in Study 1 or Study 2.\nIf you are using any other data source, you will need between 250 and 10,000 observations, and at least 250 with complete data on all variables you will use in Study 1 or Study 2.\nWe require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) or as your quantitative outcome in Study 2 contain at least 15 unique values.\nThe data must include a unique coded identifier (SEQN in NHANES) for each row (subject.)\n\nNumber and type of variables for Study 1 (where you will do 4 of the following 5 analyses)\n\nFor Analysis A, you will need appropriate data to allow you to compare two means using paired samples. So that would require a set of paired measurements of the same quantity, perhaps measurements of the same subjects before and after the application of an exposure. Again, we require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) or as your quantitative outcome in Study 2 contain at least 15 unique values.\nFor Analysis B, you will need appropriate data to allow you to compare two means using independent samples. This would require a quantitative outcome (with at least 15 unique values), and a binary categorical variable which divides the data into two subgroups, so that each subgroup has a minimum of 30 observations.\nFor Analysis C, you will need appropriate data to allow you to compare 3-6 means using independent samples. This would require a quantitative outcome (with at least 15 unique values), and a multi-categorical variable with 3-6 categories which divides the data into subgroups, so that each subgroup has a minimum of 30 observations.\nFor Analysis D, you will need appropriate data to allow you to create and analyze a 2 \\(\\times\\) 2 table. This would require two independently collected binary categorical variables, that split the data into four groups in a 2 \\(\\times\\) 2 table, each with a minimum of 30 observations.\nFor Analysis E, you will need appropriate data to allow you to create and analyze a J \\(\\times\\) K table, where \\(2 \\leq J \\leq 5\\) and \\(3 \\leq K \\leq 5\\). This would require two independently collected categorical variables (one with J groups and one with K groups), that split the data into groups in a J \\(\\times\\) K table, so that each cell within the table has a minimum of 15 observations.\nAt a bare minimum, then, you will need a quantitative outcome (for Analyses A, B and C) and two binary variables (one for B and two for D and one for E) and a multi-categorical variable with 3-5 levels (for C and E) although you are welcome to use different variables from the same data source for each of the four Study 1 analyses you complete.\n\nNumber and type of variables for Study 2\n\nYou will need a quantitative outcome. Again, we require that your quantitative outcome contains at least 15 unique values.\nYou will need a key predictor of interest (which may be either quantitative, or categorical.) If it is categorical, it must have 2-6 categories, and each category must contain at least 30 observations. Your research question will focus largely on how effectively this key predictor can be used to predict your quantitative outcome.\nYou will need to identify 3-8 additional predictors of your outcome, at least one of which must be a multi-categorical predictor with 3-6 categories, where each category contains at least 30 observations. The other predictors can be any combination of quantitative and categorical (with 2-6 categories each, with at least 30 observations in each category.)\n\nYour data for each Study must be managed, merged (if necessary) and cleaned exclusively using R to go from raw data to that Study’s final clean tibble. This data management process must include the creation of appropriately labeled (and, if necessary, collapsed) factors for all categorical variables you will use in either study, and appropriate investigation and actions regarding missing values, numbers of unique values, and impossible values.\nYou will need to generate a single clean data set which you will then use for all four of your Study 1 analyses. For Study 1, work with a data set that has complete cases only on all of the analytic variables you study in your various Study 1 analyses. Describe those data overall using a codebook and an appropriate set of numerical summaries for your variables.\nYou will need to generate a single clean data set for all of your Study 2 analyses, which you will then partition (after single imputation of all variables besides your outcome and key predictor, to deal with missing values of all of your non-key predictors, if they exist) into a model training (or development) sample containing 60-80% of the data, and a model testing (or validation) sample containing the remaining 20-40% of the data. Describe the training data overall using a codebook and an appropriate set of numerical summaries, as you did in Study 1.\n\n\n\nTips on Cleaning Your Data\n\nIf you need to merge data (for instance in NHANES) clean the data after completing the merge.\nNote that it’s only necessary to clean the variables you will actually use in your analyses below. Create an analytic data set containing only those variables.\n\nThis should include a subject identification code (the SEQN in NHANES), your outcome, your key predictor and your other predictors.\nIf you are working with NHANES Aug 2021-Aug 2023 data, you must include RIDSTATR and RIDAGEYR from the DEMO_L file. If you are working with NHANES 2017-March 2020 data, you must include the same variables from the P_DEMO file.\n\nInclude RIDSTATR just so that you can prove that all of its values are 2 in your sample.\nInclude RIDAGEYR even if you’re not using it in your models, so you can describe the ages of the people in your sample.\n\n\nIf you create a categorical variable from a quantitative one, do so in this section of your report, and then refer to that work in the analyses below when you use the new variable. In general, though, I wouldn’t do that except in dire circumstances. Variables that use categories to describe what were originally quantitative variables aren’t quantitative any more.\nThings I would treat as missing include responses like Refused, Don’t Know, Did Not Respond, Unknown, No response and missing.\n\nIf you have a quantitative variable that includes a code like 5555 or 9999 for “don’t know” or “missing”, you will need to identify those cases as missing when ingesting the data, just as you would if you were working with a categorical variable.\nBe sure that R recognizes things that are missing as missing.\n\nCollapse levels sensibly for multi-categorical variables with more than 6 categories. If you want to use more than 6 categories for a categorical variable in your analyses, contact Dr. Love.\n\nIf you have a categorical variable with codes like 77, 88 or 99, in addition to treating those as missing, you want to drop those levels from the factors you create. I recommend you run droplevels() on your tibble to remove all factor levels with zero subjects. That can help down the line.\n\nFor NHANES folks, a few specific things:\n\nGender vs. Sex I would treat the RIAGENDR variable as describing biological sex and would rename it as I created a factor.\nRace/Ethnicity If you want to use race/ethnicity I would prefer the use of RIDRETH3 over RIDRETH1, and I would recommend using all six categories, assuming you have at least 100 subjects at each level after whatever other pruning you do. If you want to collapse, then lumping codes 1 and 2 into “Hispanic/Latinx” is acceptable. Remember that race/ethnicity as a covariate is an attempt to understand the impact of structural racism, at least as much as it is anything else, so interpretation requires special care.\nAge Do not use a categorical version of age. Use the quantitative version, called RIDAGEYR, provided in the DEMO_L or P_DEMO data. When you describe your subjects, you should specify the range (minimum and maximum) ages of those subjects, so you will need to capture RIDAGEYR in your final analytic data set even if you’re not including it in your regression models.\nIncome and Measurement Caps The family income ratio INDFMPIR is appealing and quantitative, but it has a pronounced ceiling effect. It is the ratio of income to the poverty level, but is capped at 5. How should you think about that? (Note that age in adults is also capped, at 80.)\nEducation Categories If you’re working with adults (ages 20 and over), the DMDEDUC2 variable in the DEMO_L or P_DEMO file is the set of categories to use. I would probably collapse codes 1 and 2 together to create a four-category variable with “Less than HS”, “HS Grad”, “Some College”, “College Grad”.\n\nBe sure to treat all multi-categorical variables as factors in R, and don’t treat numeric codes as meaningful numeric variables.\nMake sure that all of your quantitative variables have sensible minimum and maximum values as you’re cleaning.\nSome binary variables are coded 1 and 2. Fix that in your work, ideally by using the real names and treating the variable as a factor, or by converting the 1-2 to a proper 1-0 indicator variable.\n\nUse the formula NEWVAR = 2 - OLDVAR to turn OLDVAR: 1 = Yes, 2 = No into NEWVAR: 1 = Yes, 0 = No.\nIf you have OLDVAR: 1 = No, 2 = Yes, create a NEWVAR with 1 = Yes, 0 = No using NEWVAR = OLDVAR - 1.\n\nIn Study 1, filter to complete cases. In Study 2, You should only filter to complete cases on the outcome and key predictor in Study 2. Then, perform single (simple) imputation using the mice package for any variables that are neither your outcome or your key predictor in Study 2 with missing values.\nYou are welcome to apply janitor::clean_names at the start or end of your cleaning, if you like. If you do decide to change the names as well (and that’s a good idea if a name is long or confusing, especially with NHANES), that’s great, but be sure to specify the original names as well in the codebook.\nPlease don’t include sanity checks in your report. We’ll trust you have to have done that work on your own.\nAgain, if you have missing data, you will do different things in Study 1 and Study 2 about this.\n\n\nIn Study 1, you should explicitly state that you are assuming that the “missing completely at random (MCAR)” mechanism for missing data, and then filter until you have only complete cases.\nIn Study 2, you should explicitly state that you are assuming that “missing at random (MAR)” is the most appropriate missing data mechanism and then use single imputation for Study 2, with two exceptions: (1) I don’t want you to impute your outcome or key predictor, so you will need to filter to complete cases on those variables, and (2) you may decide to add on a multiple imputation summary of parameters for the final model if you choose, as we’ll discuss in Class 21.\n\n\n\nTo use data from NHANES (National Health and Nutrition Examination Survey).\n\nPlease read the Data Requirements for Study 1 and Study 2 and Tips on Cleaning Your Data above, then read the additional details on what is required if you’re working with NHANES data here.\nMany people (in past years) have felt that using NHANES data was a little easier than using another data source. To encourage people to use data other than NHANES, there is a five-point bonus in the final project B grade available for all projects which use non-NHANES data.\n\n\n\nTo use data from a non-NHANES source that meets with Dr. Love’s approval.\n\nPlease read the Data Requirements for Study 1 and Study 2 and Tips on Cleaning Your Data above, then read the additional details on what is required if you’re instead working with some other data source here.\nAgain, to encourage people to use data other than NHANES, there is a five-point bonus available to all projects which use non-NHANES data."
  },
  {
    "objectID": "checklist.html",
    "href": "checklist.html",
    "title": "431 Project B Checklist",
    "section": "",
    "text": "Main Tasks\n\nComplete the Project B Registration Form to obtain my approval for your plan, let me know if you’re working with a partner, and schedule your oral presentation.\n\nThe registration deadline in mid-November is specified in the Course Calendar.\n\nYou (and your partner, if you have one) will present your project on December 3-9 to Dr. Love in his office or over Zoom. Details on the Oral Presentation are provided below.\nYou will build two Quarto and HTML reports (separate reports for Study 1 and Study 2) due at the project B portfolio deadline.\n\nIf you’re not using NHANES data, you’ll also submit your data to me at that time.\nDetails on how to submit your reports are provided below.\n\nFinally, complete the Project B Self-Evaluation form, also due at the same time as the Portfolio Reports for Study 1 and Study 2, as specified on the Course Calendar.\n\n\n\nSubmitting Your Study 1 Report\nYour Study 1 Report is to be submitted to Canvas by the deadline in the Course Calendar.\n\nThis submission should include both your Quarto and HTML results.\nBe sure that the names of your Quarto and HTML files clearly identify whose project is being submitted, and an indication that these files refer to study 1.\nIf you are working with a partner, one of you should submit both the Study 1 and Study 2 reports to Canvas, and the other person should submit a one-page note to Canvas (Word or PDF is best) containing your name, and stating something like “I worked on Project B with [your partner’s name] and they will submit Project B for our group.”\n\n\n\nSubmitting Your Study 2 Report\nYour Study 2 Report is to be submitted to to Canvas by the deadline in the Course Calendar.\n\nThis submission should include both your Quarto and HTML results.\nIn addition, if you worked with any data other than NHANES, your submission also needs to include your data (in the form you used to ingest the data in your Quarto file, so that we can run your Quarto code and obtain your HTML results.)\nBe sure that the names of your Quarto and HTML files clearly identify whose project is being submitted, and an indication that these files refer to study 2.\nAgain, if you are working with a partner, one of you should submit both the Study 1 and Study 2 reports to Canvas, and the other person should submit a one-page note to Canvas, (word or PDF is best) containing your name, and stating something like “I worked on Project B with [your partner’s name] and they will submit Project B for our group.”\n\n\n\nOral Presentation of Results\nYour meeting time is 20 minutes long, and please arrive 5 minutes early, either in person or via Zoom. If you have an emergency on the day of your presentation, email Dr. Love as soon as possible. Zoom information will be provided to you by December 1.\nYour meeting will involve materials from each of your studies, discussed in a fairly regimented way, described below. If you are working with a partner, Dr. Love will randomly determine at the meeting who will speak and when, so you need to each be prepared to give the entire presentation. Dr. Love will keep track of time, and move you along as necessary, so you won’t have to worry about that.\n\nYou will need to share a screen to show me the key results as you describe them for each of the analyses in Study 1 and in Study 2 that you wind up discussing. It is best if one of you is prepared to share their screen for both presentations, if you’re working with a partner, and I encourage you to practice this in advance.\nYou are welcome to show me results in the context of a Powerpoint-style presentation, if you prefer to develop one, or to show me results straight from your Quarto-created HTML files in your portfolio. Whatever works for you - so long as I can see what you are talking about as you are talking, we’ll be fine. Make sure you know how to increase the size of the text in your HTML file while presenting it.\nI will NOT be able to pull up your report or other materials while we are talking. You will have to be able to do that.\n\n\nStudy 1 presentation (6-8 minutes)\nIn Study 1, you will first select your most interesting / intriguing result out of your four main analyses and present that, in about 2 minutes. In those 2 minutes, you should be showing me the highlights of that Analysis, specifically:\n\nWhich Analysis (A, B, C, D, or E) are we describing?\nWhat research question are you investigating, and what variables did you use?\nWhat conclusion did you draw about that question?\nWhat statistical method led you to that conclusion?\n\nI will then ask you to tell me which of the other analyses (meaning A, B, C, D, or E) you did. I will then ask you to present the results of one of the other analyses you did, in a similar way. You will need to come prepared to present this information for any of your Study 1 analyses at a moment’s notice, as you will not know in advance which of your other analyses you did that I will ask for.\n\n\nStudy 2 presentation (10-12 minutes)\nIn Study 2, you will start with telling me about the most important finding of your little study in 5 minutes. In these 5 minutes, you will tell me:\n\nWhat your research question was and why it was interesting to you (combined this should take no more than 30 seconds)\nWhat your better model has to say about the answer to your research question\n\nThis should include a description of the predictors that wound up in your (final) model and the direction of each of their effects on your outcome. Show me the model as you’re telling me about this.\nThis should also include a sense of how well the model predicted overall (\\(R^2\\) is one good choice.)\nThis should also include whether the posterior predictive plots show systematic discrepancies between the fitted model’s predictions and your observed data. Show me the plot as you’re telling me about this.\nThis should also include a discussion of whether residual plots for your final model fit regression assumptions. Show me the plots as you’re telling me about this.\nYour conclusions about rational next steps to learn more from these data, or what specific new data you now wish you’d had when you started the study.\n\n\nFor most of the remaining time, I will ask you about your study, and try to help you think through any problems you had in obtaining or interpreting analyses. You should come prepared to share any of the steps in your analysis at a moment’s notice, as we may want to look at any part of your work.\n\n\nFinal Questions (2-4 minutes)\nDepending on remaining time, I may ask you any of several questions at the end of our meeting. Some possibilities you should be prepared for include the following (some of which also appear in the self-evaluation)\n\nWhat percentage of your time in Project B did you spend obtaining, cleaning, merging and tidying data, as opposed to actually performing analyses on tidy data?\nTell me something useful that you learned from doing Project B.\nTell me what the hardest part of doing Project B was.\nWhat did you learn from Project A that was helpful in doing Project B?\nWhat do you know now that you wish you’d known back when you started Project B back in November? What would you tell yourself if you could go back in time?\n\n\n\n\nA Special Note\nIf you’ve read down to here before 5 PM on December 1, thanks and here’s an opportunity for a little bonus credit. Send Dr. Love an email no later than 5 PM on December 1 with the subject line 431 Favorite Song, telling him your favorite song (and providing a link to a video of the song on YouTube), and you’ll get some bonus credit.\n\n\nSelf-Evaluation for Project B\nThe Self-Evaluation for Project B Form will be available in December and should take about 15 minutes to complete. If you are working in a team, each of you need to complete the form as an individual.\nThe Form is due when the Project B Portfolio is due, and you’ll complete it after meeting with Dr. Love for your presentation. Find the link to the Self-Evaluation Form here."
  },
  {
    "objectID": "data2.html",
    "href": "data2.html",
    "title": "Using NHANES Data",
    "section": "",
    "text": "If you select the NHANES option, you will be using data from the National Health and Nutrition Examination Survey.\nIf you decide to use some other data set instead for Project B, then you should visit this page.\nIn either case, be sure to read through and verify that your data meet all requirements described on our Data Development page."
  },
  {
    "objectID": "data2.html#about-nhanes-from-the-nhanes-website",
    "href": "data2.html#about-nhanes-from-the-nhanes-website",
    "title": "Using NHANES Data",
    "section": "About NHANES (from the NHANES website)",
    "text": "About NHANES (from the NHANES website)\n\nThe National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. The survey is unique in that it combines interviews and physical examinations. NHANES is a major program of the National Center for Health Statistics (NCHS). NCHS is part of the Centers for Disease Control and Prevention (CDC) and has the responsibility for producing vital and health statistics for the Nation.\n\n\nThe NHANES program began in the early 1960s and has been conducted as a series of surveys focusing on different population groups or health topics. In 1999, the survey became a continuous program that has a changing focus on a variety of health and nutrition measurements to meet emerging needs. The survey examines a nationally representative sample of about 5,000 persons each year. These persons are located in counties across the country, 15 of which are visited each year.\n\n\nThe NHANES interview includes demographic, socioeconomic, dietary, and health-related questions. The examination component consists of medical, dental, and physiological measurements, as well as laboratory tests administered by highly trained medical personnel.\n\n\nFindings from this survey will be used to determine the prevalence of major diseases and risk factors for diseases. Information will be used to assess nutritional status and its association with health promotion and disease prevention. NHANES findings are also the basis for national standards for such measurements as height, weight, and blood pressure. Data from this survey will be used in epidemiological studies and health sciences research, which help develop sound public health policy, direct and design health programs and services, and expand the health knowledge for the Nation."
  },
  {
    "objectID": "data2.html#general-advice-for-nhanes-learning-about-the-available-data",
    "href": "data2.html#general-advice-for-nhanes-learning-about-the-available-data",
    "title": "Using NHANES Data",
    "section": "General Advice for NHANES: Learning About The Available Data",
    "text": "General Advice for NHANES: Learning About The Available Data\nThe links in this section go to the Survey Data and Documentation section of the NHANES website.\n\nWe strongly encourage the use of either the Aug 2021 - Aug 2023 NHANES data or the NHANES 2017 - March 2020 Pre-pandemic data for Project B.\n\nThis are the two most recent public data releases that are fairly complete.\n\nYou are required to use variables taken from at least three different NHANES data sets. This must include the Demographics data set, in addition to two other data sets taken from at least one of three other available data groups (Examination, Laboratory and Questionnaire) in your chosen NHANES period.\n\nThe Demographics data group for 2021-2023 or for 2017-2020 should be part of all projects, and it contains a single data set.\nThe Examination data group for 2021-2023 or for 2017-2020 includes several data sets.\nThe Laboratory data group for 2021-2023 or for 2017-2020 contains many data sets.\nThe Questionnaire data group for 2021-2023 or for 2017-2020 also contains many data sets.\nWe do not want you to use data from the Dietary data group or the Limited Access data in Project B.\n\nYou will use the nhanesA package in R to import and work with the available data. This package is part of our list of recommended packages for installation.\nNote that none of your work will be using the sampling weights which are a key part of NHANES. Thus, none of your results from Project B will be truly representative of the national population. That’s OK for this exercise."
  },
  {
    "objectID": "data2.html#getting-the-nhanes-data",
    "href": "data2.html#getting-the-nhanes-data",
    "title": "Using NHANES Data",
    "section": "Getting the NHANES data",
    "text": "Getting the NHANES data\nVisit the NHANES website and identify the data you want to view.\n\nFor example, the Demographic Variables and Sample Weights for NHANES 2017-March 2020 are described here, and here is the 2021-2023 version.\nEach NHANES data set is associated with a Doc File (which stands for Data Documentation, Codebook and Frequencies). For instance, here’s the one for Demographics in 2017-March 2020 and here’s the 2021-2023 version. This file can be viewed online (it’s an HTML file) and it will tell you what variables are included in that data set.\nEach NHANES data set is available as a SAS transport file. For example, it’s the P_DEMO file for Demographics in 2017-March 2020, as you can see here and DEMO_L for Demographics in 2021-2023."
  },
  {
    "objectID": "data2.html#using-the-nhanesa-package",
    "href": "data2.html#using-the-nhanesa-package",
    "title": "Using NHANES Data",
    "section": "Using the nhanesA package",
    "text": "Using the nhanesA package\nOnce you’ve selected the data sets from NHANES that you want to use in your project (remember that you need at least 3), the nhanesA package in R can be used to obtain them.\nHere’s a little vignette introducing nhanesA from Christopher Endres, who built the package. The key functions in the nhanesA package that I think you might use are those described in that vignette, but the main one is simply called nhanes.\n\nAn Example\nFor example, suppose we want to load the Blood Pressure data from the 2017-18 Examination files at NHANES (contained in the BPX_J data file) into a tibble called bp_data in R.\n\nNote that you will instead use either 2017-March 2020 or 2021-2023 data, which for Blood Pressure would be, according to this page the P_BPXO file for 2017-2020, or, from here the BPXO_L file for 2021-2023, rather than BPX_J.\n\nWe would use the following code, which will take a few minutes to run.\n\nlibrary(nhanesA)\nlibrary(tidyverse)\n\nbp_raw &lt;- nhanes('BPX_J') |&gt; tibble()\n\nsaveRDS(bp_raw, \"data/BPX_J.Rds\")\n\nOnce you’ve downloaded the file once, you should save it as an R data frame, and then comment out the initial code you used to pull down the data in R. Then, when you rerun, it’ll be all set. Remember to create a data sub-folder in your R Project B directory before you run this code.\nSo your final presentation in Project B should instead look like this, which will run much more quickly.\n\nlibrary(nhanesA)\nlibrary(tidyverse)\n\n# pull in data from BPX_J from NHANES and save it\n\n# bp_raw &lt;- nhanes('BPX_J') |&gt; tibble()\n\n# saveRDS(bp_raw, \"data/BPX_J.Rds\")\n\n# Now that data are saved, I can just read in the tibble\n\nbp_raw &lt;- readRDS(\"data/BPX_J.Rds\")"
  },
  {
    "objectID": "data2.html#merging-nhanes-files",
    "href": "data2.html#merging-nhanes-files",
    "title": "Using NHANES Data",
    "section": "Merging NHANES files",
    "text": "Merging NHANES files\nYou will need to include data from multiple tibbles (data sets) pulled down in your project. I suggest you first select only those variables you intend to use in your analytic data file from each individual tibble you have created. This should always include the SEQN variable in every tibble, since that is what you will use to match up responses across those tibbles.\n\nYour final analyses should be based on somewhere between 500 and 7,500 complete cases from either the NHANES 2017-March 2020 data or the NHANES 2021-2023 data.\n\nTo merge a demographics tibble called DEMO with a BPX tibble to create a tibble called NEW that contains the variables from both DEMO and BPX for all of the subjects contained in DEMO, I’d use a left_join, as follows.\n\nNEW &lt;- left_join(DEMO, BPX, by = \"SEQN\")\n\nI’d then use another left_join to merge this NEW result with another tibble (say, the HDL_J tibble) and so on.\n\nNEW2 &lt;- left_join(NEW, HDL_J, by = \"SEQN\")\n\nThen, when I was done merging and cleaning the data I would be sure to save that result as a new Rds file, just in case I needed it again."
  },
  {
    "objectID": "data2.html#which-variables-subjects-should-i-use",
    "href": "data2.html#which-variables-subjects-should-i-use",
    "title": "Using NHANES Data",
    "section": "Which variables / subjects should I use?",
    "text": "Which variables / subjects should I use?\nThat’s up to you. Find variables of interest in the description files, and pull them out and see if they will work for you.\n\nFocus on subjects who have a RIDSTATR value of 2 (meaning they were both interviewed and examined) - this variable is part of the Demographics file.\n\nFor example, in 2017-March 2020, there are 14,300 such subjects and in 2021-2023, there are 8,860.\nIf you get the names from using the nhanes() function instead of numbers, you can either work with those names, or try adding translated = FALSE, as in demo &lt;- nhanes(\"DEMO_L\", translated = FALSE) to your call to the nhanes() function.\n\nI encourage you to not use subjects listed with ages of 80 (RIDAGEYR = 80) since that’s a catch-all for all subjects ages 80 and older.\n\nFor 2017-March 2020, of the 14,300 listed above, 13,724 are less than 80.\nFor 2021-2023, of the 8,860 listed above, 8,335 are less than 80.\n\nYou should either use children (ages 0-20) or adults (ages 21-79) in your final analyses, and not both together.\n\nSome variables are only collected on children, others only on adults.\n\nDo not filter to complete cases in creating your data. Maintain the missing values.\n\nIn many cases, you should have well over 5,000 observations in total, but depending on what you select, you may have a much smaller subset, and you should be able to explain to us why that is the case, if it is.\nFor example, if you’re studying something that is only measured in females, or in children, you’ll have a smaller sample for that reason, and you need to make that clear to us in your report. At a minimum, you will need at least 500 complete cases even if you’re using heavily filtered NHANES data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "431 Project B Instructions",
    "section": "",
    "text": "What is Project B?\nProject B is the second of two real data science projects you’ll be doing this semester. It involves the completion of four tasks, which you’ll start working on at the start of November.\n\nYou will complete a Registration Form to obtain my approval for what you propose, let me know if you’re working with a partner, and schedule your oral presentation.\nYou will build Quarto and HTML reports describing your work.\nYou (and your partner, if applicable) will present your project sometime between 12-03 and 12-09 to Dr. Love in his office in person or via Zoom. These will be scheduled immediately after the Project B Registration Forms have been submitted.\nFinally, you will complete a Self-Evaluation form.\n\n\n\nWhat’s on this Website\n\nThe Data: Instructions on getting data for Project B\n\nYou’ll either use data from NHANES, or from some other source.\n\nRegistration information proposing your Project B.\n\nThis involves completing a Google Form by the deadline in mid-November specified on the Course Calendar. In this form, you will:\n\nspecify whether or not you are working with a partner\ntell us a little about the data source (NHANES or other) you intend to use\nprovide options for when you can give your oral presentation, and whether you prefer to do so in person or via Zoom\n\n\nInstructions for Study 1\n\nYou’ll find information on required Study 1 analyses\nWe also provide detailed Study 1 report specifications\nYou’ll also find a Study 1 sample report\n\nInstructions for Study 2\n\nYou’ll find information on required Study 2 analyses\nWe also provide detailed Study 2 report specifications\nYou’ll also find a Study 2 sample report\n\nSelf-Evaluation Form for Project B\n\nIf you work with a partner, each of you submits this form separately.\n\nA Checklist of the tasks that need to be accomplished for Project B, which also includes some details on the oral presentation you’ll give to Dr. Love in December.\nA Tip Sheet of about 20 things that have come up in the past that are worth your attention as you prepare your final materials for presentation and submission.\nThe top menu also provides links to contact us, and to the 431 home page.\n\nAll of the material you need (from a statistical and coding perspective) to do Project B has been or will be covered in our first 23 classes (i.e. immediately before the Thanksgiving Break), as well as in the Course Book Chapters 1-22 and Labs 1-6.\n\n\nProject B Deliverables\n\nYou will complete a Registration Form to obtain my approval for your proposed work, let me know if you’re working with a partner, and schedule your oral presentation, by the (mid-November) deadline on the Course Calendar.\nYou (and your partner, if applicable) will present your project to Dr. Love in his office. Details on the Oral Presentation are found in the Checklist menu above. Presentations will be scheduled on December 6-11 using the Registration Form.\nYou will build two Quarto and HTML reports (separate reports for Study 1 and Study 2) by the Project B Portfolio deadline in the Course Calendar.\n\nIf you’re not using NHANES data, you’ll also submit your data to Dr. Love at that time.\n\nFinally, you will complete a Self-Evaluation form, by the Project B Portfolio deadline in the Course Calendar.\n\n\n\nPartnerships?\nYou can work alone, or with one other person on this project. If you work as a pair, you will commit to that when you register for the project. Each of you will receive the team grade for the project reports, and an individual grade for the other components of the project.\n\n\nThe Data\nYou will work with the same data source for Study 1 and for Study 2, and these data will be developed either from NHANES or from another public source that you identify.\n\nYou will find detailed instructions regarding the use of NHANES data for Project B here.\nIf you want to use other data, you’ll need it to meet some specifications we’ll describe, and you’ll have to get Dr. Love’s permission when you register your project.\nSince most people consider working with NHANES data to be easier, we will award five extra points to projects which use non-NHANES data.\n\n\n\nStudy 1\n\nStudy 1 is about making descriptive and exploratory comparisons and summaries of data. It’s not about building sophisticated statistical models.\nYou will ingest, merge and clean the data in R, then select variables to complete any four out of five potential analyses, as described in these instructions.\n\nYou can do all five analyses if you like (as preparation for Quiz 2, for instance) but you will only present four in your report. No bonus credit for doing all five analyses.\n\nYou will use 90% confidence throughout your Study 1 and Study 2.\nDr Love has developed Study 1 Report Specifications and a Study 1 Sample Report which should guide your eventual submitted Study 1 report.\n\n\n\nStudy 2\n\nStudy 2 is about building a model and making predictions. You will complete all elements of a data science project designed to create a statistical model for a quantitative outcome, then use it for prediction, and assess the quality of those predictions.\nStudy 2 involves working with data from the same source that you used for Study 1. Again, you will work through all cleaning and data management requirements in your Study 2 report.\n\nStudy 2 involves the prediction of a quantitative outcome using a key predictor and some additional predictors in two linear regression models, and then comparing those two models.\nAll of the material you need (from a statistical and coding perspective) to do these analyses has been or will be covered in our first 23 classes and in the Course Notes.\n\nYou will use 90% confidence throughout your Study 1 and Study 2.\nDr Love has developed Study 2 Report Specifications and a Study 2 Sample Report which should guide your eventual submitted Study 2 report.\n\n\n\nGrading\nProject B will be graded by Dr. Love on a scale from 0-150 points.\n\nOn-time successful completion of the Registration Form is worth 15 points.\nThe two study reports (Study 1 and Study 2) due at the final Project B deadline are worth a combined 60 points.\nThe oral presentation is also worth 60 points. Details on the Oral Presentation are found in the Checklist.\nThe self-evaluation is worth 15 points.\nLate work on Project B is unacceptable. All deadlines are in the Course Calendar.\n\nDr. Love will provide no written feedback on your Project B work. The grading timeline is simply too tight on my end. I apologize in advance.\n\n\nQuestions?\nIf you have questions, let us know about them via email to 431-help at case dot edu, speak with Dr. Love before or after class, or discuss them with the TAs during their office hours."
  },
  {
    "objectID": "sample-study1.html",
    "href": "sample-study1.html",
    "title": "431 Project B Sample Study 1 Report",
    "section": "",
    "text": "Reminders from Dr. Love\n\n\n\n\nRemember that each subsection should include at least one complete sentence explaining what you are doing, specifying the variables you are using and how you are using them, and then conclude with at least one complete sentence of discussion of the key conclusions you draw from the current step, and a discussion of any limitations you can describe that apply to the results.\nIf you want to download the Quarto code I used to create this document to use as a template for your own work, click on the Code button near the title of this Sample Study.\nIn general, DO NOT use my exact words (other than the section and subsection headings) included in this sample report in your project. Rewrite everything to make it relevant to your situation. Do not repeat my instructions back to me.\n\n\nOne partial exception is that I have demonstrated the interpretation of point estimates (and in some cases, like the paired tests in Analysis A, and the independent sample tests in Analysis B, the confidence intervals, too) using language that I would be happy to see you use."
  },
  {
    "objectID": "sample-study1.html#initial-setup-and-package-loads",
    "href": "sample-study1.html#initial-setup-and-package-loads",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.1 Initial Setup and Package Loads",
    "text": "1.1 Initial Setup and Package Loads\n\nlibrary(janitor)\nlibrary(naniar)\nlibrary(patchwork)\nlibrary(broom)\nlibrary(Epi)\nlibrary(glue)\nlibrary(gt)\nlibrary(infer)\nlibrary(readxl)\nlibrary(xfun)\nlibrary(easystats)\nlibrary(tidyverse) \n\n## Load Love-431 script \nsource(\"data/Love-431.R\")\n\n## Global options\nknitr::opts_chunk$set(comment=NA)\n\ntheme_set(theme_bw())"
  },
  {
    "objectID": "sample-study1.html#loading-the-raw-data-into-r",
    "href": "sample-study1.html#loading-the-raw-data-into-r",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.2 Loading the Raw Data into R",
    "text": "1.2 Loading the Raw Data into R\nThis document demonstrates a variety of things required in your Project B Study 1. We will demonstrate ideas using data from a 2015 class survey, gathered in three data files available on the 431-data website. The files are called:\n\nprojectB-study1-demo-survey-2015a.xlsx\nprojectB-study1-demo-survey-2015b.csv\nprojectB-study1-demo-survey-2015c.csv\n\nAfter merging, the complete data set should include data on 21 variables for 53 subjects.\n\nI’m going to use clean_names() from the janitor package before I do the merging. It would also be OK to do this after the merge is complete.\nI’m also going to tell R to interpret both a blank “” and an “NA” in a cell of the Excel sheet as indicating a missing value, since that’s what I need, and since that’s what read_csv already does, by default.\n\n\nsur15_raw_a &lt;- read_excel(\"data/projectB-study1-demo-survey-2015a.xlsx\", \n                      na = c(\"\", \"NA\")) |&gt;\n  janitor::clean_names()\n\nsur15_raw_b &lt;- read_csv(\"data/projectB-study1-demo-survey-2015b.csv\") |&gt;\n  janitor::clean_names()\n\nsur15_raw_c &lt;- read_csv(\"data/projectB-study1-demo-survey-2015c.csv\") |&gt;\n  janitor::clean_names()"
  },
  {
    "objectID": "sample-study1.html#contents-of-the-raw-tibbles",
    "href": "sample-study1.html#contents-of-the-raw-tibbles",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.3 Contents of the Raw Tibbles",
    "text": "1.3 Contents of the Raw Tibbles\nWe have three tibbles now, which (once we have merged them together) will contain complete data on all 53 subjects for all 21 variables.\n\nsur15_raw_a contains data on all 21 variables for the first 20 subjects.\n\n\ndim(sur15_raw_a)\n\n[1] 20 21\n\n\n\nsur15_raw_b contains data on 9 of the variables (including the subject ID code: s.id) for the other 33 subjects.\n\n\ndim(sur15_raw_b)\n\n[1] 33  9\n\n\n\nsur15_raw_c contains data on 13 of the variables (also including the subject ID code: s.id) for the same 33 subjects that are in sur15_raw_b.\n\n\ndim(sur15_raw_c)\n\n[1] 33 13"
  },
  {
    "objectID": "sample-study1.html#two-merging-steps",
    "href": "sample-study1.html#two-merging-steps",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.4 Two Merging Steps",
    "text": "1.4 Two Merging Steps\n\nJoin the columns in sur15_raw_b and in sur15_raw_c to obtain a new tibble, which I’ll call sur15_last33, holding information on all 21 variables for the last 33 subjects.\n\n\nsur15_last33 &lt;- inner_join(sur15_raw_b, sur15_raw_c, by = \"s_id\")\n\ndim(sur15_last33)\n\n[1] 33 21\n\n\n\nCombine the rows together from sur15_raw_a (which has the first 20 subjects) and sur15_last33 (which has the other 33 subjects) to create a tibble called sur15_merged which has all 21 variables for all 53 subjects.\n\n\nsur15_merge &lt;- bind_rows(sur15_raw_a, sur15_last33)\n\ndim(sur15_merge)\n\n[1] 53 21\n\n\nOK. We have 53 subjects and 21 variables, as expected."
  },
  {
    "objectID": "sample-study1.html#checking-the-merge",
    "href": "sample-study1.html#checking-the-merge",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.5 Checking the Merge",
    "text": "1.5 Checking the Merge\nWe need to perform two checks here.\n\nFirst, we should check to ensure that the number of distinct (unique) subject identification codes (shown below) matches the number of rows. Those two values should be identical. Are they?\n\n\nidentical(n_distinct(sur15_merge$s_id), \n          sur15_merge |&gt; nrow())\n\n[1] TRUE\n\n\nExcellent.\n\nSecond, we should also check that we haven’t added any new variables. The sur15_raw_a tibble included all of the variable names we should have in the final result. Do the names in sur15_raw_a match the names in our merged tibble exactly?\n\n\nidentical(names(sur15_merge), \n          names(sur15_raw_a))\n\n[1] TRUE\n\n\nAll right. Our merge was successful."
  },
  {
    "objectID": "sample-study1.html#selecting-only-the-variables-well-use",
    "href": "sample-study1.html#selecting-only-the-variables-well-use",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.6 Selecting only the variables we’ll use",
    "text": "1.6 Selecting only the variables we’ll use\nThe sur15_merge data includes some variables we don’t need, so we’ll prune down to the 11 variables we’ll actually use in the analyses we’ll do. This should certainly include the subject identification code, so we’ll include that, and also switch it to a character representation instead of numeric.\n\nsur15_m &lt;- sur15_merge |&gt;\n  mutate(s_id = as.character(s_id)) |&gt;\n  select(s_id, r_pre, r_now, height, weight, \n         comfort_431, grades, r_before, english, \n         medium, fiction)"
  },
  {
    "objectID": "sample-study1.html#our-survey-items",
    "href": "sample-study1.html#our-survey-items",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.1 Our Survey Items",
    "text": "2.1 Our Survey Items\nThe 10 survey items that we will actually use in this demonstration are listed below.\n\n2.1.1 Rating Variables\nFor each of these, subjects gave a response between 0 and 100 indicating their agreement with the statement as presented. The scale was 0 = Strongly disagree, 100 = Strongly agree.\n\nr_pre: Prior to taking 431, I was totally confident and comfortable with using R. (0 = Strongly Disagree, 100 = Strongly Agree)\nr_now: Right now, I am totally confident and comfortable with using R. (0 = Strongly Disagree, 100 = Strongly Agree)\ncomfort_431: I am very comfortable with my understanding of the material discussed so far in 431.\n\n\n\n2.1.2 Other Quantitative Variables\n\nheight: What is your height, in inches?\nweight: What is your weight, in pounds?\n\n\n\n2.1.3 Binary Variables\n\nr_before: Before taking 431, had you ever used R before? (Yes, No)\nenglish: Is English the language you speak better than any other? (Yes, No)\n\n\n\n2.1.4 Multi-Categorical Variables\n\ngrades: In your graduate and undergraduate educational experience, which of the following types of assignments have you received the HIGHEST grades for?\n\nAvailable responses were “A. Individual Assignments”, “B. Partner Assignments (you and 1 other student)”, and “C. Group Assignments (you and 2 or more others)”.\n\nmedium: Which medium do you use most to get your fictional stories (containing plot)?\n\nAvailable Responses: “A. Movies”, “B. Television”, “C. Print (including books, comics, etc.)”, and “D. Other”.\n\nfiction: Which type of fictional stories do you consume most?\n\nAvailable Responses: “A. Comedy”, “B. Drama”, “C. Action”, “D. Horror / Thriller”, and “E. Fantasy / Science Fiction”.\n\n\nOur analytic tibble will be called sur15 for this demonstration.\n\nThis tibble will need to contain information developed from the variables listed above, plus the subject identifying code s_id.\nAs we add variables to the analytic tibble, we’ll also check to see that all of the values fall in a reasonable range (with no results that fall outside of the parameters of how we are measuring the results) and we’ll identify whether there are any missing values.\n\nNote that we’ve already checked our subject identification codes to ensure that we have no missing values there and that we have a unique identifier for each row in the data back when we did the merge."
  },
  {
    "objectID": "sample-study1.html#checking-our-quantitative-variables",
    "href": "sample-study1.html#checking-our-quantitative-variables",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.2 Checking our Quantitative Variables",
    "text": "2.2 Checking our Quantitative Variables\nWe have five quantitative variables. We want to check the range (minimum and maximum) plus for each, to ensure that we have no impossible or missing values.\n\nsur15_m |&gt;\n  select(r_pre, r_now, comfort_431, height, weight) |&gt;\n  data_codebook()\n\nselect(sur15_m, r_pre, r_now, comfort_431, height, weight) (53 rows and 5 variables, 5 shown)\n\nID | Name        | Type    | Missings |       Values |  N\n---+-------------+---------+----------+--------------+---\n1  | r_pre       | numeric | 0 (0.0%) |      [0, 90] | 53\n---+-------------+---------+----------+--------------+---\n2  | r_now       | numeric | 0 (0.0%) |      [0, 95] | 53\n---+-------------+---------+----------+--------------+---\n3  | comfort_431 | numeric | 0 (0.0%) |    [15, 100] | 53\n---+-------------+---------+----------+--------------+---\n4  | height      | numeric | 0 (0.0%) | [22.83, 217] | 53\n---+-------------+---------+----------+--------------+---\n5  | weight      | numeric | 0 (0.0%) |     [1, 320] | 53\n---------------------------------------------------------\n\n\n\nFor the three rating variables, all values are in the range [0, 100], as they must be.\nHowever, the height range doesn’t seem reasonable. With height measured in inches, do we really think there should be a height as small as 22.83 inches?\nThe weight minimum is also a problem. Is 1 pound a reasonable value?\nWe also want to create a body mass index from the height and weight data\n\n\n2.2.1 Combining height and weight into bmi and Specifying NA for Implausible Values\nWe will calculate bmi (body-mass index) from the available height (inches) and weight (pounds) data. The BMI formula for inches and pounds is available at http://www.bmi-calculator.net/bmi-formula.php. A reasonable range for BMI values is probably about 15 to 50.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(bmi = 703 * weight / height^2)\n\nsur15_m |&gt; reframe(lovedist(bmi))\n\n# A tibble: 1 × 10\n      n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    53     0  26.2  23.5  23.2  3.25 0.159  21.2  25.5  189.\n\n\nThe minimum calculated bmi value seems impossibly low, and the highest bmi seems impossibly high. Let’s look at the heights and weights involved.\n\nsur15_m |&gt; select(s_id, height, weight) |&gt; arrange(height) |&gt; head()\n\n# A tibble: 6 × 3\n  s_id  height weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 504     22.8    140\n2 530     61      140\n3 513     61.4    112\n4 519     62      126\n5 528     62      155\n6 540     62      140\n\n\n\nsur15_m |&gt; select(s_id, height, weight) |&gt; arrange(height) |&gt; tail()\n\n# A tibble: 6 × 3\n  s_id  height weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 532       72    160\n2 549       72    220\n3 506       73    145\n4 507       74    320\n5 535       74    172\n6 529      217    165\n\n\n\nsur15_m |&gt; select(s_id, height, weight) |&gt; arrange(weight) |&gt; head()\n\n# A tibble: 6 × 3\n  s_id  height weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 550     66.5      1\n2 521     63      107\n3 512     65      112\n4 513     61.4    112\n5 552     65      120\n6 526     64      121\n\n\n\nsur15_m |&gt; select(s_id, height, weight) |&gt; arrange(weight) |&gt; tail()\n\n# A tibble: 6 × 3\n  s_id  height weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 505       70    178\n2 516       71    200\n3 511       65    202\n4 546       69    210\n5 549       72    220\n6 507       74    320\n\n\nThe subjects with heights of 22.83 inches and 217 inches are implausible, and the subject with weight 1 pound is also not reasonable. We want to focus on actually plausible results.\n\nA reasonable guess is that no one in the class was less than about 122 centimeters, or 4 feet tall (48 inches) nor were they greater than about 213 centimeters, or 7 feet tall (84 inches) so we’re going to change any values outside that range to NA.\nSimilarly, it seems reasonable to assume that no one in the class was below 80 pounds (36.3 kg) or above 400 pounds (181.4 kg) so again, we’ll regard any values we see outside that range is implausible and change them to NA.\n\nI’ll do this by creating new variables height_r and weight_r where the _r (meaning “revised”) indicates to me that I’ve revised the original variable in some way without adding a lot of characters to its name.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(height_r = replace(height, height &lt; 48 | height &gt; 84, NA),\n           weight_r = replace(weight, weight &lt; 80 | weight &gt; 400, NA)) |&gt;\n    mutate(bmi = 703 * weight_r / height_r ^2)\n\nsur15_m |&gt; select(height_r, weight_r, bmi) |&gt;\n  data_codebook()\n\nselect(sur15_m, height_r, weight_r, bmi) (53 rows and 3 variables, 3 shown)\n\nID | Name     | Type    | Missings |         Values |  N\n---+----------+---------+----------+----------------+---\n1  | height_r | numeric | 2 (3.8%) |       [61, 74] | 51\n---+----------+---------+----------+----------------+---\n2  | weight_r | numeric | 1 (1.9%) |     [107, 320] | 52\n---+----------+---------+----------+----------------+---\n3  | bmi      | numeric | 3 (5.7%) | [18.64, 41.08] | 50\n--------------------------------------------------------\n\n\nSo now, we have 2 missing values of height_r, 1 missing value of weight_r and we have calculated BMI results, with 3 missing values, and our ranges (minimum and maximum) for each of these variables now look OK."
  },
  {
    "objectID": "sample-study1.html#checking-our-binary-variables",
    "href": "sample-study1.html#checking-our-binary-variables",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.3 Checking our Binary Variables",
    "text": "2.3 Checking our Binary Variables\nWe have two binary variables.\n\nsur15_m |&gt; select(english, r_before) |&gt; glimpse()\n\nRows: 53\nColumns: 2\n$ english  &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"…\n$ r_before &lt;chr&gt; \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"N…\n\n\nI’d like those to be factors in R, rather than characters.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(r_before = factor(r_before),\n           english = factor(english))\n\nsur15_m |&gt; count(r_before, english)\n\n# A tibble: 4 × 3\n  r_before english     n\n  &lt;fct&gt;    &lt;fct&gt;   &lt;int&gt;\n1 No       No         10\n2 No       Yes        18\n3 Yes      No          8\n4 Yes      Yes        17\n\n\nOK. No missingness, and no values out of the range of our expectations. Good."
  },
  {
    "objectID": "sample-study1.html#checking-our-multi-category-variables",
    "href": "sample-study1.html#checking-our-multi-category-variables",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.4 Checking our Multi-Category Variables",
    "text": "2.4 Checking our Multi-Category Variables\nFor each of our multi-categorical variables, I’ll run a quick tabyl to see if we have any surprising results or missing values. Then I’ll revise each of them (as needed) to have more suitable (mostly, shorter) level names. In addition to checking for missingness and inappropriate values, we want to collapse some categories, or adjust names or labeling to mirror what we need in our analyses.\n\n2.4.1 The grades variable\n\nsur15_m |&gt;\n  tabyl(grades)\n\n                                           grades  n    percent valid_percent\n                        A. Individual Assignments 40 0.75471698     0.7692308\n B. Partner Assignments (you and 1 other student)  6 0.11320755     0.1153846\n  C. Group Assignments (you and 2 or more others)  6 0.11320755     0.1153846\n                                             &lt;NA&gt;  1 0.01886792            NA\n\n\nFor grades, we want to create a new factor called grades_r which is a factor and which has shorter level names, specifically: Individual, Partner and Group, in that order. We’ll use the fct_recode function from forcats:\n\nsur15_m &lt;- sur15_m |&gt; \n    mutate(grades_r = fct_recode(factor(grades), \n        \"Individual\" = \"A. Individual Assignments\",\n        \"Partner\" = \"B. Partner Assignments (you and 1 other student)\",\n        \"Group\" = \"C. Group Assignments (you and 2 or more others)\"))\n\n# sanity check to ensure we coded correctly\nsur15_m |&gt; count(grades, grades_r)\n\n# A tibble: 4 × 3\n  grades                                           grades_r       n\n  &lt;chr&gt;                                            &lt;fct&gt;      &lt;int&gt;\n1 A. Individual Assignments                        Individual    40\n2 B. Partner Assignments (you and 1 other student) Partner        6\n3 C. Group Assignments (you and 2 or more others)  Group          6\n4 &lt;NA&gt;                                             &lt;NA&gt;           1\n\n\n\nThat looks like we’ve correctly renamed the values.\nFor this demonstration, we’ll allow counts as low as 5 for individual levels of a categorical variable, because of the small sample size, so I won’t collapse the levels at all.\nWe have a missing value here, so we’ll need to deal with that later.\n\n\n\n2.4.2 The medium variable\n\nsur15_m |&gt;\n  tabyl(medium)\n\n                                   medium  n    percent\n                                A. Movies 17 0.32075472\n                            B. Television 22 0.41509434\n C. Print (including books, comics, etc.)  9 0.16981132\n                                 D. Other  5 0.09433962\n\n\n\nWe have no missing values, so that’s good.\nIn this demonstration, we will require that each category have at least 5 responses, so while this just barely meets that standard, I think I will go ahead and collapse the variable down to just three categories.\n\nFor the medium variable, we want to collapse the Print and Other levels to form a three category variable (with levels Movies, TV and Other) called medium_r.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(medium_r = fct_recode(factor(medium), \n                                 \"Movies\" = \"A. Movies\",\n                                 \"TV\" = \"B. Television\",\n                                 \"Other\" = \"C. Print (including books, comics, etc.)\",\n                                 \"Other\" = \"D. Other\"))\n\nsur15_m |&gt; count(medium, medium_r) # sanity check\n\n# A tibble: 4 × 3\n  medium                                   medium_r     n\n  &lt;chr&gt;                                    &lt;fct&gt;    &lt;int&gt;\n1 A. Movies                                Movies      17\n2 B. Television                            TV          22\n3 C. Print (including books, comics, etc.) Other        9\n4 D. Other                                 Other        5\n\n\nOK. Looks good now.\n\n\n2.4.3 The fiction variable\n\nsur15_m |&gt;\n  tabyl(fiction)\n\n                      fiction  n    percent\n                    A. Comedy 18 0.33962264\n                     B. Drama 15 0.28301887\n                    C. Action  5 0.09433962\n         D. Horror / Thriller  1 0.01886792\n E. Fantasy / Science Fiction 14 0.26415094\n\n\n\nNo signs of missing values, so that’s good.\nWith only one value in category D and only 5 in category C, we will need to do some collapsing to use this variable later.\n\n\n\n2.4.4 Collapsing and recoding levels of fiction\nFor the fiction variable, we want to form a four category variable (with levels Comedy, Drama, Fantasy/SF, Other) called fiction_r.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(fiction_r = fct_recode(factor(fiction), \n                                 \"Comedy\" = \"A. Comedy\",\n                               \"Drama\" = \"B. Drama\",\n                               \"Fantasy/SF\" = \"E. Fantasy / Science Fiction\",\n                               \"Other\" = \"C. Action\",\n                               \"Other\" = \"D. Horror / Thriller\"))\n\nsur15_m |&gt; count(fiction, fiction_r) # sanity check\n\n# A tibble: 5 × 3\n  fiction                      fiction_r      n\n  &lt;chr&gt;                        &lt;fct&gt;      &lt;int&gt;\n1 A. Comedy                    Comedy        18\n2 B. Drama                     Drama         15\n3 C. Action                    Other          5\n4 D. Horror / Thriller         Other          1\n5 E. Fantasy / Science Fiction Fantasy/SF    14\n\n\nActually, I’d like to reorder fiction_r to put Other last.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(fiction_r = fct_relevel(fiction_r, \n                                   \"Comedy\", \"Drama\",\n                                   \"Fantasy/SF\", \"Other\"))\n\nOK. Let’s see what we have now…\n\nsur15_m |&gt;\n    tabyl(medium_r, fiction_r) |&gt;\n    gt()\n\n\n\n\n\n\n\nmedium_r\nComedy\nDrama\nFantasy/SF\nOther\n\n\n\n\nMovies\n4\n5\n6\n2\n\n\nTV\n11\n5\n2\n4\n\n\nOther\n3\n5\n6\n0\n\n\n\n\n\n\n\nOK. I wish we didn’t have that zero cell in the cross-tabulation, but we’ll leave it alone, rather than collapsing further, given our small number of observations in this demonstration."
  },
  {
    "objectID": "sample-study1.html#creating-our-analytic-tibble",
    "href": "sample-study1.html#creating-our-analytic-tibble",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.5 Creating our Analytic Tibble",
    "text": "2.5 Creating our Analytic Tibble\nSo our analytic tibble, which I’ll call sur15 should contains only the twelve variables that appear in our code book.\n\nsur15 &lt;- sur15_m |&gt;\n    select(s_id, r_pre, r_now, comfort_431, \n           height_r, weight_r, bmi, \n           r_before, english,\n           grades_r, medium_r, fiction_r)"
  },
  {
    "objectID": "sample-study1.html#list-of-missing-values",
    "href": "sample-study1.html#list-of-missing-values",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.6 List of Missing Values",
    "text": "2.6 List of Missing Values\nWe can count the number of missing observations in each variable, with …\n\nmiss_var_summary(sur15)\n\n# A tibble: 12 × 3\n   variable    n_miss pct_miss\n   &lt;chr&gt;        &lt;int&gt;    &lt;num&gt;\n 1 bmi              3     5.66\n 2 height_r         2     3.77\n 3 weight_r         1     1.89\n 4 grades_r         1     1.89\n 5 s_id             0     0   \n 6 r_pre            0     0   \n 7 r_now            0     0   \n 8 comfort_431      0     0   \n 9 r_before         0     0   \n10 english          0     0   \n11 medium_r         0     0   \n12 fiction_r        0     0   \n\n\nWe can see the subjects who have missing values in several ways, including…\n\nmiss_case_summary(sur15)\n\n# A tibble: 53 × 3\n    case n_miss pct_miss\n   &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;\n 1     4      2    16.7 \n 2    29      2    16.7 \n 3    50      2    16.7 \n 4    16      1     8.33\n 5     1      0     0   \n 6     2      0     0   \n 7     3      0     0   \n 8     5      0     0   \n 9     6      0     0   \n10     7      0     0   \n# ℹ 43 more rows\n\n\n\nsur15[which(!complete.cases(sur15)),]\n\n# A tibble: 4 × 12\n  s_id  r_pre r_now comfort_431 height_r weight_r   bmi r_before english\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 504      20    80          50     NA        140  NA   Yes      No     \n2 516       0    50          70     71        200  27.9 No       Yes    \n3 529      25    75          85     NA        165  NA   No       Yes    \n4 550       0     0          15     66.5       NA  NA   No       No     \n# ℹ 3 more variables: grades_r &lt;fct&gt;, medium_r &lt;fct&gt;, fiction_r &lt;fct&gt;\n\n\nIn our sample of respondents, we have:\n\n49 subjects with no missing values,\n1 subject (s_id = 516) who is missing grades_r,\n2 subjects (s_id = 504 and 529) who are missing height_r and bmi, and\n1 subject (s_id = 550) who is missing weight_r and bmi."
  },
  {
    "objectID": "sample-study1.html#filtering-to-complete-cases",
    "href": "sample-study1.html#filtering-to-complete-cases",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.7 Filtering to Complete Cases",
    "text": "2.7 Filtering to Complete Cases\nNow, in Study 1, I’ve asked you to filter your data to complete cases throughout. So I’ll do that now, and wind up with just 49 subjects in the data. I’ll include an explicit statement here (and you should, too) that I’m assuming Missing Completely at Random for the missing values in these data.\n\n\n\n\n\n\nNote\n\n\n\nAccording to the mcar_test() function (part of the naniar package) which runs Little’s missing completely at random test1, this is a debatable assumption (we’d like to see a high \\(p\\) value here) but we’ll make it anyway for Study 1.\n\nsur15 |&gt; mcar_test()\n\n# A tibble: 1 × 4\n  statistic    df p.value missing.patterns\n      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;            &lt;int&gt;\n1      42.9    31  0.0763                4\n\n\n\n\n\nsur_15 &lt;- sur15 |&gt; drop_na()\n\nnrow(sur_15)\n\n[1] 49"
  },
  {
    "objectID": "sample-study1.html#variable-descriptions",
    "href": "sample-study1.html#variable-descriptions",
    "title": "431 Project B Sample Study 1 Report",
    "section": "3.1 Variable Descriptions",
    "text": "3.1 Variable Descriptions\nThe 12 variables in our tidy data set sur_15 for this demonstration are as follows. The Type column indicates the number of levels in each categorical (factor) variable. Recall that we had missing data in height_r, weight_r, bmi and grades_r but I’ve filtered that away, so we have no missingness left now. As for the Type information, I’m using Quant to indicate quantitative variables, and Cat-x indicates a categorical variable (factor) with x levels.\n\n\n\n\n\n\n\n\nVariable\nType\nDescription / Levels\n\n\n\n\ns_id\nID\nsubject code\n\n\nr_pre\nQuant\n0 (SD) - 100 (SA) with Prior to taking 431, I was totally confident and comfortable with using R.\n\n\nr_now\nQuant\n0 (SD) - 100 (SA) with Right now, I am totally confident and comfortable with using R.\n\n\ncomfort_431\nQuant\n0 (SD) - 100 (SA) with I am very comfortable with my understanding of the material discussed so far in 431.\n\n\nheight_r\nQuant\nWhat is your height, in inches\n\n\nweight_r\nQuant\nWhat is your weight, in pounds\n\n\nbmi\nQuant\n703 x weight/(height squared)\n\n\nr_before\nCat-2\nyes, no: Before taking 431, had you ever used R before?\n\n\nenglish\nCat-2\nyes, no: Is English the language you speak better than any other?\n\n\ngrades_r\nCat-3\nIndividual, Partner, Group: In your graduate and undergraduate educational experience, which of the following types of assignments have you received the HIGHEST grades for?\n\n\nmedium_r\nCat-3\nMovies, TV, Other: Which medium do you use most to get your fictional stories (containing plot)?\n\n\nfiction_r\nCat-4\nComedy, Drama, Fantasy/SF, Other: Which type of fictional stories do you consume most?"
  },
  {
    "objectID": "sample-study1.html#analytic-tibble",
    "href": "sample-study1.html#analytic-tibble",
    "title": "431 Project B Sample Study 1 Report",
    "section": "3.2 Analytic Tibble",
    "text": "3.2 Analytic Tibble\nNow, I’ll prove that sur_15 is a tibble by printing it.\n\nsur_15\n\n# A tibble: 49 × 12\n   s_id  r_pre r_now comfort_431 height_r weight_r   bmi r_before english\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n 1 501       0    70          90     68.1      162  24.6 Yes      No     \n 2 502       0    70          50     67        151  23.6 No       Yes    \n 3 503       0    10          70     62.5      127  22.9 No       Yes    \n 4 505      80    90          85     70        178  25.5 Yes      Yes    \n 5 506       0    50          80     73        145  19.1 No       Yes    \n 6 507      50    50          50     74        320  41.1 Yes      Yes    \n 7 508      60    75          80     70        165  23.7 Yes      No     \n 8 509       0    50          75     64        135  23.2 No       Yes    \n 9 510      30    30          50     69        155  22.9 No       Yes    \n10 511       0    50          88     65        202  33.6 No       Yes    \n# ℹ 39 more rows\n# ℹ 3 more variables: grades_r &lt;fct&gt;, medium_r &lt;fct&gt;, fiction_r &lt;fct&gt;"
  },
  {
    "objectID": "sample-study1.html#data-summary",
    "href": "sample-study1.html#data-summary",
    "title": "431 Project B Sample Study 1 Report",
    "section": "3.3 Data Summary",
    "text": "3.3 Data Summary\n\n3.3.1 data_description()\nHere’s a data_description() result to show some information about the distribution of each quantitative variables in the sur_15 tibble.\n\ndescribe_distribution(sur_15 |&gt; select(-s_id))\n\nVariable    |   Mean |    SD |   IQR |            Range | Skewness | Kurtosis\n-----------------------------------------------------------------------------\nr_pre       |  21.94 | 31.31 | 50.00 |    [0.00, 90.00] |     1.03 |    -0.52\nr_now       |  57.02 | 26.34 | 38.00 |    [0.00, 95.00] |    -0.62 |    -0.54\ncomfort_431 |  77.65 | 16.39 | 20.00 |  [30.00, 100.00] |    -1.15 |     0.94\nheight_r    |  67.42 |  3.49 |  5.50 |   [61.00, 74.00] |    -0.02 |    -0.87\nweight_r    | 154.97 | 34.31 | 37.50 | [107.00, 320.00] |     2.46 |    10.33\nbmi         |  23.86 |  4.11 |  4.22 |   [18.64, 41.08] |     1.94 |     5.61\n\nVariable    |  n | n_Missing\n----------------------------\nr_pre       | 49 |         0\nr_now       | 49 |         0\ncomfort_431 | 49 |         0\nheight_r    | 49 |         0\nweight_r    | 49 |         0\nbmi         | 49 |         0\n\n\n\n\n3.3.2 data_codebook()\nAnd here’s the data_codebook() result, which adds in tabulations of the categorical variables.\n\ndata_codebook(sur_15 |&gt; select(-s_id))\n\nselect(sur_15, -s_id) (49 rows and 11 variables, 11 shown)\n\nID | Name        | Type        | Missings |         Values |          N\n---+-------------+-------------+----------+----------------+-----------\n1  | r_pre       | numeric     | 0 (0.0%) |        [0, 90] |         49\n---+-------------+-------------+----------+----------------+-----------\n2  | r_now       | numeric     | 0 (0.0%) |        [0, 95] |         49\n---+-------------+-------------+----------+----------------+-----------\n3  | comfort_431 | numeric     | 0 (0.0%) |      [30, 100] |         49\n---+-------------+-------------+----------+----------------+-----------\n4  | height_r    | numeric     | 0 (0.0%) |       [61, 74] |         49\n---+-------------+-------------+----------+----------------+-----------\n5  | weight_r    | numeric     | 0 (0.0%) |     [107, 320] |         49\n---+-------------+-------------+----------+----------------+-----------\n6  | bmi         | numeric     | 0 (0.0%) | [18.64, 41.08] |         49\n---+-------------+-------------+----------+----------------+-----------\n7  | r_before    | categorical | 0 (0.0%) |             No | 25 (51.0%)\n   |             |             |          |            Yes | 24 (49.0%)\n---+-------------+-------------+----------+----------------+-----------\n8  | english     | categorical | 0 (0.0%) |             No | 16 (32.7%)\n   |             |             |          |            Yes | 33 (67.3%)\n---+-------------+-------------+----------+----------------+-----------\n9  | grades_r    | categorical | 0 (0.0%) |     Individual | 40 (81.6%)\n   |             |             |          |        Partner |  4 ( 8.2%)\n   |             |             |          |          Group |  5 (10.2%)\n---+-------------+-------------+----------+----------------+-----------\n10 | medium_r    | categorical | 0 (0.0%) |         Movies | 15 (30.6%)\n   |             |             |          |             TV | 21 (42.9%)\n   |             |             |          |          Other | 13 (26.5%)\n---+-------------+-------------+----------+----------------+-----------\n11 | fiction_r   | categorical | 0 (0.0%) |         Comedy | 17 (34.7%)\n   |             |             |          |          Drama | 14 (28.6%)\n   |             |             |          |     Fantasy/SF | 12 (24.5%)\n   |             |             |          |          Other |  6 (12.2%)\n-----------------------------------------------------------------------"
  },
  {
    "objectID": "sample-study1.html#the-question",
    "href": "sample-study1.html#the-question",
    "title": "431 Project B Sample Study 1 Report",
    "section": "4.1 The Question",
    "text": "4.1 The Question\nWe’ll compare the r_now scores to r_pre scores. The scores are paired by subject, as each subject gives us both a r_pre and r_now score, and computing and assessing within-subject differences in comfort with R makes sense, because we are interested in the change in each person’s comfort level. We’ll generally use r_now - r_pre in our calculations, so that positive numbers indicate improvements in confidence. Note that we’ll use a 90% confidence level throughout this demonstration project for all analyses, and you will do this in your actual Project B Study 1 work, as well.\nSo, our research question might be something like:\nWhat is a typical change in comfort with R experienced by students in 431 through the first couple of months in the course?"
  },
  {
    "objectID": "sample-study1.html#describing-the-data",
    "href": "sample-study1.html#describing-the-data",
    "title": "431 Project B Sample Study 1 Report",
    "section": "4.2 Describing the Data",
    "text": "4.2 Describing the Data\n\n4.2.1 Compute and summarize the paired differences\nThe natural first step is to compute paired differences between the r_now and r_pre samples, and then use graphical and numerical summaries to assess whether the sample (of differences) can be assumed to follow a Normal distribution. First, we’ll calculate the paired differences.\n\nsur_15 &lt;- sur_15 |&gt;\n    mutate(r_diff = r_now - r_pre)\n\nsur_15 |&gt; reframe(lovedist(r_diff)) |&gt; gt()\n\n\n\n\n\n\n\nn\nmiss\nmean\nsd\nmed\nmad\nmin\nq25\nq75\nmax\n\n\n\n\n49\n0\n35.08163\n29.06017\n25\n37.065\n0\n10\n60\n95\n\n\n\n\n\n\n\nOK. It appears that we have successfully subtracted the PRE data from the NOW data, and everyone has a difference of at least zero. Now, we’ll assess whether or not a Normal distribution might be a reasonable model for the data.\n\n\n4.2.2 Graphical Summaries to Assess Normality\nWe should start by looking at the distribution of these 49 values of r_diff. As we’ve seen, there’s a floor effect at zero.\nA histogram with 49 values won’t give us a lot of information. Perhaps we should focus instead on a Normal Q-Q plot and boxplot with violin? We’ll draw all three here.\n\nbw = 5 # specify width of bins in histogram\n\np1 &lt;- ggplot(sur_15, aes(x = r_diff)) +\n  geom_histogram(binwidth = bw, \n                 fill = \"slateblue\", col = \"springgreen\") +\n  stat_function(fun = function(x)\n    dnorm(x, mean = mean(sur_15$r_diff), sd = sd(sur_15$r_diff)) *\n      length(sur_15$r_diff) * bw,  \n    geom = \"area\", alpha = 0.5, fill = \"lightblue\", col = \"blue\") +\n  labs(x = \"R Comfort Rating Difference\", \n       title = \"Histogram & Normal Curve\") \n\np2 &lt;- ggplot(sur_15, aes(sample = r_diff)) +\n  geom_qq() + geom_qq_line(col = \"slateblue\") +\n  labs(y = \"Rating Difference\",\n       x = \"Standard Normal Distribution\",\n       title = \"Normal Q-Q plot\") \n\np3 &lt;- ggplot(sur_15, aes(x = r_diff, y = \"\")) +\n  geom_violin(fill = \"mintcream\") +\n  geom_boxplot(width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", shape = 16, col = \"slateblue\") +\n  labs(y = \"\", x = \"Current - Pre-class Rating Difference\", \n       title = \"Boxplot with Violin\")\n\np1 + (p2 / p3 + plot_layout(heights = c(2, 1))) +\n  plot_annotation(\n    title = \"Most Students Improved R Comfort Ratings during 431\",\n    caption = glue(\"Sample Size = \", nrow(sur_15)))\n\n\n\n\n\n\n\n\nWith just 49 observations, it will be a little difficult to get a clear picture of whether a Normal approximation is reasonable or not. I would conclude that a bootstrap approach would be a better choice here than a Normal model for the paired differences, owing to the floor effect (many zeros) in the paired differences.\n\nsur_15 |&gt; reframe(lovedist(r_diff)) |&gt; gt()\n\n\n\n\n\n\n\nn\nmiss\nmean\nsd\nmed\nmad\nmin\nq25\nq75\nmax\n\n\n\n\n49\n0\n35.08163\n29.06017\n25\n37.065\n0\n10\n60\n95\n\n\n\n\n\n\n\nThe data seem a bit right skewed, as well. The sample mean is 34.7% of a standard deviation larger than the sample median2.\n\n\n4.2.3 Did Pairing Help Reduce Nuisance Variation?\nWe would expect a strong correlation between the r_pre and r_now scores in this repeated measures analysis where each subject is assessing both their confidence before the class and then again during the class. To assess whether pairing helped reduce nuisance variation, I’ll build a scatterplot of the r_pre and r_now scores, supplemented by a Pearson correlation coefficient. Since we have so many ties in the data, with two or more points in the same place, I’ll use geom_jitter rather than geom_point to plot the points. The larger the correlation, the more that pairing will help reduce the impact of differences between subjects on the r_pre score on the comparison we’re trying to make.\n\nggplot(sur_15, aes(x = r_pre, y = r_now)) +\n    geom_jitter(col = \"slateblue\") +\n    geom_smooth(formula = y ~ x, method = \"lm\", col = \"red\") +\n    labs(title = \"Jittered Scatterplot shows moderately strong relationship\",\n         subtitle = \"especially for those starting above 0\")\n\n\n\n\n\n\n\n\nFor people with a r_pre score greater than zero, we see a pretty strong linear relationship between r_pre and r_now.\n\nsur_15 |&gt; select(r_pre, r_now) |&gt; correlation()\n\n# Correlation Matrix (pearson-method)\n\nParameter1 | Parameter2 |    r |       95% CI | t(47) |         p\n-----------------------------------------------------------------\nr_pre      |      r_now | 0.50 | [0.26, 0.69] |  3.99 | &lt; .001***\n\np-value adjustment method: Holm (1979)\nObservations: 49\n\n\nThe Pearson correlation is quite strong at 0.5 so that a linear model using the r_pre score accounts for a reasonably large fraction (25.3%) of the variation in r_now scores.\n\nIf the Pearson correlation had been small but still positive (perhaps less than 0.2), we might conclude that pairing wouldn’t be exceptionally helpful, but if the samples are meant to be paired, we should still do a paired samples analysis, but such a small correlation would imply that an independent samples comparison would come to about the same conclusion."
  },
  {
    "objectID": "sample-study1.html#main-analysis",
    "href": "sample-study1.html#main-analysis",
    "title": "431 Project B Sample Study 1 Report",
    "section": "4.3 Main Analysis",
    "text": "4.3 Main Analysis\nAs you’ll recall, we have two main methods for building confidence intervals in a paired samples analysis:\n\nThe Paired t test\nThe Bootstrap\n\nLet’s run each in this demonstration just so you have the code, even though, as mentioned, I’d be most interested in what the bootstrap approach suggests, owing to the modest non-Normality we see in the sample of differences. I’ll even throw in a Wilcoxon signed rank test approach here, even though I wouldn’t recommend you include that in Project B. In each case, we’ll build a 90% confidence interval for the population mean (or pseudo-median, in the case of the signed rank test) of the r_now - r_pre differences.\n\n4.3.1 The Paired t test approach\nHere is a 90% confidence interval for the population mean of the paired r_now - r_pre differences.\n\nlm(r_diff ~ 1, data = sur_15) |&gt; \n  model_parameters(ci = 0.90) \n\nParameter   | Coefficient |   SE |         90% CI | t(48) |      p\n------------------------------------------------------------------\n(Intercept) |       35.08 | 4.15 | [28.12, 42.04] |  8.45 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\n\nThe point estimate for the population mean of the differences is 35.08, indicating that the average subject rated agreement with the statement about confidence in R 35 points higher now than when they started the class.\nOur 90% confidence interval for the population mean of the differences is (28.12, 42.04).\n\nThe confidence interval reflects imprecision in the population estimate, based only on assuming that the participants are selected at random from the population of interest.\nWhen we generalize beyond study participants to the population they were selected at random from, then our data are compatible (at the 90% confidence level) with population mean differences between 28.12 and 42.04, depending on the assumptions of our linear model (here, our paired t test) being correct.\n\nThe assumptions of the paired t procedure are\n\nthat the matched differences are independent of each other,\nthat the matched differences represent a random sample of the population of possible matched differences,\nand that the matched differences are drawn from a Normally distributed population.\n\nThe last of these assumptions is hard to justify given these data, which is why I’d prefer the bootstrap approach in this case.\nHere, I’ve assumed a two-sided confidence interval procedure Use a two-sided confidence interval for everything you do in 431.\n\n\n\n4.3.2 The Bootstrap approach for the mean from paired samples\nHere is a 90% confidence interval for the population mean of the paired r_now - r_pre differences, as estimated by a bootstrap approach using a random seed of 431. (Note: when you set a seed for this or other analyses in the project, pick something other than 431.)\n\nset.seed(431)\n\nx_bar &lt;- sur_15 |&gt; observe(response = r_diff, stat = \"mean\")\n\nres1 &lt;- sur_15 |&gt;\n  specify(response = r_diff) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  calculate(stat = \"mean\") |&gt;\n  get_confidence_interval(level = 0.90, type = \"percentile\")\n\nres1 &lt;- res1 |&gt; mutate(pt_est = x_bar$stat) |&gt; relocate(pt_est)\n\nres1 |&gt; gt()\n\n\n\n\n\n\n\npt_est\nlower_ci\nupper_ci\n\n\n\n\n35.08163\n28.38673\n41.79898\n\n\n\n\n\n\n\n\nThe point estimate for the population mean of the differences is 35.08, indicating that the average subject rated agreement with the statement about confidence in R 35 points higher now than when they started the class.\nOur 90% confidence interval for the population mean of the differences is fairly close to what we got from the paired t test, as it turns out.\n\nThe confidence interval reflects imprecision in the population estimate, based only on assuming that the participants are selected at random from the population of interest.\nWhen we generalize beyond study participants to the population they were selected at random from, then our data are compatible (at the 90% confidence level) with population mean differences between 28.39 and 41.80, depending on the assumptions of bootstrap estimation procedure being correct.\n\nAgain, I’ve assumed a two-sided confidence interval procedure, and so we can discuss a range of reasonable estimates for the true difference in r_pre and r_now scores.\nThe assumptions of this bootstrap procedure are\n\nthat the matched differences are independent of each other, and\nthat the matched differences represent a random sample of the population of possible matched differences.\n\n\nThese assumptions seem more reasonable."
  },
  {
    "objectID": "sample-study1.html#conclusions",
    "href": "sample-study1.html#conclusions",
    "title": "431 Project B Sample Study 1 Report",
    "section": "4.4 Conclusions",
    "text": "4.4 Conclusions\nSubjects appear to improve in their comfort with R an average of 35.1 points on the 0-100 scale, with a 90% confidence interval for that average improvement of (28.4, 41.8) points. This conclusion is motivated by a bootstrap estimate to compare paired responses from students before and after the first couple of months of the course, and I feel this is the most justified approach based on my assessment of Normality in the data from these 49 students.\nA natural next step would be to look at values of something like this over multiple years, or perhaps comparing students at more than just two stages. It would also be appealing to measure comfort with R at the earlier time, and then return to the students later, rather than asking them to remember where they were at the start a couple of months later. There are several other possible next steps here, too, depending on what population you might decide to target."
  },
  {
    "objectID": "sample-study1.html#the-question-1",
    "href": "sample-study1.html#the-question-1",
    "title": "431 Project B Sample Study 1 Report",
    "section": "5.1 The Question",
    "text": "5.1 The Question\nWe’ll compare bmi by english in this analysis using independent samples. We’re comparing the mean bmi of the population represented by respondents who speak English best to the mean bmi of the population represented by the respondents who speak some other language better. There is nothing to suggest that the two samples (English bmi and non-English bmi values) are paired or matched in any way. Plus, as we’ll see, there are different numbers of English and non-English preferring subjects, so there’s no way their bmi values could be paired. As a result, we’re going to be interested in looking at the two samples separately to help us understand issues related to hypothesis testing assumptions. Note that we’ll use a 90% confidence level throughout this demonstration project for all analyses, and you will do this in your actual Project Study B work, as well.\nOur research question is:\nDid students who speak English best have meaningfully different average body mass index values than students who speak some other language better than they speak English?"
  },
  {
    "objectID": "sample-study1.html#describing-the-data-1",
    "href": "sample-study1.html#describing-the-data-1",
    "title": "431 Project B Sample Study 1 Report",
    "section": "5.2 Describing the Data",
    "text": "5.2 Describing the Data\nCan the samples (of Yes and No respondents, separately) each be modeled appropriately by a Normal distribution?\n\n5.2.1 Graphical Summaries\nLet’s build a comparison boxplot (with violins and means) to start.\n\nggplot(sur_15, aes(x = english, y = bmi, fill = english)) + \n  geom_violin(alpha = 0.3) +\n  geom_boxplot(width = 0.3) +\n  stat_summary(fun = mean, geom = \"point\", size = 3, col = \"white\") +\n  scale_fill_social() +\n  guides(fill = \"none\") +\n  labs(title = \"BMI data somewhat right skewed in each group\",\n       subtitle = \"n = 49 Students in 431: Fall 2015\",\n       x = \"Speaks English better than all other languages?\", y = \"Body Mass Index\") \n\n\n\n\n\n\n\n\nThere are at least a couple of candidate outliers in each group on the high end, which suggest some potential for meaningful skew.\nWe could also build a pair of Normal Q-Q plots.\n\nggplot(sur_15, aes(sample = bmi, col = english)) +\n  geom_qq() + geom_qq_line() +\n  facet_wrap(~ english, labeller = \"label_both\") +\n  scale_color_social() +\n  guides(col = \"none\") +\n  labs(y = \"Observed BMI values\",\n       title = \"BMI isn't well fit by a Normal model in either group\")\n\n\n\n\n\n\n\n\nIt looks like the right skew is large enough, at least in the Yes (speaks English best) group to warrant avoiding tests that require Normality. So again it looks like it’s not reasonable to assume Normality here, or even symmetry.\n\n\n5.2.2 Numerical Summaries\nWe have 16 No and 33 Yes respondents to the English language question who have known BMI values.\n\nsur_15 |&gt; group_by(english) |&gt; reframe(lovedist(bmi)) |&gt; gt()\n\n\n\n\n\n\n\nenglish\nn\nmiss\nmean\nsd\nmed\nmad\nmin\nq25\nq75\nmax\n\n\n\n\nNo\n16\n0\n23.52387\n2.971336\n23.26601\n2.409531\n19.96686\n21.25653\n24.43161\n30.27053\n\n\nYes\n33\n0\n24.02736\n4.601075\n23.17017\n3.246759\n18.63574\n21.15509\n25.60354\n41.08108\n\n\n\n\n\n\n\n\nIn the “Yes” group, the sample mean BMI is 24.03 and sample median BMI is 23.17, while the sample standard deviation of BMI is 4.60. So the mean is 18.7% of a standard deviation above the median3.\nIn the “No” group, the sample mean BMI is 23.52 and sample median BMI is 23.27, while the sample standard deviation of BMI is 2.97. So the mean is 8.4% of a standard deviation above the median.\n\nThere’s room for concern about whether a test that requires Normal distributions in the populations is a good choice here. With these small sample sizes, we’d probably be better off not making too many strong assumptions."
  },
  {
    "objectID": "sample-study1.html#main-analysis-1",
    "href": "sample-study1.html#main-analysis-1",
    "title": "431 Project B Sample Study 1 Report",
    "section": "5.3 Main Analysis",
    "text": "5.3 Main Analysis\nAs you’ll recall, we have three main methods for building confidence intervals in an independent samples analysis:\n\nWelch’s t test (t test without assuming equal variances)\nThe Pooled t test (t test with equal variances assumed)\nThe Bootstrap\n\nLet’s run each here just so you have the code, even though, as mentioned, I’d be most interested in what the bootstrap approach suggests, owing to the fact that the samples aren’t well described by Normal models or even symmetric ones. In each case, we’ll build a 90% confidence interval for the population mean comparing bmi for people who answered Yes and No to the question about English being the language they speak best.\n\n5.3.1 The Welch’s t test approach\nWith a somewhat unbalanced design (16 No and 33 Yes), the assumption of equal population variances will probably require us to look at the sample variances.\n\nsur_15 |&gt; group_by(english) |&gt;\n  summarise(n = n(), mean = mean(bmi), variance = var(bmi)) |&gt; gt()\n\n\n\n\n\n\n\nenglish\nn\nmean\nvariance\n\n\n\n\nNo\n16\n23.52387\n8.828839\n\n\nYes\n33\n24.02736\n21.169895\n\n\n\n\n\n\n\nThat’s a pretty substantial difference in variance with the Yes group a good deal more than 50% larger than the No group, so we might expect the Welch t test and pooled t test to look fairly different, and that would motivate me to focus on the Welch approach over the pooled t test. Of course, neither is a great choice here, due to the samples showing some non-Normality. Regardless, here is a 90% confidence interval for the difference between the “No” group and the “Yes” group population mean bmi based on Welch’s test.\n\nt.test(bmi ~ english, data = sur_15, conf.level = 0.90) \n\n\n    Welch Two Sample t-test\n\ndata:  bmi by english\nt = -0.4609, df = 42.944, p-value = 0.6472\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n90 percent confidence interval:\n -2.339923  1.332950\nsample estimates:\n mean in group No mean in group Yes \n         23.52387          24.02736 \n\n\n\nThe point estimates for the two population bmi means are 23.523 for No and 24.027 for Yes, so the average student who speaks English best has a BMI estimated to be about 0.504 points higher points higher than the average for a student who speaks another language better than English, based on our samples.\nOur 90% confidence interval for the difference (English - non-English) of the population means is (-1.33, 2.34).\n\nThe confidence interval reflects imprecision in the population estimate, based only on assuming that the participants are selected at random from the population of interest.\nWhen we generalize beyond study participants to the population they were selected at random from, then our data are compatible (at the 90% confidence level) with differences between the two population means between -1.33 and 2.34, depending on the assumptions of our Welch t test being correct.\n\nThe assumptions of the Welch’s t test are\n\nthat the samples in each group are drawn independently of each other,\nthat the samples in each group represent a random sample of the population of interest,\nand that the samples in each group are drawn from a Normally distributed population.\n\nThe last of these assumptions is especially hard to justify given these data.\nHere, I’ve also used a two-sided confidence interval procedure, which is what we’ll do in all work for 431, not just Project B.\n\n\n\n5.3.2 The Pooled t test (t test with equal variances)\nThe pooled t test, of course, actually adds an assumption (that either the sample sizes or the population variances are equal) to the assumptions of the Welch test. As mentioned above, the large difference in the sample variances and sample sizes makes this test unattractive, in addition to the problems with assuming Normality. Regardless, here is a 90% confidence interval for the difference between the non-English and English population mean bmi based on the pooled t test.\n\nfitB &lt;- lm(bmi ~ english, data = sur_15) \n\nmodel_parameters(fitB, ci = 0.90)\n\nParameter     | Coefficient |   SE |         90% CI | t(47) |      p\n--------------------------------------------------------------------\n(Intercept)   |       23.52 | 1.04 | [21.78, 25.27] | 22.67 | &lt; .001\nenglish [Yes] |        0.50 | 1.26 | [-1.62,  2.63] |  0.40 | 0.692 \n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\n\nThe point BMI estimates are 23.523 for No and 24.027 for Yes, so the average student who speaks English best has a BMI estimated to be about 0.504 points higher than the average for a student who speaks another language better than English, based on our samples.\nOur 90% confidence interval for the difference (English - non-English) of the population means is now (-1.62, 2.63) based on the pooled t procedure.\n\nThe confidence interval reflects imprecision in the population estimate, based only on assuming that the participants are selected at random from the population of interest.\nWhen we generalize beyond study participants to the population they were selected at random from, then our data are compatible (at the 90% confidence level) with differences between the two population means between -1.62 and 2.63, depending on the assumptions of our linear model being correct.\n\nThe assumptions of the pooled t test are\n\nthat the samples in each group are drawn independently of each other,\nthat the samples in each group represent a random sample of the population of interest,\nthe samples in each group are drawn from a Normally distributed population,\nand that either the sample sizes or the population variances are equal.\n\nThe Normality assumption remains hard to justify given these data, so we should look at alternatives.\nHere, I’ve again used a two-sided confidence interval procedure, as we’ll do in all 431 work.\n\n\n\n5.3.3 The Bootstrap for comparing means from two independent samples\nAn independent samples comparison that doesn’t require Normality is the bootstrap. Here is a 90% confidence interval for the difference between the English and non-English population bmi distributions based on the bootstrap using a seed of 431. (Note: when you set a seed for this or other analyses in the project, pick something other than 431.)\n\nset.seed(431)\nsur_15 |&gt;\n  specify(bmi ~ english) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  calculate(stat = \"diff in means\",\n    order = c(\"Yes\", \"No\") ) |&gt;\n  get_confidence_interval(level = 0.90, type = \"percentile\")\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1    -1.19     2.28\n\n\n\nThe population mean BMI in those who said Yes is estimated to be about 0.504 points higher than the population mean BMI for those who said No, based on our samples. So the mean differences’ point estimate is 0.504\nOur 90% bootstrapped confidence interval for the difference (Yes - No) of the population means is (-1.19, 2.28).\n\nWhen we generalize beyond study participants to the population they were selected at random from, then our data are compatible (at the 90% confidence level) with differences between the two population means between -1.19 and 2.28, depending on the assumptions of our bootstrap estimation procedure being correct.\n\nThe assumptions of this bootstrap procedure are:\n\nthat the samples in each group are drawn independently of each other,\nand that the samples in each group represent a random sample of the population of interest.\n\nAgain, I’ve used a two-sided confidence interval procedure.\n\nSo, I think the bootstrap procedure would be most appropriate here, due to the non-Normality (and in particular the asymmetry) in the samples."
  },
  {
    "objectID": "sample-study1.html#conclusions-1",
    "href": "sample-study1.html#conclusions-1",
    "title": "431 Project B Sample Study 1 Report",
    "section": "5.4 Conclusions",
    "text": "5.4 Conclusions\nWe find a point estimate of 0.51 and a 90% confidence interval of (-1.19, 2.28) for the difference between the population mean BMI for those who speak English best minus the population mean BMI for those who speak another language best, based on our sample. This conclusion is motivated by a bootstrap estimate to compare the two groups (English and non-English) across 49 subjects. I feel this is the most justified approach based on the apparent skew in the data (particularly among those who speak English best) in these students.\nIf this were an actual Project B Study 1, I’d discuss the other issues that go into a conclusion, including limitations of this study and suggestions about logical next steps. But I’ll leave that to you."
  },
  {
    "objectID": "sample-study1.html#the-question-2",
    "href": "sample-study1.html#the-question-2",
    "title": "431 Project B Sample Study 1 Report",
    "section": "6.1 The Question",
    "text": "6.1 The Question\nWe’ll compare comfort_431 by grades_r in this analysis, using the analysis of variance, and related tools. We’re comparing the mean comfort_431 scores of the population represented by the respondents who got their best grades_r on individual work, to the population represented by the respondents who got their best grades_r with a partner, to the population represented by the respondents who got their best grades_r on group work. There is no link between subjects across the three grades_r groups, so the samples are independent. Plus, as we’ll see, there are different numbers of subjects in the three grades_r groups, so there’s no way their comfort_431 values could be matched. As a result, we’re going to be interested in looking at the three samples separately to help us understand issues related to hypothesis testing assumptions. Note that we’ll use a 90% confidence level throughout this demonstration project for all analyses, and you will do this in your actual Project B Study 1 work, as well.\nIf this were an actual Study 1, rather than a demonstration, I’d build a research question here, but that will be your job."
  },
  {
    "objectID": "sample-study1.html#describing-the-data-2",
    "href": "sample-study1.html#describing-the-data-2",
    "title": "431 Project B Sample Study 1 Report",
    "section": "6.2 Describing the Data",
    "text": "6.2 Describing the Data\nI’ll start by looking at the range of the comfort_431 data within each grades_r group.\n\nsur_15 |&gt; group_by(grades_r) |&gt; reframe(lovedist(comfort_431))\n\n# A tibble: 3 × 11\n  grades_r       n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Individual    40     0  79.0  15.3    80  14.8    35  73.8  90     100\n2 Partner        4     0  63.8  23.6    70  11.1    30  60    73.8    85\n3 Group          5     0  78.4  17.8    85  14.8    50  73    89      95\n\n\nWe have only 4 and 5 respondents in the Partner and Group grades_r categories, respectively, so that will make it difficult to say much about the distributions of comfort_431 in those populations.\n\n6.2.1 Graphical Summaries\nSince we are exploring the distributions of three independent samples, I’ll plot each of the groups in a comparison boxplot, as a start.\n\nggplot(sur_15, aes(x = grades_r, y = comfort_431, fill = grades_r)) +\n  geom_violin(alpha = 0.3) +\n  geom_boxplot(width = 0.3) +\n  stat_summary(fun = \"mean\", geom = \"point\", size = 3, col = \"white\") +\n  coord_flip() +\n  scale_fill_social() +\n  guides(fill = \"none\") +\n  labs(title = \"Comfort with 431 by Type of Assignment that produces best grades_r\",\n       y = \"Comfort with 431 Materials (0-100)\",\n       x = \"\")\n\n\n\n\n\n\n\n\nThe sample sizes are so small that histograms for those two levels of the grades_r factor (Partner and Group) tell us nothing of substantial value.\n\nggplot(sur_15, aes(x = comfort_431)) +\n  geom_histogram(aes(fill = grades_r), bins = 10, col = \"white\") +\n  facet_wrap(~ grades_r, labeller = \"label_both\") +\n  scale_fill_social() +\n  guides(fill = \"none\") +\n  labs(title = \"Comfort with 431 by Type of Assignment that produces best grades_r\",\n       y = \"Comfort with 431 Materials (0-100)\",\n       x = \"\")\n\n\n\n\n\n\n\n\n\nIn addition, the Individual data look as though they may be either skewed to the left a bit or at least have one potential outlier.\nWith these tiny sample sizes (less than 10 observations) these plots don’t really help. All of the values in each group are within the stated response levels (0-100) but otherwise, there’s not a lot to go on. ANOVA is quite robust, so we’ll run it, but I expect that a Kruskal-Wallis approach may also be useful here.\n\n\n\n6.2.2 Numerical Summaries\nWith so few observations in the Partner and Group grades_r levels, there’s not much to see in numerical summaries, either.\n\nsur_15 |&gt; group_by(grades_r) |&gt; reframe(lovedist(comfort_431))\n\n# A tibble: 3 × 11\n  grades_r       n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Individual    40     0  79.0  15.3    80  14.8    35  73.8  90     100\n2 Partner        4     0  63.8  23.6    70  11.1    30  60    73.8    85\n3 Group          5     0  78.4  17.8    85  14.8    50  73    89      95\n\n\nWe have 40 Individual, 4 Partner and 5 Group subjects with known comfort levels.\nThe conclusion I draw from all of this is that we need to run but that we probably can’t trust an ANOVA here, with such small sample sizes in the non-Individual grades_r levels. Anything below 10 subjects is just too small, and, practically, I’d consider collapsing the groups to Individual vs. All Other. But for this demonstration, I’ll press on."
  },
  {
    "objectID": "sample-study1.html#analysis-of-variance",
    "href": "sample-study1.html#analysis-of-variance",
    "title": "431 Project B Sample Study 1 Report",
    "section": "6.3 Analysis of Variance",
    "text": "6.3 Analysis of Variance\nLet’s run the ANOVA here just so you have the code, even though we don’t have large enough data samples in the Partner and Group levels to justify statistical inference at all.\nThe Analysis of Variance compares the means of comfort_431 in the three grades_r populations. We can run the analysis using either of two approaches, each of which we’ll show in what follows.\n\nfitC &lt;- lm(comfort_431 ~ grades_r, data = sur_15) \n\nfitC |&gt; anova()\n\nAnalysis of Variance Table\n\nResponse: comfort_431\n          Df  Sum Sq Mean Sq F value Pr(&gt;F)\ngrades_r   2   843.3  421.63   1.609 0.2111\nResiduals 46 12053.8  262.04               \n\nfitC |&gt; eta_squared()\n\nFor one-way between subjects designs, partial eta squared is equivalent\n  to eta squared. Returning eta squared.\n\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\ngrades_r  | 0.07 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n\nHere, we’d conclude only that the results we have are not particularly consistent with an assumption that there are no differences between the population mean comfort_431 scores for the three grades_r categories.\nThe grades_r account for \\(\\eta^2 = \\frac{843.3}{843.3 + 12053.8} = 0.07\\) or 7% of the variation in comfort_431 scores in our sample.\nThe natural next question is to try to identify which pairs of grades_r categories show larger estimated differences, and we’ll tackle that in a moment with a Bonferroni/Holm approach (although you are welcome to use Tukey HSD instead.)\nANOVA is the natural extension of the pooled t test for two independent samples, and so it has the same set of assumptions when we compare population means across multiple categories (here, the three grades_r categories)…\n\nthat the samples in each category are drawn independently of each other,\nthat the samples in each category represent a random sample of the population of interest,\nthe samples in each category are drawn from a Normally distributed population,\nand that either the sample sizes or the population variances are equal across the categories.\n\n\nThe main problem here is that the sample size is so small that we can’t tell whether this result is truly reasonable or not. We really need a minimum of 15 observations (and ideally more like 30) in each group to let our histograms and boxplots have any chance to be informative on these points. We’ll move on to looking at the pairwise comparisons, though, in this demonstration.\n\n6.3.1 Holm approach to Pairwise Comparisons of Means\nWe have two approaches available for dealing with multiple comparisons. If we had not pre-planned the full set of pairwise comparisons of comfort_431 across the grades_r categories, or if we wanted to use a fairly conservative approach, we could apply a Holm correction to our comparisons. This works reasonably well even with an unbalanced design, such as we have here, and I recommend you use this approach in Project B Study 1 Analysis C4.\n\nconC1 &lt;- estimate_contrasts(fitC, contrast = \"grades_r\", \n                           ci = 0.90, p.adjust = \"holm\")\n\nconC1 |&gt; gt()\n\n\n\n\n\n\n\nLevel1\nLevel2\nDifference\nSE\nCI_low\nCI_high\nt\ndf\np\n\n\n\n\nPartner\nIndividual\n-15.20\n8.488878\n-29.449944\n-0.9500557\n-1.79057811\n46\n0.0799432\n\n\nGroup\nIndividual\n-0.55\n7.678469\n-13.439542\n12.3395419\n-0.07162886\n46\n0.9432078\n\n\nGroup\nPartner\n14.65\n10.859003\n-3.578579\n32.8785788\n1.34911094\n46\n0.1839050\n\n\n\n\n\n\n\n\nOur process detects positive differences between the mean of the Partner category and the means of the other two categories, but suggests that the difference between Individual and Group means covers both positive and negative values.\n\nNote that a more comprehensive discussion of the confidence intervals here might be helpful, but I’ll leave that to you.\n\nThe assumptions here include the ANOVA assumptions, which are no more or less justified than they were before. We do not, however, require that our pairwise comparisons be pre-planned.\n\nHere is the plot of the results.\n\nconC1_tib &lt;- tibble(conC1) |&gt;  \n  mutate(contr = str_c(Level1, \" - \", Level2))\n\nggplot(conC1_tib, aes(y = contr, x = Difference)) +\n  geom_point() +\n  geom_errorbar(aes(xmin = CI_low, xmax = CI_high)) +\n  geom_vline(xintercept = 0, col = \"red\", lty = \"dashed\") +\n  labs(title = \"Holm 90% HSD Intervals for Comfort with 431\",\n       y = \"Contrast\", \n       x = \"Difference in Comfort with 431\")"
  },
  {
    "objectID": "sample-study1.html#conclusions-2",
    "href": "sample-study1.html#conclusions-2",
    "title": "431 Project B Sample Study 1 Report",
    "section": "6.4 Conclusions",
    "text": "6.4 Conclusions\nOur conclusions are:\n\nthat the sample size is just too small in the non-Individual grades_r categories to draw very firm conclusions, and\nthe ANOVA results don’t appear to have the power to detect meaningful differences between the means based on this small sample.\n\n\n\n\n\n\n\nNote\n\n\n\nI’ve made no special effort here to write these conclusions in the format we’re looking for in your Study 1 work, because you’ll have larger sample sizes, and (I hope) more faith as a result in the comparisons you build."
  },
  {
    "objectID": "sample-study1.html#the-question-3",
    "href": "sample-study1.html#the-question-3",
    "title": "431 Project B Sample Study 1 Report",
    "section": "7.1 The Question",
    "text": "7.1 The Question\nWe’ll look at the association of r_before with english in this analysis. The r_before variable and the english variable each have two levels, and suppose we are interested in whether english has an impact on r_before, so we’ll build a contingency table with english in the rows and r_before in the columns. Note that we’ll use a 90% confidence level and the add 2 successes and 2 failures Bayesian augmentation, and you will do this in your actual Project B Study 1 work, as well. I’ll remind you that in your Project B, we’re requiring you to have a minimum number of observations within each cell of the table that I cannot meet here with this tiny sample size.\nIf this were an actual Study 1, rather than a demonstration, I’d build a research question here, but I have decided to leave that work to you."
  },
  {
    "objectID": "sample-study1.html#describing-the-data-3",
    "href": "sample-study1.html#describing-the-data-3",
    "title": "431 Project B Sample Study 1 Report",
    "section": "7.2 Describing the Data",
    "text": "7.2 Describing the Data\nHere is the data for our 2x2 table.\n\nsur_15 |&gt; tabyl(english, r_before) |&gt; adorn_title()\n\n         r_before    \n english       No Yes\n      No        9   7\n     Yes       16  17\n\n\nThose names could use some work, I think.\n\nThe row names, in order, should be something like “English” (where “Yes” is now) and “Not English” with “English” first\nThe column names, respectively, should be “Prior R user” and “No Prior R”, with “Prior R User” first.\n\n\nsur_15_D &lt;- sur_15 |&gt;\n  select(s_id, english, r_before) |&gt;\n  mutate(english_r = fct_recode(factor(english),\n                                \"Not English\" = \"No\",\n                                \"English\" = \"Yes\"),\n         english_r = fct_relevel(english_r, \"English\"),\n         r_before_r = fct_recode(factor(r_before),\n                                 \"No Prior R\" = \"No\",\n                                 \"Prior R user\" = \"Yes\"),\n         r_before_r = fct_relevel(r_before_r, \"Prior R user\"))\n\n\nsur_15_D |&gt; tabyl(english_r, r_before_r) \n\n   english_r Prior R user No Prior R\n     English           17         16\n Not English            7          9"
  },
  {
    "objectID": "sample-study1.html#main-analysis-2",
    "href": "sample-study1.html#main-analysis-2",
    "title": "431 Project B Sample Study 1 Report",
    "section": "7.3 Main Analysis",
    "text": "7.3 Main Analysis\nI strongly encourage you to use the Bayesian augmentation where we add two successes and add two failures, as recommended in Agresti and Coull5, and to use 90% confidence levels. To accomplish this I’ll use the twoby2 function in the Epi package.\n\nt1 &lt;- table(sur_15_D$english_r, sur_15_D$r_before_r)\n\ntwoby2(t1 + 2, conf.level = 0.90) \n\n2 by 2 table analysis: \n------------------------------------------------------ \nOutcome   : Prior R user \nComparing : English vs. Not English \n\n            Prior R user No Prior R    P(Prior R user) 90% conf. interval\nEnglish               19         18             0.5135    0.3806   0.6445\nNot English            9         11             0.4500    0.2809   0.6315\n\n                                   90% conf. interval\n             Relative Risk: 1.1411    0.7030   1.8522\n         Sample Odds Ratio: 1.2901    0.5161   3.2248\nConditional MLE Odds Ratio: 1.2844    0.4506   3.7146\n    Probability difference: 0.0635   -0.1576   0.2740\n\n             Exact P-value: 0.7828 \n        Asymptotic P-value: 0.6474 \n------------------------------------------------------\n\n\nNote what I did to add two observations to each cell of the table.\n\nIn your Project B write-up, be sure to interpret the point estimates of the relative risk and the odds ratio (the sample one, not the conditional MLE one) and the probability difference. For the confidence intervals, though, just write out your interpretation of the confidence interval explanation for the probability difference.\n\nWe can draw conclusions now about:\n\nThe individual probabilities of being a prior R user in the English and non-English groups, and 90% confidence intervals for each at the top of the output, so that, for instance, we estimate the probability of prior R usage among subjects for whom English is not their best language at 0.45, with 90% confidence interval (0.29, 0.63).\nThe relative risk of Prior R use given English vs. Prior R use given non-English, which is estimated to be 1.14, with 90% CI (0.70, 1.85). (In your project, you’ll explain what your relative risk point estimate means in detail, but don’t worry about interpreting the CI - just specify the lower and upper bounds.)\nThe odds ratio describing the odds of Prior R use given English vs. Non-English, which is estimated to be 1.29 with 90% CI (0.52, 3.22). (In your project B, you’ll explain what your odds ratio point estimate means in detail, but don’t worry about interpreting the CI - just specify the lower and upper bounds.)\nThe difference in probability of Prior R use for English vs. non-English subjects, which is estimated to be 0.0635, with a 90% confidence interval of (-0.1576, 0.2740). (In your project, you’ll explain what your point estimate for the probability difference means in detail and also state and interpret the CI for the probability difference.)\nThe chi-square test of independence, which assesses the null hypothesis of no association between language preference and prior R usage, using either Fisher’s exact test or the Pearson chi-square test (labeled asymptotic here.) The p value here is quite large.\n\n\n7.3.1 Checking Assumptions\nSince each cell in our (non-augmented) 2x2 table is at least 5, R throws no warning messages. We should be reasonably comfortable with the chi-square test of independence here. If every cell was 10 or more, we’d be even more comfortable.\n\n\n7.3.2 What If We Wanted to Type in the Table Ourselves?\nWith the twobytwo function available in the Love-boost.R script, we can directly obtain 90% confidence intervals. For example, suppose we had the following data, pulled from our 2016 survey:\n\n\n\n2016 Survey\nDrank Tea Recently\nDidn’t Drink Tea\n\n\n\n\nNot Born in US\n21\n10\n\n\nUS Born\n20\n18\n\n\n\nSuppose we wanted to use twobytwo and the +2/+4 Bayesian augmentation (adding 2 to the count in each cell of our 2x2 table) and a 90% confidence interval for this comparison, to see whether the population proportions who drank tea recently differ between those born in and out of the US.\n\ntwobytwo(21+2, 10+2, 20+2, 18+2,\n         \"Not US Born\", \"US Born\", \"Drank Tea\", \"No Tea\",\n         conf.level = 0.90)\n\n2 by 2 table analysis: \n------------------------------------------------------ \nOutcome   : Drank Tea \nComparing : Not US Born vs. US Born \n\n            Drank Tea No Tea    P(Drank Tea) 90% conf. interval\nNot US Born        23     12          0.6571    0.5162   0.7749\nUS Born            22     20          0.5238    0.3982   0.6465\n\n                                   90% conf. interval\n             Relative Risk: 1.2545    0.9160   1.7181\n         Sample Odds Ratio: 1.7424    0.8024   3.7839\nConditional MLE Odds Ratio: 1.7299    0.7276   4.1948\n    Probability difference: 0.1333   -0.0512   0.3036\n\n             Exact P-value: 0.2561 \n        Asymptotic P-value: 0.2389 \n------------------------------------------------------"
  },
  {
    "objectID": "sample-study1.html#conclusions-3",
    "href": "sample-study1.html#conclusions-3",
    "title": "431 Project B Sample Study 1 Report",
    "section": "7.4 Conclusions",
    "text": "7.4 Conclusions\nOur primary conclusions about the study we’ve done here in Analysis D should be motivated by comparing the point estimates of the relative risk and odds ratio to what they would be (i.e., 1) if there was no relationship, and a more thorough description of the estimated difference in probabilities between the two groups (English and not English in our case) including its 90% confidence interval.\nThen we’d write more about limitations and opportunities for further work, were this an actual Study 1, instead of just a demonstration."
  },
  {
    "objectID": "sample-study1.html#the-question-4",
    "href": "sample-study1.html#the-question-4",
    "title": "431 Project B Sample Study 1 Report",
    "section": "8.1 The Question",
    "text": "8.1 The Question\nWe’ll look at the association of two categorical factors we created earlier: medium_r and fiction_r in this analysis. We’re interested in whether there is an association between the ways in which subjects consumed their fiction, and the type of fiction they most enjoy. The medium_r data have three levels, and the fiction_r data have four levels. Note that we’ll use a 90% confidence level and you will do this in your actual Project B Study 1 work, as well.\nIf this were an actual Study 1, rather than a demonstration, I’d build a research question here, but I have decided to leave that work to you."
  },
  {
    "objectID": "sample-study1.html#describing-the-data-4",
    "href": "sample-study1.html#describing-the-data-4",
    "title": "431 Project B Sample Study 1 Report",
    "section": "8.2 Describing the Data",
    "text": "8.2 Describing the Data\nLet’s store this initial table of interest as table_E1\n\ntable_E1 &lt;- table(sur_15$medium_r, sur_15$fiction_r)\n\ntable_E1\n\n        \n         Comedy Drama Fantasy/SF Other\n  Movies      4     4          5     2\n  TV         10     5          2     4\n  Other       3     5          5     0\n\n\nWe could add the marginal totals, I suppose.\n\nsur_15 |&gt;\n  tabyl(medium_r, fiction_r) |&gt;\n  adorn_totals(where = c(\"row\", \"col\"))\n\n medium_r Comedy Drama Fantasy/SF Other Total\n   Movies      4     4          5     2    15\n       TV     10     5          2     4    21\n    Other      3     5          5     0    13\n    Total     17    14         12     6    49\n\n\nNote that we don’t meet the Cochran conditions here. In particular, we still have a 0 cell, and that might motivate us to consider collapsing or removing the “Other” category from the fiction_r variable.\nNOTE: In doing your project B, I would only proceed once I’d identified variables (after whatever collapsing you decide to do) that meet the Cochran conditions (described below.)\nI’ll leave it alone for now, and see what happens, returning to this later. The research question, if I’d written would need to address whether which medium (Movies, TV or other) you like is associated with which genre (Comedy, Drama, Fantasy/SF) you prefer."
  },
  {
    "objectID": "sample-study1.html#main-analysis-3",
    "href": "sample-study1.html#main-analysis-3",
    "title": "431 Project B Sample Study 1 Report",
    "section": "8.3 Main Analysis",
    "text": "8.3 Main Analysis\n\n8.3.1 Running the Pearson \\(\\chi^2\\) Test\nWe’ll run the Pearson \\(\\chi^2\\) test using:\n\nchisq.test(table_E1)\n\nWarning in stats::chisq.test(x, y, ...): Chi-squared approximation may be\nincorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table_E1\nX-squared = 8.2621, df = 6, p-value = 0.2195\n\n\nNote the warning, because our table does not meet the Cochran conditions.\n\n\n8.3.2 Running Fisher’s Exact Test\nNOTE: In doing your project B, I would only proceed once I’d identified variables (after whatever collapsing you decide to do) that meet the Cochran conditions (described below.) I would not run Fisher’s test.\nGiven a small overall sample size, the fisher.test command will also produce a Fisher’s exact test, which may be a little more appropriate here, given the presence of cells with small counts.\n\nfisher.test(table_E1)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table_E1\np-value = 0.2096\nalternative hypothesis: two.sided\n\n\nBased on the Fisher test, we would get only a slightly different conclusion than the Pearson test. However,\n\nOur conclusions are quite dependent on the choice of \\(\\alpha\\) level.\nNeither test is really appropriate, since we have very small cell counts, including a zero.\n\n\n\n8.3.3 Checking Assumptions - The Cochran Conditions\nThe “Cochran conditions”, which require that we have:\n\nno cells with 0 counts\nat least 80% of the cells in our table with counts of 5 or higher\nexpected counts in each cell of the table should be 5 or more\n\nWe don’t meet those Cochran conditions here. In addition, since each cell in our 3x4 table is NOT at least 5, R throws a warning message when we run the Pearson \\(\\chi^2\\) test, and since we don’t meet the Cochran conditions, the fisher.test results are questionable, as well. We should consider whether collapsing or deleting some of the rows or columns might be more reasonable. And we’ll do this next.\n\n\n8.3.4 An Association Plot for the 3x4 Table\nThe assocplot function in R produces a plot that indicates deviations from the assumption of independence of rows and columns in a two-way table. For instance, using our original table, we have:\n\nassocplot(table_E1)\n\n\n\n\n\n\n\n\nWe can see that the independence model really doesn’t work well for the cells with larger shapes here, which we note especially in the Fantasy/SF category, and to some extent in the Comedy category.\nHint: Finding a better scheme for visualizing a contingency table’s relationship to independence (or simply the table itself), especially if it’s using the gt package, would be a good idea to explore further in Analysis E, too, especially if you’re looking to learn to build savvy tables. But this is not necessary, certainly.\n\n\n8.3.5 A 2x3 Table, After Collapsing (Lumping) Some Small Rows and Columns\nSuppose we instead decided to drop down to a study of TV vs. Other media (combining Movies and Other) and also collapsed the Fantasy/SF and Other columns (so the remaining subjects form a 2x3 table), in an effort to remove zero cells, and reduce the incidence of cells with counts below 5.\nFirst, we’ll combine the Movies and Other groups to create medium_2 from medium_r using fct_recode.\n\nsur_15 &lt;- sur_15 |&gt;\n  mutate(medium_2 = fct_recode(medium_r, \n                                \"Not TV\" = \"Movies\",\n                                \"TV\" = \"TV\",\n                                \"Not TV\" = \"Other\"))\n\nOr, we can use the fct_lump function to lump together the two categories with the smallest overall counts directly, in creating fiction_3 from fiction_r.\n\nsur_15 &lt;- sur_15 |&gt;\n  mutate(fiction_3 = fct_lump(fiction_r, 2))\n\nLet’s call the collapsed table table_E2.\n\ntable_E2 &lt;- \n  table(sur_15$medium_2, sur_15$fiction_3)\n\ntable_E2\n\n        \n         Comedy Drama Other\n  Not TV      7     9    12\n  TV         10     5     6\n\n\nThis new 2x3 table loses some fidelity, but gains in that each cell now contains at least 5 subjects. I’ll remind you that in your Project B, we’re requiring you to have even more than that in each cell.\n\n\n8.3.6 Chi-Square Testing for the 2x3 Table\nAnd here are the results from chi-square testing…\n\nchisq.test(table_E2)\n\n\n    Pearson's Chi-squared test\n\ndata:  table_E2\nX-squared = 2.7279, df = 2, p-value = 0.2556\n\nfisher.test(table_E2)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table_E2\np-value = 0.2765\nalternative hypothesis: two.sided\n\n\nFor the project, once all of the cells have at least 5 observations, I recommend the use of the Pearson approach, unless the table is square (# of rows = # of columns), in which case the Fisher test is also a reasonable choice. Generally, the Fisher test is more appropriate when the sample sizes are small. In this case, of course, it doesn’t matter much after collapsing cells and forming this 2x3 table. We’ll close with the association plot for this smaller table, which suggests that the independence model inverts its errors for Comedy as compared to the other two categories.\n\nassocplot(table_E2)"
  },
  {
    "objectID": "sample-study1.html#conclusions-4",
    "href": "sample-study1.html#conclusions-4",
    "title": "431 Project B Sample Study 1 Report",
    "section": "8.4 Conclusions",
    "text": "8.4 Conclusions\nUsing the collapsed table_E2 to meet the Cochran conditions, and either the Pearson or Fisher test we detect no strong association between the favorite consumption method and favorite genre. I’d also spend a bit of time talking about the results of the assocplot, I think, or at least make some effort to indicate where the independence assumption holds less well, even though it doesn’t reach the point where we can reject it with 90% confidence.\nAgain, it’s your job to identify and discuss your conclusions, as expected in the instructions for Project B Study 1. This is just a demonstration."
  },
  {
    "objectID": "sample-study1.html#footnotes",
    "href": "sample-study1.html#footnotes",
    "title": "431 Project B Sample Study 1 Report",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLittle, Roderick J. A. 1988. “A Test of Missing Completely at Random for Multivariate Data with Missing Values.” Journal of the American Statistical Association 83 (404): 1198–1202. doi:10.1080/01621459.1988.10478722.↩︎\nNote the use of inline code here to specify this result. The usual cutoff for meaningful right skew by this measure is around 20% of a standard deviation.↩︎\nThe usual cutoff for meaningful right skew by this measure is around 20% of a standard deviation.↩︎\nThere is no need in Project B for you to use both a Holm and a Tukey HSD approach to your ANOVA. Either one is OK.↩︎\nAgresti A Coull BA 1988 Approximate is Better than “Exact” for Interval Estimation of Binomial Proportions. The American Statistician 52(2), 119-126. http://www.jstor.org/stable/2685469↩︎"
  },
  {
    "objectID": "self_eval.html",
    "href": "self_eval.html",
    "title": "Project B Self-Evaluation",
    "section": "",
    "text": "The self-evaluation form will appear on December 1 at https://bit.ly/431-2025-projectB-self-evaluation. If it’s after December 1, and the form isn’t available to you, please contact Dr. Love via email to remind him to turn it on.\nYou should complete the form after you have met with Dr. Love and given your project presentation. The deadline is the same as the deadline for your Final Report, and is posted on the Course Calendar.\nThe form is the usual sort of Google Form that Dr. Love uses for lots of things, and should take less than 15 minutes to complete. The form will ask you to reflect briefly on your project report and your presentation.\nIf you are working with a partner, each of you will need to separately complete the self-evaluation."
  },
  {
    "objectID": "study1b.html",
    "href": "study1b.html",
    "title": "Study 1 Report Specifications",
    "section": "",
    "text": "Produce a beautiful HTML report containing 8 main sections, as described below. It should include:"
  },
  {
    "objectID": "study1b.html#headings-you-should-use-in-the-study-1-report",
    "href": "study1b.html#headings-you-should-use-in-the-study-1-report",
    "title": "Study 1 Report Specifications",
    "section": "Headings you should use in the Study 1 report",
    "text": "Headings you should use in the Study 1 report\nAll of your work should be done in a fresh R project in a clean directory on your computer. - If you are working with NHANES data, your directory should include a data subdirectory, in which you will probably need to place the Love-431.R script. - If you need to ingest non-NHANES data, then your data directory should also include the raw data files.\n\nSetup and Data Ingest\n\nBe sure to load all necessary packages and ingest your data, either by reading it in with nhanesA or by reading in your raw non-NHANES data. Load the tidyverse last and do not load core packages from the tidyverse separately.\n\nCleaning the Data\n\nBe sure to review the material (including the Tips on Cleaning Data) provided in the Data Development section of this website.\nNote that it’s only necessary to clean the variables you will actually use in your four analyses below. Select only those variables (including the subject identifier) here when you create your analytic tibble.\nI also suggest applying janitor::clean_names at the start, but I wouldn’t otherwise change variable names if you’re not changing the meaning of the variables. If you want to change the names, you can, but then you must indicate that in your codebook, and do the renaming before you show the codebook.\nIf you create a new categorical variable from an existing quantitative variables, do so in this section of your report, and then refer to that work in the analyses below when you use the new variable.\n\nCodebook and Data Description\n\nThe first thing that should appear in the section is a description of the subjects of your study.\n\nAs an example of what I’m looking for, suppose that you are working with NHANES 2017-2020 data and have identified 3500 adults between the ages of 21 and 79 who have complete data on the variables in your final data set. In that case, the description I would want to see would be: “3500 adults ages 21-79 participating in NHANES 2017-2020 with complete data on the variables listed in the table below.”\n\nIn the first subsection in this section, labeled Codebook, present a codebook where you list all of the variables you will actually use in your four chosen analyses, in the format you will use in those analyses. Do not include any other variables (besides the subject identifying code) in the codebook.\nPresent your codebook in a table, with either three or four columns.\nPlace the variable name you will use in your analyses in the left-most column. The Codebook lists all of the variables you will use in your analyses (plus the subject identifying code). If you’re working with NHANES data, you should include both SEQN (subject code) in this list.\nThe type of variable should be Quant (for quantitative variables), Binary (for two-category variables), or X-cat for multi-category variables) where X should either be 3, 4, 5 or 6, to indicate the number of levels in the variable.\nIf you’ve changed a variable name (other than the obvious changes made by clean_names) from what you imported initially from your data source, add a final column where you specify the original variable name. The original name alone is sufficient here.\n\nFor those working with NHANES data, we will already be able to tell which data set in NHANES you used to obtain this variable from your initial pull of the data with the nhanesA package, so don’t specify the data set name again here.\n\n\n\nMake sure your Codebook looks nice and is easy to read in your HTML result. - If you decide to rename any of the variables from the names provided with the raw data, you should specify your new name and the original name in your codebook. - Your codebook should also describe each of the variables you are using and specify whether they are quantitative, binary or multi-categorical. - In the second subsection (called Analytic Tibble), list your clean tibble that the codebook describes, so we can see it is a tibble. Only the variables in your Codebook should appear. - In the third and final subsection here, labeled Data Summary, provide useful descriptive summaries of each variable in your codebook other than the subject identifying code. You can use describe from Hmisc or another option of your choosing to accomplish this. You needn’t provide graphical summaries here, and include only variables that are in your codebook.\nThose first three sections should then be followed by any four of the following five sections (which will be sections 4-7 in your report)…\n\nAnalysis A: Comparing 2 Means with Paired Samples\nAnalysis B: Comparing 2 Means with Independent Samples\nAnalysis C: Comparing X Means with Independent Samples (where you’d substitute in the number of means you’re comparing for X)\nAnalysis D: Analyzing a 2x2 table\nAnalysis E: Analyzing a JxK table (where you substitute in the values for J and K)\n\n\nWithin each of the four analyses you present, I’d have four (numbered) subsections:\n\nThe Question\n\nStart by describing what you want to study, and then specify a research question (which should end with a question mark and be something you can resolve with the planned analysis.)\nDon’t boil the ocean here. You’re looking for a research question that can be reasonably addressed using your data, so it has to be pretty straightforward.\nIf you have a pre-existing belief about what will happen, before you look at the data, please feel encouraged to include a statement about that belief before specifying your question.\n\nDescribing The Data\n\nThis should start with specifications of what each of the variables you are studying in this analysis actually mean.\nYour cleaning, creation of factors and other data management activities for each analysis should already have been shown in earlier sections. Please refer back to that section and don’t repeat what you’ve already done. Be sure that the Codebook you provided describes all variables you are using in your analyses here.\nProvide numerical summaries and visualizations of interest that are relevant to the analysis, and comment on any issues you observe.\n\nMain Analysis\n\nShow your work, and comment on whatever decisions you make.\nBe sure to present and justify the assumptions you are making.\n\nConclusions\n\nAnswer your research question, by clearly linking the analytic results to what you were asking at the start.\nIf you can see a logical next step for the analysis of the question you asked, specify it. Also, if you specified a pre-existing belief about what would happen, reflect on that in light of the data."
  },
  {
    "objectID": "study1b.html#and-finally",
    "href": "study1b.html#and-finally",
    "title": "Study 1 Report Specifications",
    "section": "And finally…",
    "text": "And finally…\nAs the final section of your report (which should be section 8), include the session information using session_info() from the xfun package. If you make more use of AI than spell-check or RStudio’s help with filling in details of functions, the place to talk about that is here, at the start of Section 8."
  },
  {
    "objectID": "study2a.html",
    "href": "study2a.html",
    "title": "Required Study 2 Analyses",
    "section": "",
    "text": "Once you have identified an acceptable data set, you will produce a report that demonstrates that you have accomplished the following:\n\nIdentify a quantitative outcome.\n\nFor purposes of this project, we will require your quantitative outcome to contain more than 15 unique values.\n\nIdentify a key predictor (which may be either quantitative or categorical.)\n\nIf the key predictor is categorical, it must have 3-6 categories, and each category must contain at least 30 observations.\n\nIdentify 3-8 other predictors of your outcome (demonstrating that either your key predictor or at least one of the “other” predictors is multi-categorical with 3-6 categories.)\nDefine a research question related to how effectively your key predictor predicts your quantitative outcome, while (possibly) adjusting for the other predictors.\nSteps 1-3 will yield a set of 6-11 variables (an outcome, a key predictor, 3-8 other predictors, and a subject identifier). Use those selections to create your analytic data set.\n\nYou must have between (500 and 7,500 observations if you’re using NHANES; 250 and 10,000 observations if not using NHANES) with complete data on all 6-11 variables included in your Study 2 analytic tibble. No other variables should be included in your Study 2 analytic tibble.\n\nClean the data in R, and this includes the creation of appropriately labeled (and if necessary, collapsed) factors for all categorical variables, and the investigation and decision-making regarding missing values, numbers of unique values and impossible values.\nComplete any imputation required to deal with missing data. Use single (simple) imputation with the mice package to create your imputed data. Do not impute your outcome or key predictor - you should filter to complete cases on those two variables.\nUse appropriate tools to provide useful numerical summaries for all data you will study, after all cleaning, so that these results describe the exact variables you will be modeling in the remaining work. Provide a clear note describing how much imputation you did.\nPartition the clean data into a model development (also called a model training) sample (60-80% of the data) and a model testing (also called a model validation) sample (the remaining 20-40%) using the approach recommended in the data .\n\nSuppose you had a tibble called original_data which identified its subjects with a subjID variable, and you wanted to place 75% of your data for development into training_sample and the rest into test_sample. You could do that with the following code…\n\n\n\nlibrary(tidyverse)\n\nset.seed(431) # pick a different seed than this\n\ntraining_sample &lt;- original_data |&gt; slice_sample(prop = 0.75)\n\ntest_sample &lt;- \n    anti_join(original_data, training_sample, by = \"subjID\")\n\n\nProvide appropriate, well-labeled visualizations of your outcome, and investigate potential transformations of that outcome for the purpose of fitting regression models in a useful way. Whatever transformation (including no transformation at all) should be used for the steps that follow.\nProduce two competitive models fit using least squares (rather than a Bayesian approach) for predicting your outcome using your clean data that provide evidence regarding your research question.\n\nOne of these models should be the full model with all candidate predictors included.\nYour other model should be a well-motivated subset of your full model, that at least includes the key predictor and one more predictor.\n\nAssess the performance of your two models (full model or subset) and come to a conclusion about which is better. This assessment should includes both in-sample (predictive performance and adherence to assumptions) and holdout sample (predictive quality) assessments. Be sure to attend to back-transformation properly should that be necessary, in evaluating the quality of predictions.\nUse the results of the model you chose to answer your research question, and then describe the limitations of this study and next steps you would like to pursue.\nJust to reiterate, in Study 2, you should explicitly state that you are assuming that “missing at random (MAR)” is the most appropriate missing data mechanism and then use single imputation for Study 2, with two exceptions: (1) I don’t want you to impute your outcome or key predictor, so you will need to filter to complete cases on those variables, and (2) you may decide to add on a multiple imputation summary of parameters for the final model if you choose, as we’ll discuss in Class."
  },
  {
    "objectID": "study2c.html",
    "href": "study2c.html",
    "title": "Study 2 Sample Report",
    "section": "",
    "text": "The Sample Study 2 Report is now available.\nThe Sample Study 2 Report provides a brief demonstration of an appropriate analysis for each of the required Study 2 analyses in Project B. Complete instructions for your Study 2 report are available here."
  },
  {
    "objectID": "study2c.html#the-study-2-sample-report",
    "href": "study2c.html#the-study-2-sample-report",
    "title": "Study 2 Sample Report",
    "section": "The Study 2 Sample Report",
    "text": "The Study 2 Sample Report\nThe Sample Study 2 Report demonstrates many of the elements you would need to complete, including:\n\ndata ingest\ncleaning the data, as well as\nbuilding a codebook for the final variables and describing them numerically, plus\npartitioning the data\nconsidering (and applying) a transformation\nfitting and summarizing a big model and a small model\ncomparing the two models within the training sample\nvalidating and comparing the two models within the holdout (test) sample\n\nfor a simulated data set containing information on 999 subjects about high blood pressure control."
  },
  {
    "objectID": "study2c.html#study-2-sample-report-the-files",
    "href": "study2c.html#study-2-sample-report-the-files",
    "title": "Study 2 Sample Report",
    "section": "Study 2 Sample Report: The Files",
    "text": "Study 2 Sample Report: The Files\nThe Sample Study 2 Report can be viewed in HTML at this link.\nThere is a link at the top of the HTML document where you can download the complete Quarto code used to create the Sample Study 2 Report, which might be a helpful template for your Study 2 report.\nThe data file for the Study 2 Example Report is described in the Quarto and HTML files above and is found on the 431-data website. It is called:\n\nhbp_study.csv (999 observations in 12 columns)\n\nThe subjects are identified with a code called subj_id"
  },
  {
    "objectID": "study2c.html#caveats",
    "href": "study2c.html#caveats",
    "title": "Study 2 Sample Report",
    "section": "Caveats",
    "text": "Caveats\n\nThe Sample Study 2 Report does not precisely follow the requirements from Study 2 for certain sections, because that is a big part of your job.\nIn the Sample Study 2 Report, I don’t make much of an effort to make attractive graphs. You really should.\nOutside of those caveats, the Sample Study 2 Report is meant to be accurate and reflect the level of detail I’m looking for, although it is certainly possible to expand on these demonstrations in your work, if that seems helpful. I believe the Sample Study 2 Report documents to be largely accurate, but many eyes will find some issues, eventually. If people find corrections and would be good enough to email me about them, I will attempt to reflect those edits in revisions. If I do something in the Sample Study 2 Report that appears to be in conflict with the instructions for Study 2, then (a) please let me know, and (b) treat the Study 2 instructions as your guidepost in completing your work."
  }
]